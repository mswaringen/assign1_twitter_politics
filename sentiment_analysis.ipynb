{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "\n",
    "* Import and preprocess Assignment Data\n",
    "* Import and preprocess Labeled Twitter Data\n",
    "* Split/train/test Labeled Twitter data model\n",
    "* Split/train/test Movie Review data model\n",
    "* Compare results of both models on Labeled Twitter data Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import html.parser as HTMLParser# In Python 3.4+ import html \n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "import collections, itertools\n",
    "import nltk.classify.util\n",
    "import nltk.metrics\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk import precision\n",
    "from nltk import recall\n",
    "from nltk import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Assignment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>full_location</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 10:04:02 +0000 2016</td>\n",
       "      <td>@BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...</td>\n",
       "      <td>en</td>\n",
       "      <td>Baton Rouge, LA</td>\n",
       "      <td>United States</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Aug 12 10:04:30 +0000 2016</td>\n",
       "      <td>#CNN #newday clear #Trump deliberately throwin...</td>\n",
       "      <td>en</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>United States</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Aug 12 10:04:46 +0000 2016</td>\n",
       "      <td>@realDonaldTrump, you wouldn't recognize a lie...</td>\n",
       "      <td>en</td>\n",
       "      <td>Palm Springs, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Aug 12 10:04:48 +0000 2016</td>\n",
       "      <td>\"Kid, you know, suing someone? Thats the most ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Secaucus, NJ</td>\n",
       "      <td>United States</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Aug 12 10:04:48 +0000 2016</td>\n",
       "      <td>@HillaryClinton you ARE the co-founder of ISIS...</td>\n",
       "      <td>en</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>United States</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Fri Aug 12 10:04:02 +0000 2016   \n",
       "1  Fri Aug 12 10:04:30 +0000 2016   \n",
       "2  Fri Aug 12 10:04:46 +0000 2016   \n",
       "3  Fri Aug 12 10:04:48 +0000 2016   \n",
       "4  Fri Aug 12 10:04:48 +0000 2016   \n",
       "\n",
       "                                                text lang     full_location  \\\n",
       "0  @BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...   en   Baton Rouge, LA   \n",
       "1  #CNN #newday clear #Trump deliberately throwin...   en     Baltimore, MD   \n",
       "2  @realDonaldTrump, you wouldn't recognize a lie...   en  Palm Springs, CA   \n",
       "3  \"Kid, you know, suing someone? Thats the most ...   en      Secaucus, NJ   \n",
       "4  @HillaryClinton you ARE the co-founder of ISIS...   en        Irving, TX   \n",
       "\n",
       "         country state  \n",
       "0  United States    LA  \n",
       "1  United States    MD  \n",
       "2  United States    CA  \n",
       "3  United States    NJ  \n",
       "4  United States    TX  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_feather('data/tweets_by_state.feather')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[[0]]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract then Remove Hyperlinks, Tokenize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "def tokenize_tweets(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match: \n",
    "        result = re.sub(r\"http\\S+\", \"\", text)\n",
    "        return tokenizer.tokenize(result.lower())\n",
    "    return tokenizer.tokenize(text.lower())\n",
    "\n",
    "# A function that extracts the hyperlinks from the tweet's content.\n",
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''\n",
    "\n",
    "# A function that checks whether a word is included in the tweet's content\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_tokens'] = tweets['text'].apply(lambda tweet: tokenize_tweets(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>full_location</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>link</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 10:04:02 +0000 2016</td>\n",
       "      <td>@BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...</td>\n",
       "      <td>en</td>\n",
       "      <td>Baton Rouge, LA</td>\n",
       "      <td>United States</td>\n",
       "      <td>LA</td>\n",
       "      <td>https://t.co/5GMNZq40V3</td>\n",
       "      <td>[all, in, collusion, together, #nojustice, #tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Aug 12 10:04:30 +0000 2016</td>\n",
       "      <td>#CNN #newday clear #Trump deliberately throwin...</td>\n",
       "      <td>en</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>United States</td>\n",
       "      <td>MD</td>\n",
       "      <td></td>\n",
       "      <td>[#cnn, #newday, clear, #trump, deliberately, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Aug 12 10:04:46 +0000 2016</td>\n",
       "      <td>@realDonaldTrump, you wouldn't recognize a lie...</td>\n",
       "      <td>en</td>\n",
       "      <td>Palm Springs, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>CA</td>\n",
       "      <td>https://t.co/pKSQM8yikm</td>\n",
       "      <td>[,, you, wouldn't, recognize, a, lie, if, it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Aug 12 10:04:48 +0000 2016</td>\n",
       "      <td>\"Kid, you know, suing someone? Thats the most ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Secaucus, NJ</td>\n",
       "      <td>United States</td>\n",
       "      <td>NJ</td>\n",
       "      <td></td>\n",
       "      <td>[\", kid, ,, you, know, ,, suing, someone, ?, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Aug 12 10:04:48 +0000 2016</td>\n",
       "      <td>@HillaryClinton you ARE the co-founder of ISIS...</td>\n",
       "      <td>en</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>United States</td>\n",
       "      <td>TX</td>\n",
       "      <td></td>\n",
       "      <td>[you, are, the, co-founder, of, isis, ,, you, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Fri Aug 12 10:04:02 +0000 2016   \n",
       "1  Fri Aug 12 10:04:30 +0000 2016   \n",
       "2  Fri Aug 12 10:04:46 +0000 2016   \n",
       "3  Fri Aug 12 10:04:48 +0000 2016   \n",
       "4  Fri Aug 12 10:04:48 +0000 2016   \n",
       "\n",
       "                                                text lang     full_location  \\\n",
       "0  @BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...   en   Baton Rouge, LA   \n",
       "1  #CNN #newday clear #Trump deliberately throwin...   en     Baltimore, MD   \n",
       "2  @realDonaldTrump, you wouldn't recognize a lie...   en  Palm Springs, CA   \n",
       "3  \"Kid, you know, suing someone? Thats the most ...   en      Secaucus, NJ   \n",
       "4  @HillaryClinton you ARE the co-founder of ISIS...   en        Irving, TX   \n",
       "\n",
       "         country state                     link  \\\n",
       "0  United States    LA  https://t.co/5GMNZq40V3   \n",
       "1  United States    MD                            \n",
       "2  United States    CA  https://t.co/pKSQM8yikm   \n",
       "3  United States    NJ                            \n",
       "4  United States    TX                            \n",
       "\n",
       "                                        clean_tokens  \n",
       "0  [all, in, collusion, together, #nojustice, #tr...  \n",
       "1  [#cnn, #newday, clear, #trump, deliberately, t...  \n",
       "2  [,, you, wouldn't, recognize, a, lie, if, it, ...  \n",
       "3  [\", kid, ,, you, know, ,, suing, someone, ?, t...  \n",
       "4  [you, are, the, co-founder, of, isis, ,, you, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Labeled Tweets Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets = pd.read_csv('data/raw_data/training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-1\", usecols=[0,5], names=['sentiment', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets.loc[labeled_tweets['sentiment'] == 4, 'sentiment'] = 'pos'\n",
    "labeled_tweets.loc[labeled_tweets['sentiment'] == 0, 'sentiment'] = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       neg  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       neg  is upset that he can't update his Facebook by ...\n",
       "2       neg  @Kenichan I dived many times for the ball. Man...\n",
       "3       neg    my whole body feels itchy and like its on fire \n",
       "4       neg  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>pos</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>pos</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>pos</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>pos</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>pos</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                               text\n",
       "1599995       pos  Just woke up. Having no school is the best fee...\n",
       "1599996       pos  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997       pos  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998       pos  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999       pos  happy #charitytuesday @theNSPCC @SparksCharity..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    800000\n",
       "pos    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_tweets.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize Tweets & Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets['clean_tokens'] = labeled_tweets['text'].apply(lambda tweet: tokenize_tweets(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets['clean_tokens'] = labeled_tweets['clean_tokens'].apply(lambda x: [item for item in x if item not in stops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets['clean_tokens'] = labeled_tweets['clean_tokens'].apply(lambda x: [item for item in x if len(item) >= 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>[awww, that's, bummer, shoulda, got, david, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[upset, can't, update, facebook, texting, ...,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>[dived, many, times, ball, managed, save, rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[behaving, i'm, mad, can't, see]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text  \\\n",
       "0       neg  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1       neg  is upset that he can't update his Facebook by ...   \n",
       "2       neg  @Kenichan I dived many times for the ball. Man...   \n",
       "3       neg    my whole body feels itchy and like its on fire    \n",
       "4       neg  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                        clean_tokens  \n",
       "0  [awww, that's, bummer, shoulda, got, david, ca...  \n",
       "1  [upset, can't, update, facebook, texting, ...,...  \n",
       "2  [dived, many, times, ball, managed, save, rest...  \n",
       "3            [whole, body, feels, itchy, like, fire]  \n",
       "4                   [behaving, i'm, mad, can't, see]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (End preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create & Test Labeled Twitter Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting tokens and label into a list for pos and neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['love', 'guys', 'best'], 'pos'),\n",
      " (['meeting', 'one', 'besties', 'tonight', 'cant', 'wait', 'girl', 'talk'],\n",
      "  'pos')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pos_tweets_df = labeled_tweets[labeled_tweets['sentiment']=='pos']\n",
    "pos_tweets = []\n",
    "\n",
    "def feat_format(token):\n",
    "    pos_tweets.append((token,'pos'))\n",
    "\n",
    "pos_tweets_df['clean_tokens'].apply(lambda token: feat_format(token))\n",
    "pprint(pos_tweets[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['awww',\n",
      "   \"that's\",\n",
      "   'bummer',\n",
      "   'shoulda',\n",
      "   'got',\n",
      "   'david',\n",
      "   'carr',\n",
      "   'third',\n",
      "   'day'],\n",
      "  'neg'),\n",
      " (['upset',\n",
      "   \"can't\",\n",
      "   'update',\n",
      "   'facebook',\n",
      "   'texting',\n",
      "   '...',\n",
      "   'might',\n",
      "   'cry',\n",
      "   'result',\n",
      "   'school',\n",
      "   'today',\n",
      "   'also',\n",
      "   'blah'],\n",
      "  'neg')]\n"
     ]
    }
   ],
   "source": [
    "neg_tweets_df = labeled_tweets[labeled_tweets['sentiment']=='neg']\n",
    "neg_tweets = []\n",
    "\n",
    "def feat_format(token):\n",
    "    neg_tweets.append((token,'neg'))\n",
    "\n",
    "neg_tweets_df['clean_tokens'].apply(lambda token: feat_format(token))\n",
    "pprint(neg_tweets[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Reduce data set\n",
    "\n",
    "Accuracy improves with larger dataset, but takes exponentially more time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "subset_size = 0.0015\n",
    "pos_tweets = random.sample(pos_tweets,int(len(pos_tweets)*subset_size))\n",
    "neg_tweets = random.sample(neg_tweets,int(len(neg_tweets)*subset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tweets = pos_tweets[:int((len(pos_tweets)*0.001))]\n",
    "# neg_tweets = neg_tweets[:int((len(neg_tweets)*0.001))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_tweets+neg_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract List of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the separate words in tweets\n",
    "# Input:  A list of tweets\n",
    "# Output: A list of all words in the tweets\n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "# Create a dictionary measuring word frequencies\n",
    "# Input: the list of words\n",
    "# Output: the frequency of those words apearing in tweets\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "#     print (\"Word frequency list created\\n\")\n",
    "    # pprint(type(wordlist))\n",
    "    return word_features\n",
    "\n",
    "# Construct our features based on which tweets contain which word\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "def best_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in best_features:\n",
    "        features[word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1800 instances, test on 600 instances\n",
      "accuracy: 0.66\n",
      "Most Informative Features\n",
      "                    hate = True              neg : pos    =      8.6 : 1.0\n",
      "                watching = True              pos : neg    =      8.6 : 1.0\n",
      "                   sucks = True              neg : pos    =      8.3 : 1.0\n",
      "                   tired = True              neg : pos    =      7.8 : 1.0\n",
      "                  stupid = True              neg : pos    =      7.7 : 1.0\n",
      "                   thank = True              pos : neg    =      7.4 : 1.0\n",
      "                     sad = True              neg : pos    =      7.3 : 1.0\n",
      "                     ugh = True              neg : pos    =      7.0 : 1.0\n",
      "                    cold = True              neg : pos    =      6.3 : 1.0\n",
      "                    gone = True              neg : pos    =      6.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "negcutoff = int(len(neg_tweets)*3/4)\n",
    "poscutoff = int(len(pos_tweets)*3/4)\n",
    "\n",
    "train_tweets = neg_tweets[:negcutoff] + pos_tweets[:poscutoff]\n",
    "test_tweets = neg_tweets[negcutoff:] + pos_tweets[poscutoff:]\n",
    "\n",
    "word_features = get_word_features(get_words_in_tweets(train_tweets))\n",
    "\n",
    "# Here we apply the features we constructed to our tweets data.\n",
    "twitter_training_set = nltk.classify.apply_features(extract_features, train_tweets)\n",
    "\n",
    "# Feaure count\n",
    "# len(twitter_training_set[0][0])\n",
    "\n",
    "# Printing the resulting training set shows the features we are going to pass to the classifier.\n",
    "# pprint(training_set[0])\n",
    "\n",
    "# This is the line of code that we use to train our classifier. Training is performed in a streamlined way so no output is visible.\n",
    "classifier = nltk.NaiveBayesClassifier.train(twitter_training_set)\n",
    "\n",
    "twitter_test_set = nltk.classify.apply_features(extract_features,test_tweets)\n",
    "\n",
    "print ('train on %d instances, test on %d instances' % (len(twitter_training_set), len(twitter_test_set)))\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, twitter_test_set))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_fd = FreqDist()\n",
    "label_word_fd = ConditionalFreqDist()\n",
    "junk = ['p','o','s','n','e','g','...']\n",
    "\n",
    "for tpl in pos_tweets[:poscutoff]:\n",
    "    for lst in tpl:\n",
    "        for word in lst:\n",
    "            if word not in junk:\n",
    "                word_fd[word.lower()] += 1\n",
    "                label_word_fd['pos'][word.lower()] += 1\n",
    "\n",
    "for tpl in neg_tweets[:negcutoff]:\n",
    "    for lst in tpl:\n",
    "        for word in lst:\n",
    "            if word not in junk:\n",
    "                word_fd[word.lower()] += 1\n",
    "                label_word_fd['neg'][word.lower()] += 1\n",
    "\n",
    "pos_word_count = len(label_word_fd['pos'])\n",
    "neg_word_count = len(label_word_fd['neg'])\n",
    "total_word_count = pos_word_count + neg_word_count\n",
    " \n",
    "word_scores = {}\n",
    " \n",
    "for word, freq in word_fd.items():\n",
    "    pos_score = BigramAssocMeasures.chi_sq(label_word_fd['pos'][word],\n",
    "        (freq, pos_word_count), total_word_count)\n",
    "    neg_score = BigramAssocMeasures.chi_sq(label_word_fd['neg'][word],\n",
    "        (freq, neg_word_count), total_word_count)\n",
    "    word_scores[word] = pos_score + neg_score\n",
    " \n",
    "best = sorted(word_scores.items(), key=lambda s: s[1], reverse=True)[:10000]\n",
    "bestwords = set([w for w, s in best])\n",
    "best_features = dict.fromkeys(bestwords,0).keys()\n",
    " \n",
    "# def best_word_feats(words):\n",
    "#     return dict([(word, True) for word in words if word in bestwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-0cd25646692b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtwitter_training_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwitter_training_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtwitter_test_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/classify/naivebayes.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# Count up how many times each feature value occurred, given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# the label and featurename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0mlabel_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/collections.py\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/classify/util.py\u001b[0m in \u001b[0;36mlazy_func\u001b[0;34m(labeled_token)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlazy_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mLazyMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object is not callable"
     ]
    }
   ],
   "source": [
    "twitter_training_set = nltk.classify.apply_features(best_features, train_tweets)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(twitter_training_set)\n",
    "\n",
    "twitter_test_set = nltk.classify.apply_features(best_features,test_tweets)\n",
    "\n",
    "print ('train on %d instances, test on %d instances' % (len(twitter_training_set), len(twitter_test_set)))\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, twitter_test_set))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_word_fd['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['school', 'like', 'thursdays', 'thankfully', 'real', 'last', 'one', 'screamed', 'bloody', 'mary', 'garage', 'thinking', 'wow', \"i'm\", 'scared', 'gray', 'animal', 'comes', 'think', 'touched', 'sucks', 'want', 'pet', 'feel', 'bad', 'fans', 'tree', 'hilll', 'episode', 'sooo', 'sad', 'june', 'gloom', 'thought', 'gone', '.  ...', 'guess', 'means', 'time', 'head', 'gym', 'ugh', 'fml', 'going', 'make', 'music', 'heeey', 'guys', \"i'msoo\", 'today', 'need', 'sister', 'pleease', 'flavia', 'sitting', 'next', 'loser', 'work', 'day', \"ain't\", 'truth', 'ahah', 'game', 'fuck', 'outloud', 'daniel', 'murphy', 'got', 'officially', 'morning', '...', 'thakyou', 'informing', 'important', 'matter', 'screwed', 'horribly', 'often', 'end', 'order', 'fix', 'afraid', 'band-aids', 'wont', 'job', 'anymore', 'please', 'tell', 'start', 'selling', 'k-cups', 'miss', 'community', 'keurig', 'machines', 'met', 'pushing', 'daisies', 'hope', 'upset', 'cancellation', 'love', 'people', 'power', 'trips', 'especially', 'push', 'yayy', 'well', 'piff', 'busy', 'plurk', 'hate', 'much', 'making', \":'(\", 'gonna', 'try', 'sleep', 'goodnight', 'twitterville', 'loveme', 'haha', 'hey', 'tom', 'look', 'reply', 'safari', 'use', 'add-ons', 'must', 'get', 'ready', 'wonder', 'would', 'mind', 'taking', 'laptop', 'writing', 'evening', 'hmm', 'back', 'pain', 'grrr', 'cant', 'dwnld', 'fav', 'song', \"d'aw\", 'since', 'kill', 'bill', 'vol', 'background', 'noise', 'rip', 'david', 'carradine', 'sorry', 'widad', 'jus', 'left', 'old', 'navy', 'tried', 'outfit', 'less', 'fun', 'getting', 'anything', 'ngl', 'listen', 'shit', 'busan', 'dreading', 'surprise', 'vacation', 'coming', 'wednesday', 'seriously', 'makes', 'really', 'goes', 'bell', 'right', 'shall', 'tweet', \"y'all\", 'later', 'choir', 'net', 'block', 'text', \"that's\", 'retarded', 'maybe', 'adrenaline', 'new', 'minimize', 'symptoms', 'woke', 'missing', 'pimp', 'daddy', 'hmmm', 'still', 'mend', 'brain', 'working', 'know', 'lucozade', 'crackers', 'lol', 'cos', 'reminds', 'stuff', 'sure', 'update', 'true', 'thinkin', 'something', 'dinner', 'best', 'cook', 'feeling', 'quite', 'worried', 'tweeted', 'days', 'feelin', 'missin', 'baby', 'girl', 'laughin', 'role', 'models', 'tho', 'dear', 'skyped', 'client', 'coaching', 'session', 'wrong', 'two', 'hours', 'early', 'oops', 'evryone', '#pawpawty', 'mollyd', 'take', 'care', 'grandma', 'pawty', 'shooting', 'threes', 'minutes', 'ads', 'free', 'throw', 'messin', 'around', 'visual', 'basic', 'travel', 'australia', 'earring', 'home', 'earlier', 'store', 'open', 'rafael', 'nadal', 'amazing', 'talent', 'watch', 'wishing', 'soon', 'living', 'able', 'save', 'doc', 'silly', 'made', 'grumpy', 'hurting', 'surgery', 'lost', 'ipod', 'songs', 'soundtrack', 'empty', 'god', 'essay', 'due', \"i've\", 'worn', 'charlie', 'brown', 'costume', 'install', 'iphone', 'sdk', 'yet', 'requires', '10.5', 'using', '10.4', 'uni', 'ruining', 'life', 'per', 'usual', 'raining', 'tokyo', 'saturdays', 'without', 'football', 'fridays', 'fish', 'better', 'least', 'thurs-sun', 'stress', 'promise', 'bored', 'trapped', 'indoors', 'leaving', 'everyone', 'tired', 'though', 'including', 'andrew', 'fallen', 'asleep', 'zomg', 'on-air', 'microbiology', 'water', 'thorn', 'ice', 'cream', 'incredibally', 'logs', 'turns', 'might', 'whitby', 'gothic', 'weekend', 'oct', 'looking', 'forward', 'resort', 'heating', 'weather', 'sat', 'signal', 'terrestrial', 'emergency', 'vet', 'hoping', 'kitten', 'online', 'nothing', 'dooo', 'graduating', 'tomorrow', 'hit', 'someone', 'already', 'everything', '21st', 'stupid', 'grad', 'trip', 'year', 'sadd', 'wanna', 'cry', 'find', 'jacket', 'come', 'hang', 'buddy', 'yeah', 'drive', 'good', 'melissa', 'wants', 'doctors', 'glad', 'class', 'break', 'algebra', 'test', 'website', 'found', 'cup', 'final', 'whilst', 'boy', 'reason', 'sam', 'threw', 'little', 'bit', 'hardheaded', 'improve', \"can't\", 'keep', 'emotional', 'figure', 'hahaha', \"would've\", 'disappointed', 'licence', 'months', 'passenger', 'dad', 'talks', 'eat', 'change', 'diet', 'fat', 'holy', 'fault', 'veggies', 'involved', 'cease', 'desist', 'another', 'wedding', 'planner', 'plagiarised', 'content', 'pricing', 'twitter', 'clicked', 'icon', 'blog', 'given', 'error', 'page', 'screams', 'tucks', \"i'll\", 'friday', 'crazy', 'seeing', 'dead', 'deer', 'side', 'road', 'sick', 'coughing', 'runny', 'nose', 'lay', 'bed', 'dbz', 'everybody', 'church', 'camp', '2morow', 'summer', \"what's\", 'wish', 'could', 'week', 'sleeping', 'choking', 'death', 'wtf', 'universe', 'luckkky', 'dock', 'burnt', 'popcorn', 'hates', 'sunburn', 'watchin', 'mtv', 'movie', 'awards', 'soo', 'saaad', 'thanks', 'prom', 'cuz', 'dont', 'suggestions', 'followers', 'twits', 'become', 'invigorating', 'grounded', 'lond', 'hahahaha', 'commercials', 'leave', 'never', 'updates', 'bgirl', 'see', 'possum', 'murderer', 'stand', 'chance', 'whoah', 'crap', 'mistake', 'put', 'three', 'letters', 'together', 'im-el-im', 'overwhelmed', 'follow', 'bots', 'talk', 'iloveyou', 'minus', 'ticket', 'thing', 'shopping', 'hear', 'isa', 'shipping', 'bermuda', 'triangle', 'kicked', 'butt', 'dang', 'sounds', 'saw', 'first', 'del', 'taco', 'ventura', 'looks', 'bomb', 'totally', 'excited', 'relaized', 'call', 'bodies', 'tragic', 'air', 'france', 'flight', 'live', 'illinois', 'nice', 'many', 'laging', 'terrible', 'night', 'almost', 'big', 'headache', 'absolutely', 'waking', 'ocean', 'dammit', 'low', 'score', 'hay', 'wat', 'havnt', 'email', 'secrets', 'stay', 'secret', 'stoopid', 'dude', 'move', 'protocol', 'help', 'thinks', 'say', 'concerts', 'town', 'house', 'star', 'trek', 'davy', 'run', 'prolly', 'cus', 'phone', 'verizon', 'cause', 'phones', 'hurts', 'stop', 'sneezing', 'tootoo__much', 'vanilla', 'finished', 'cleaning', 'room', 'study', 'science', 'omg', 'pro', 'suicide', 'obviously', 'spell', 'fingerrs', 'caring', 'julia', 'loll', 'meant', 'lunching', 'colleages', 'meeting', 'idea', \"they'll\", 'happy', 'fathers', 'person', 'ever', 'awww', 'sree', 'nih', 'gmn', 'sih', 'ngerti', 'guee', 'apa', 'mksdnya', 'following', 'long', 'patience', 'guidance', 'daily', 'forget', 'man', 'exist', 'joe', '830', 'cruise', 'jealous', 'calls', 'friends', 'family', 'place', 'one-on-one', 'conversations', 'watched', 'finale', 'show', 'awesome', 'season', 'cool', 'till', '2day', 'altho', 'jeremy', 'kyle', 'friend', 'possible', 'soulmate', \"sammy's\", 'poor', 'puppy', 'alas', 'cherry', 'pie', 'enough', 'maoam', 'checked', 'story', 'enjoy', 'facing', 'poles', 'embarrassment', 'central', 'aplication', 'hummm', 'customised', 'site', 'money', 'ive', 'seen', 'option', 'settings', 'screen', 'cramps', 'plus', 'gotta', 'buena', 'park', 'traffic', 'exercising', 'self', 'quarantine', 'way', 'russia', 'imagine', 'korea', 'iran', 'saying', 'neck', 'killing', 'turn', 'carma', 'teasing', 'cousin', 'stiff', 'bar', 'stewards', 'exclusive', 'orange', 'far', 'loved', 'membership', 'mine', 'birthday', 'monday', 'eloise', 'unsatisfied', 'flu', 'taken', 'cared', 'happen', 'wake', 'damn', 'rush', 'hour', 'mess', 'multiple', 'serious', 'accidents', 'wanted', 'failed', 'also', 'reminded', 'read', 'dat', 'fever', 'mild', 'body', 'aches', 'otherwise', 'yesterday', 'teamed', 'speech', 'loss', 'stranger', 'eyes', 'red', 'burning', 'pollen', 'finally', 'worst', 'series', 'tnt', 'inside', 'nba', 'accumulate', 'spent', 'organizing', 'cold', 'lightheaded', 'coughy', 'picture', 'showing', 'doped', 'painkillers', 'fed', 'welcome', 'china', 'bitch', 'nooo', 'ahh', 'tmrw', 'noe', 'half', 'everytime', 'click', 'chat', 'write', 'message', 'send', 'takes', 'login', 'bugger', 'closed', 'nope', 'idiots', 'biggest', 'difference', 'unfortunately', 'longest', 'word', 'english', 'language', 'sadly', '140', 'characters', 'whopping', 'sore', 'top', 'lip', 'lips', 'fire', 'resigning', 'month', 'payment', 'p45', 'p60', 'wage', 'slip', 'awake', 'resulted', 'crying', 'sober', 'fam', 'hungry', 'alone', 'abandoned', 'child', 'awe', 'neil', 'leaves', 'tonite', 'okey', 'idiot', 'poly', 'difficulty', 'understanding', 'modules', 'maths', 'forever', 'horrid', 'ramp', 'chocolate', 'rejecting', 'shake', 'drank', 'trying', 'muir', 'woods', 'fewer', 'trees', 'thank', 'grow', 'told', 'lil', 'attack', 'clue', 'lmao', 'present', 'hell', 'waiting', 'cannot', 'believe', 'ordered', 'salad', \"main-that's\", 'eating', 'twice', 'great', 'beats', 'catching', 'partying', 'huh', 'didnt', 'even', 'celebrate', 'b-day', 'agree', 'suffer', 'oomph', 'somewhere', 'shift', 'woken', 'shuffles', 'away', 'britans', 'boo', 'hoo', 'harder', 'tattoos', 'chicken', 'oneon', 'ribs', 'said', 'hurt', 'wuss', 'utterly', 'lonely', 'drinking', 'waste', 'drink', 'tonight', 'productive', 'always', 'cursed', 'hideous', 'costumes', 'heavy', 'hot', 'worrying', 'went', 'forest', 'cullens', 'rly', 'sometime', 'knowing', 'disheartening', 'frustrating', 'soe', 'done', 'paul', 'play', 'party', 'fell', 'jeans', 'beasides', 'wounded', 'understand', 'sleepy', 'pleaseee', 'kick', 'jogging', 'hammersmith', 'fridayyy', 'weird', 'anybody', 'lives', 'atl', 'storms', 'rain', 'tuesday', 'mega', 'photo', 'pretty', 'useless', 'piece', \"we've\", 'talked', 'finland', 'eurovision', 'beginning', 'toll', 'mental', 'well-being', 'girls', 'glittery', 'body-hugging', 'dresses', 'helping', 'yay', 'six', 'olds', 'forgot', 'previous', 'nights', 'level', 'moment', 'multi', 'skillz', 'rusty', 'caught', 'pan', 'finger', 'miserable', 'bull', 'lmfaoo', \"steve's\", 'nightmares', 'nestly', \"there's\", 'cookies', 'publix', 'boi', 'mane', 'warmed', 'nicely', 'outside', 'stuck', 'coding', 'taf', '1057', 'zulu', 'sky', 'clear', 'wind', '270/10', 'becoming', '1130z', 'overcast', '250', 'brother', 'date', 'cut', 'short', \"friend's\", 'father-in-law', 'heart', 'bust', 'blagh', 't_t', 'fmlfmlfml', 'magpies', 'blues', 'aussie', 'rules', 'hiss', 'bloodwork', 'ihop', 'nurse', 'wounds', 'scratch', 'atm', 'card', 'sifr', 'rendering', 'craving', 'food', 'agreed', 'civil', 'growing', 'called', 'hateful', 'ignorant', 'despite', 'efforts', 'may', 'worth', 'wiso', 'sind', 'deine', 'screenshots', 'immer', 'mieser', 'qualli', 'gosh', 'reminding', 'waltzers', 'alton', 'towers', 'serve', 'europe', 'turned', 'cameo', 'performance', 'slightly', 'thinned', 'poodle', 'cuts', 'urrgh', 'hearing', 'puppies', 'bark', 'downstairs', 'tradus', 'peste', '3100', 'propozitii', 'din', 'eng', 'romana', 'pana', 'duminica', 'viitoare', 'cine', 'm-a', 'pus', 'exact', 'cand', 'incepe', 'wimbledonul', 'arghhh', 'lovely', 'dhira', 'leader', 'padahal', 'minggu', 'lagi', 'brasiliansnya', 'dateng', 'fair', 'foxtel', 'jonas', 'brothers', 'luckyyy', 'ewww', 'sends', 'freshener', 'windows', 'hospital', 'pics', 'turning', 'problem', 'brought', '1gb', 'memory', 'stick', 'roommate', 'started', 'packing', 'breakfast', 'title', 'training', 'devoured', 'mosquitoes', 'terrific', 'speed', 'paintballing', 'running', 'fast', 'beer', 'combination', 'paying', 'isnt', 'sunny', 'enjoying', 'sun', 'late', 'channel', '#bntm', 'viola', 'breasts', 'sweetheart', 'post', 'twitpic', 'lot', 'myspace', 'accts', 'shoes', 'aiyo', 'classes', 'crampsss', 'smoking', 'moving', 'weak', 'give', 'round', 'rate', 'says', 'breathe', 'refuse', 'dark', 'swimming', 'mean', 'fallout', 'keeps', 'jump', 'health', 'ammo', 'worry', 'fan', 'cheap', 'electric', 'kettle', 'tea', 'taste', 'plastic', 'non-plastic', 'snap', 'reality', 'hooked', 'mailbox', \"t'was\", 'drinkin', 'guinness', '272', \"dad's\", 'cat', 'iabm', 'thre', 'nfight', 'iughhh', 'fuckkk', 'thisss', 'hard', 'animation', 'voice', 'actors', 'sweet', 'train', 'apple', 'reallly', 'needs', 'ability', 'reinstall', 'backed', 'app', 'data', 'app-by-app', 'basis', 'palm', '#iphone', '#apple', 'america', 'ass', 'funny', 'hopefully', 'haruhi', 'link', 'stream', 'direct', 'download', 'plz', 'wait', 'tomorrows', 'canny', '2hear', 'kerry', 'gmtv', 'missed', 'aghh', 'crappy', 'unorganised', 'sucking', 'thursday', 'perfect', 'drawing', 'board', 'light', 'midnight', 'jetlagg', 'uber', 'pissed', 'ppl', 'picked', 'intimidating', 'googled', 'source', 'project', 'sir', 'min', 'fuckers', 'cooked', 'grim', 'outsides', 'shudder', 'lobster', 'anyone', 'wasnt', 'saturday', 'came', '4days', 'interval', 'influenced', 'probably', 'boring', 'angry', 'youre', 'concert', 'demi', 'itching', 'api', 'cried', 'american', 'warm', 'beautiful', 'instead', 'annoying', 'blackmailed', \"drew's\", 'sub', 'bike', 'view', 'drew', 'yes', 'holidays', 'havent', 'ima', 'fired', 'wii', 'budget', 'disconnected', 'aim', 'yep', 'restarting', 'ton', 'programs', 'works', 'fireworks', 'lame', 'happening', 'ahhh', 'caliwas', 'win', 'keen', 'walking', 'tomoro', 'scaredi', 'actually', 'someones', 'mum', 'duno', 'drunk', 'climb', 'acho', 'musica', 'mais', 'chata', 'miley', 'cyrus', 'saddd', \"they're\", 'recording', 'mom', 'lax', 'hello', 'office', 'wokr', 'dyeing', 'hair', 'colors', \"i'd\", 'tennessee', 'basically', 'hid', 'set', 'roger', 'comp', 'broken', 'yall', 'pms', 'emo', 'opportunity', 'letting', 'discrete', '800msp', 'point', 'lookout', 'technical', 'issues', 'sound', '#jeffstreet', 'counting', 'dentist', 'energy', 'bills', '400', 'every', 'extend', 'overdraft', 'finals', 'bummed', 'grizzly', 'bear', 'album', 'capture', 'brillance', 'show.songs', 'strong', 'indo', 'credit', 'dnt', 'either', 'join', 'club', 'sumtimes', 'gurl', 'sux', 'homework', 'bedtimeee', 'prepearing', 'luvin', 'peaceful', 'pleasant', 'cloudy', 'eaten', 'extremely', 'bloated', 'part', 'favorite', 'bands', 'used', 'prayers', 'families', '447', 'passengers', 'ddude', 'fit', 'dress', 'debbie', 'downer', 'large', 'font', 'named', 'katty', 'kitty', 'yea', 'rude', 'fot', 'sin', 'lmfao', 'spit', 'pulled', 'stash', 'dash', 'laundry', 'attic', 'tub', 'full', '#rpattz', 'canada', \"rob's\", 'mins', \"nikki's\", 'sunday', \"tom's\", 'truly', 'brb', 'asking', 'assume', 'london', 'spammer', 'wellington', 'jet', 'lagged', 'lunch', 'beach', 'ansted', 'pick', 'guitar', 'sing', 'everyday', 'exactly', 'nine', 'inch', 'nails', 'pfff', 'eminem', '#mtv', 'lung', 'infection', 'spreading', 'rest', 'organs', 'died', 'hun', 'nap', 'mad', 'speaking', 'experience', 'failing', 'subject', 'anticlimatic', 'phil', 'hacker', 'unmotivated', 'slamming', 'yummy', 'lasagna', 'news', \"honey's\", 'nah', 'jks', 'tru', 'dumb', 'pizza', 'reading', 'jon', \"kate's\", 'problems', 'aww', 'tumblr', 'changed', 'log', 'enjoyed', 'oversized', 'hats', \"could've\", 'noes', 'pounding', 'uhm', 'al-queda', 'creation', 'ronald', 'reagan', 'headaches', 'gurgaon', 'buy', 'ship', 'recommend', 'amazon', 'doesnt', 'intl', 'ideas', 'age', 'video', 'upload', 'youtube', 'watching', 'world', 'hills', 'bailed', 'workin', 'sigh', 'memories', 'wooot', 'secondary', 'pencil', 'case', 'mukas', 'italian', 'dood', 'hugs', 'parents', 'loose', 'heartbreaking', 'nervous', 'bout', '...  ..', 'camera', 'flying', 'banff', '24hrs', '11.25', 'ways', 'dog', 'abby', 'question', 'suspend', 'investigated', 'clients', 'official', 'newmediaguy', 'contact', 'thats', 'cute', 'glade', 'husband', '360', 'whats', 'gas', 'hut', 'isolated', 'normal', 'unfollow', 'mentioned', 'ide', 'personal', 'losing', 'overtired', 'wreck', 'chicken-pox', 'bound', 'til', 'canberra', 'coz', '2nd', 'sway', 'beyond', 'vortex', \"team's\", 'intercept', \"father's\", 'wonderful', 'years', 'ago', 'payday', 'snack', 'machine', 'microsoft', 'discontinue', 'wash', 'shame', 'cancelled', 'refund', 'informed', 'organiser', 'doobie', 'exhausted', 'fantastic', 'trawl', 'boards', 'careful', 'chellez', 'funnystyle', 'psycho', 'skip', 'homework-time', 'paperwork', 'wheel', 'misfortune', 'meets', 'apparently', 'rejects', 'attempted', 'philly', 'epic', 'fail', 'anyways', 'passed', 'bak', 'accent', 'commute', 'nyc', 'swoll', 'aching', 'pilot', 'continental', 'airlines', 'brussels', 'newark', 'atlantic', 'ohh', 'noo', 'joshua', 'forgive', 'madd', 'boogie', '5647560', 'whole', 'wee', 'pink', 'eye', 'grandads', '2moz', 'holiday', 'playstation', '9:22', 'bleh', 'plan', 'thru', 'tongue', 'burny', 'babe', \"wife's\", 'sleepin', \"baby's\", 'accoint', 'check', 'swine', 'land', 'san', 'diego', 'wearing', 'sense', 'tan.com/skincaner', 'aaah', 'nowww', 'feverish', 'freedom', 'jees', 'green', 'envy', 'invited', 'mac', 'launch', 'journo', 'helen', 'shows', 'tattooed', 'hook', 'lan', 'cord', 'sharyn', 'brett', 'trinda', 'driving', '730', 'sry', 'froofroo', 'times', 'realise', 'mbp', 'edge', 'loneeelllyyy', 'cuddle', 'dyin', 'owner', 'asked', 'random', 'africans', 'colour', 'car', 'nothin', 'face', 'fullest', 'mark', 'bustin', 'door', 'computer', 'freaking', 'alex', 'wong', 'incredible', 'dancer', 'eugh', 'hangovers', 'confused', 'engineering', 'walkin', 'ftl', 'goooddd', 'texted', 'gran', 'ring', 'coward', 'sign', 'library', 'wet', 'screw', 'couldnt', 'flipping', 'puyeng', 'nya', 'pasti', 'ngga', 'kangen', 'cinta', 'bertepuk', 'sebelah', 'tangan', 'grandmother', 'decided', 'reeks', 'excellent', 'context', 'covered', 'cure', 'public', 'scorpions', 'bruno', 'ages', 'babies', 'talkative', 'teenagers', 'lovey', 'dovey', 'couples', 'metra', 'rides', 'unbareable', 'muzza', 'lying', 'cuevas', 'serve-volleying', \"he's\", 'ones', 'took', 'nearly', 'race', 'gona', 'happened', \"dr's\", 'purse', 'chair', 'kobe', 'cheats', 'wife', 'yuck', 'needle', 'thumb', 'unlucky', 'revision', \"we're\", 'supposed', 'thunderstorms', 'sunshine', 'pay', 'attention', 'jen', 'diarrhea', 'incher', \"cat's\", 'looked', 'horrible', 'eventually', 'ears', 'blocked', 'delete', 'tweets', \"car's\", 'interior', 'washed', 'wheels', 'course', 'dirty', 'fuckin', 'starvin', 'mojo', 'volleyball', 'hangin', 'babysit', 'somebody', 'whos', 'name', 'oclock', 'dreaming', 'waited', 'sawyer', 'mbxes', 'build', 'server', 'outlook', 'airport', 'starbucks', 'plane', 'delayed', 'forgotten', 'ankles', 'esp', 'dry', 'socks', 'hand', 'boston', 'legal', '. . .', '1st', 'wings', 'debating', 'whether', \"cousin's\", 'bday', 'risk', 'infecting', 'kids', \"here's\", 'sns', 'heff', 'wondering', 'hurry', '#oldnavyweekly', \"today's\", 'graphic', 'design', 'expression', 'sawry', \"let's\", 'let', 'wher', 'snow', 'huuurts', 'proper', 'preparation', 'physical', 'activity', 'beg', 'july', 'die', 'dream', 'swap', 'wld', 'lahh', '20th', 'listening', 'heaps', '500', 'bucks', 'gotten', 'heard', 'invites', 'google', 'users', 'initiate', 'checking', 'melbs', 'tilt-shift', 'time-lapse', 'photography', 'calendar', 'www.uniqlo.com/calendar/', 'scenes', 'japan', 'kinda', 'gear', 'bring', 'frozen', 'sweetcorn', 'remain', 'pair', 'lobsters', 'cramping', 'argentina', 'unfair', 'michigan', 'special', 'non-attendance', 'hiccups', 'fmlaptop', 'realize', 'theres', 'no1', 'gota', 'unpack', 'borin', 'shopaholic', 'austin', 'knit', 'yarns', 'learned', 'lake', 'police', 'drunkenness', 'tickets', 'monsters', 'maria', 'coffee', 'catch', 'doubt', 'sack', 'throat', 'frm', 'singing', 'lozenges', 'popped', 'flew', 'pontiac', 'entire', 'system', '1700.00', 'sold', 'mechanic', '200.00', 'jesus', 'christ', '83.50', 'pit', 'seat', 'blows', 'scare', 'shut', 'wasted', 'avoiding', 'transformation', 'college', 'mcfly', 'played', 'jobros', 'wembley', 'fave', 'rift', 'valley', 'wknd', 'scenery', 'variety', 'www.journeykenya.com', 'blazing', 'kmt', 'apartment', 'hunt', 'continues', 'visiting', 'sites', 'near', 'orchid', 'baner', 'confusing', 'badly', 'mosquito', 'staying', 'ketek', 'abis', 'ngerjain', 'mtk', 'pile', 'books', 'fall', 'suitcase', 'sisters', 'keeper', 'ouch', 'hste', 'umbrella', 'knw', 'der', 'umbrellas', 'anti-breakage', 'ropes', 'attached', 'market', 'shud', '#gmail', 'forcing', '#rich', '#format', '#plain', '#text', 'limit', '<sob>', '#maxis', 'killed', 'kutner', 'okay', 'widget', 'wishin', 'connected', 'available', 'area', 'omfg', 'gets', 'easliy', 'drugs', 'heeelp', 'rugged', 'hilton', 'wythville', 'hike', 'joy', 'poohey', 'cycle', 'luck', 'tummys', 'grumbling', 'huge', 'north', 'woodlands', 'pkwy', 'motorcycle', 'loaded', 'onto', 'flatbed', 'ooohhh', 'pop', 'nobody', 'twiiter', 'lived', 'fletcher', 'crickets', 'idk', 'todayy', 'haircut', 'backache', 'mile', \"o'clock\", 'whoops', 'tooted', 'black', 'waitress', 'nite', 'bangin', 'arm', 'seems', 'starting', 'migrate', 'heck', 'birth', 'lazy', 'kid', 'ride', 'erg', 'tires', 'suck', 'dropped', 'shattered', 'product', 'goal', 'sickies', 'expecting', 'rubber', 'braces', 'heartbroken', '100', 'davids', 'wwaaahhh', 'reno', 'crash', 'metro', 'last.fm', 'glares', 'foot', 'gateway', '#fail', '#sony', 'vidzone', 'streaming', 'videos', 'playstation', 'sch', 'aber', 'nicht', 'schweizer', 'children', 'metallic', 'polariod', '195bucks', 'wristcutters', 'nelson', 'sundance', 'movies', 'demand', 'afternoon', 'mcdonalds', 'rexy', 'likes', 'boxing', \"it'll\", 'contract', 'broke', 'allergic', 'names', 'knackered', 'sudden', 'thoughts', 'sims', 'humidity', 'bathroom', 'nicest', 'smelling', 'snaps', 'shampoos', 'seniors', 'roll', 'along', 'piiissed', \"we'll\", 'lyrics', 'boys', 'future', 'foolery', 'pee', 'strap', 'thread', 'unraveling', 'woooa', 'bird', 'bnc', 'expected', 'naw', 'argh', 'exams', 'nazi', 'film', 'jut', 'upcoming', 'graduation', 'indeed', 'solo', 'dryh', 'tasty', 'treat', 'hacks', 'starving', 'hablaaame', 'others', 'ooo', 'procrastinating', 'fucking', 'bang', 'gay', 'tryna', 'hiz', 'bag', 'economy', 'graduated', 'biatches', 'greeaattt', 'sept', 'beby', 'goin', 'akon', 'bean', 'depressing', 'oldest', 'transformers', 'showings', 'except', '10pm', 'shojo', 'manga', \"kid's\", 'program', 'melody', 'douchebag', 'stock', 'aaw', 'pili', 'magwito', 'asap', 'orientation', 'cancels', 'regular', 'sched', 'hahahahhahaha', 'stretch', \"rem's\", \"avi's\", 'viewing', 'web', '640x480', 'canadian', 'women', 'rated', 'form', 'text-based', 'communication', 'via', 'cell', 'illegal', 'covers', 'fucked', 'cracking', 'fixed', 'betta', 'nuffin', 'neglected', 'sox', 'opening', 'conflicts', 'prevent', 'rescheduled', 'grills', 'dot', 'cotton', \"tv's\", 'in-laws', 'smoother', 'hug', 'major', 'siick', 'arent', 'nottingham', 'signing', 'materials', 'introduction', 'hotel', 'young', 'couple', 'bummer', 'east', 'search', 'barn', 'shot', 'interested', '5.5', 'miles', 'although', 'ridiculously', 'bootcamp', 'toget', 'goose', 'egg', 'legs', \"bestfriend's\", 'moneyyy', 'cooking', 'cake', 'php', 'easy', 'realy', 'expensive', 'announcements', 'rumours', 'battery', 'charging', 'decide', 'account', 'outa', 'bath', 'dropping', 'comedyqueen', '#twittertakeover', 'fully', 'cloud', 'list', 'bali', 'quarantined', 'ikea', 'nearby', 'ate', 'onion', 'rings', 'gross', 'attempt', 'ahha', 'juat', 'atlanta', 'add', 'things', 'scones', 'fattening', 'carrasco', 'interacting', 'ball', 'snagged', 'smells', 'wonderfulness', 'share', 'ending', 'highly', 'dislike', 'mornings', 'reformat', 'cds', 'lossless', 'mighty', 'geek', 'plese', 'super', 'outdoors', 'bedtime', 'arsed', 'sundae', 'passing', 'table', 'wakin', 'guy', 'singin', 'durin', 'kareoke', 'research', 'exam', 'corn', 'fellow', 'euro', 'u21', 'malm', 'owning', 'taxi', 'facebook', 'gangster', 'concerned', 'awful', 'boot', 'yer', 'moms', 'straight', 'answer', 'migraine', 'considered', 'possibility', 'scary', '228', 'mini', 'parked', 'window', 'drop', '11am', 'helps', 'castle', 'howard', 'temple', 'four', 'winds', 'former', 'diana', 'pic', 'pts', 'suppose', 'breaks', 'fandom', 'eachother', 'different', 'respect', 'sniffs', 'pint', 'sending', 'grossed', 'waterbug', 'scurried', 'arabic', \"who's\", 'pens', '3-1', 'faith', 'ting', 'skool', 'bruv', 'sadness', 'links', 'foo', 'susan', 'boyle', 'hospitalized', 'blackberry', 'hola', 'mwah', 'srs', 'flail', 'krugman', 'snarky', 'bloggers', 'quoting', 'climbing', 'bright', 'pots', 'cedric', 'map', 'benihana', 'twins', 'lens', 'lump', 'stomach', 'backtell', 'lana', 'info', 'itunes', 'udate', 'serato', 'dans', 'potatoes', 'films', 'scottish', 'thunderstorm', 'coreplayer', 'winmo', 'standard', 'version', 'replies', 'appear', 'apologise', 'donut', 'stronger', 'desire', 'nebraska', 'tailgaiting', 'anywhere', 'connection', 'chicago', 'ugly', 'wes', 'company', 'female', 'california', 'angelus', 'sex', 'nibble', 'can.have', '3000', 'words', 'semi', 'team', 'intend', \"ev'd\", 'unlikely', 'cmt', 'spend', 'lunchtime', 'else', 'theater', 'giving', 'balloons', 'couldve', 'besties', 'comments', 'policy', \"nyt's\", 'multimedia', 'here', 'emoticons', 'don', 'sadface', 'shitty', 'internet', 'zone', 'fashion', 'media', 'promotion', 'huddersfield', 'applied', \"l's\", 'username', 'lovvve', 'micro', 'romania', 'wacked', 'laying', 'utilities', 'afan', 'studio', 'emv', 'anthem', 'bumbed', 'record', 'verse', 'rough', 'volcano', 'peace', 'quiet', 'wifi', 'www.netpierre.nl', 'tweet-up', 'host', 'congratulations', 'achievement', 'vote', 'england', 'awsome', 'loads', 'dancing', 'feet', 'michelleyys', 'tis', 'images', 'stealing', 'issue', 'peruse', 'spot', 'fries', 'struggling', 'third', 'assessment', 'neighbor', 'stolen', 'driveway', 'somerville', 'scene', 'grumpsus', 'perhaps', 'neckache', '2:30', 'spammed', 'idiotic', 'quizzes', 'section', 'controls', 'charge-up', 'spin', 'spending', 'revenge', 'scratched', 'derby', 'convincingly', 'preakness', 'exciting', 'shirt', 'wore', 'weekly', 'bunches', 'janes', 'single', 'depressed', 'raining.and', 'somehow', 'tomorrow.but', 'positive', 'grand', 'piano', 'dozen', 'swear', 'remember', '1pm', 'mush', 'finish', 'arrrgh', 'leicester', 'laptops', 'teach', 'teacher', '#edtech', 'note', 'serial', 'beethoven', 'homggg', 'slim', 'plugging', 'mains', 'perfumes', 'colognes', 'los', 'angeles', 'repeat', 'gossip', 'atleast', '2night', 'samsung', 'buttons', 'stopped', 'gutted', 'lush', 'ham', 'sanie', 'deli', 'chelsea', 'bun', 'coke', 'yum', 'ben', 'loves', 'blast', 'dissed', 'arm-paint', 'implied', 'inappropriate', 'frustrated', 'comcast', 'step', 'steps', 'manager', 'ohhh', 'impossible', 'depends', 'borrow', 'prices', 'ridiculous', '#acen', 'preparing', 'gf11', 'supervision', 'yippie', 'aloud', 'lets', 'profs', 'dee', '4dogz', 'hayfever', 'modem', 'premiere', 'slat', '#newmoon', 'bae', 'worse', 'dreams', 'celeb', \"shannon's\", 'slow', 'pune', 'backlog', 'southside', \"u're\", 'nickkkjonasss', 'officialjobros', 'fake', 'bentley', 'doin', \"name's\", 'james', 'mother', 'talking', 'wood', 'snapping', 'banging', 'accidently', 'april', 'rainy', 'tomorrowww', 'killer', 'hangover', 'modeling', 'bye', 'mommy', 'pirates', 'pinball', 'putt-putt', 'eff', 'hairdresser', 'cutted', 'laaame', \"they've\", 'tennis', 'smell', 'thoughon', 'ohno', 'affect', 'bbq', 'pregnancy', 'second', 'smoke', 'depended', 'possibly', 'taylor', \"lautner's\", \"mmva's\", 'tears', '2ma', 'eyes.cuz', 'starin', 'dads', 'now.lost', \"where's\", 'promising', 'bottle', 'sweater', 'noticed', 'stitch', 'stumped', 'wakey', 'patio', 'birds', 'suggest', 'lamb', 'rage', 'lately', 'household', 'corndogs', 'classy', 'tweeters', '6am', 'appt', 'fine', 'australian', 'appreciate', 'eggs', 'toast', 'benedict', 'kitchen', 'reliving', 'quake', 'quakelive', \"they'd\", 'portable', 'plugin', 'iron', 'wine', 'naked', 'devo', 'tanta', 'coisa', 'mas', 'vai', 'ser', 'rapido', 'deve', 'teu', 'endere', 'crush', 'trey', 'songz', \"emma's\", 'cutest', 'zander', 'penguins', 'skits', 'penguin', 'puppets', 'fatz', 'swimteam', 'pleeease', 'kan', 'aminn', 'south', 'asia', 'region', 'gtuu', 'loh', 'iya', 'pass', 'hiks', 'boyzone', \"in't\", 'freddie', 'montserrat', 'chortle', 'bein', 'kindly', 'however', 'chilling', 'sexy', 'clever', 'heaptweets', 'biog', 'thxs', 'joining', '#ilove', 'movement', 'quick', 'meet', 'complaining', 'pff', 'renew', 'milder', '311', 'genre', 'uplifter', 'tip', '11.15', 'haa', 'flavor', 'jerrys', 'choc', 'fudge', 'brownie', 'danicng', 'shop', 'pooped', 'practice', 'girlie', 'rockin', 'robin', 'jackson', \"twitter's\", 'theme', 'battlefield', 'rock', 'belated', 'bowling', 'splashed', 'awning', 'tym', 'gon', 'sobombtictic', 'hehehe', 'beat', 'stockton', 'rule', '1981', 'born', 'www.tweeterfollow.com', 'vip', 'terry', 'andrews', 'wud', 'arrived', 'safely', 'philippines', 'yeaaauh', 'feels', 'bitchin', 'complain', 'uno', 'jolt', 'mentioning', 'wears', 'skirts', 'wear', 't-shirts', 'rofl', 'comment', 'tokin', \"tmail'in\", 'taylah', 'vistoso', 'bosses', 'states', 'potluck', 'twitterers', 'seas', 'centrelink', 'lycan', 'ran', 'crowded', 'fiends', '15th', 'emptied', '50sqm', 'funeral', 'service', \"matt's\", 'worries', 'elana', 'speak', 'restricted', 'apps', '7th', 'lucky', 'redmond', 'heyyy', \"ya'll\", 'managed', 'connect', 'white', 'yellow', 'glorious', 'dedication', 'deserves', 'goodies', 'mail', 'stickers', 'addy', 'livin', 'downloadingnow', 'thankiesss', 'doctor', 'pristine', 'liner', 'frog', 'tossing', 'incidents', 'artist', 'ssup', 'howz', 'ystrdy', 'bothered', 'advise', 'medical', 'webical', 'bro', 'sushi', \"best's\", 'owen', 'replay', 'besides', 'winged', 'shoot', 'ono', 'compare', 'notes', 'craziest', 'shower', 'bags', 'attractive', 'acting', \"nothing's\", 'unusual', 'wtf-is-your-problem-feed-me', 'heh', 'realised', 'freaky', 'book', 'orders', 'dpd', 'booked', 'coolio', 'tillie', 'coast', 'graceful', 'rise', 'brightening', 'customer', 'tutor', \"updating-can't\", 'exceptionally', 'lloyd', 'webber', 'tim', 'rice', 'total', 'eclipse', 'separate', 'definitely', 'el-oh-el', '#literalvideos', 'ashley', 'kat', 'married', 'japanese', 'farewell', 'lal', 'meal', 'adore', 'belongs', 'flabbergasted', 'functioning', 'actual', 'human', 'habit', 'sell', \"dvd's\", 'makeup', 'sunbath', 'goona', 'original', 'svu', 'boss', 'ask', 'staff', 'emails', 'masterpieces', 'tact', 'positivity', 'legend', 'twittering', 'tina', 'ash', 'smiley', 'congrat', '@bakytn', 'battle', 'resize', 'pictures', 'gorgeous', 'punk', 'dance', 'strip', 'getty', 'hurray', 'offers', 'interveiws', 'access', 'ace', 'liquor', 'tastes', 'piss', 'assuming', 'tasted', 'smiled', 'shook', 'older', 'generation', 'fuzzball', 'blood', 'uhhh', 'cheers', 'wii-tastic', 'marrying', 'fairly', 'competitive', \"maiya's\", 'vicinity', 'cupcake', 'close', 'nerd', 'careless', 'ruin', 'simple', 'spare', 'ajax', 'impact', 'util', 'sharing', 'stood', 'building', 'dmb', 'woo', 'howdy', 'twitterland', 'phne', 'related', 'steven', 'redicously', 'schoool', 'baseball', 'plans', 'sit', \"pj's\", 'kerrang', 'peter', 'kind', '#smtb', 'themostawesomepromever', 'advance', 'shining', 'yeh', 'duhh', 'brunch', 'mommie', 'knows', 'interest', 'joop', 'hold', 'local', 'congrats', 'icecream', 'addicted', 'gettin', '08:22', 'needed', 'hysterical', 'headed', 'dougs', 'burn', 'dunnut', 'dane', \"cook's\", 'incident', 'comedy', 'hiddedn', 'hopes', 'hup', 'youd', 'chosen', 'hullooo', 'fay', 'lautner', 'washing', 'mmm', '6-1', 'bummish', 'dayy', 'belinda', 'makan', 'bersama', 'pria', 'bau', 'kentut', 'corner', 'oooppps', 'www.auntychristine.etsy.com', 'flipsides', 'nom', 'hal', 'mayer', 'bay', 'flooding', 'waterfront', 'millions', 'customers', 'switched', 't-mobile', 'national', 'carriers', 'average', 'archie', 'btw', 'archangel', 'fanatics', 'ovr', 'wishes', 'bunch', 'hehe', 'uhhmm', 'kahit', 'anung', 'raket', 'basta', 'wag', 'lang', 'sayaw', 'baka', 'kilala', 'ding', 'scout', 'nene', 'dond', 'andas', 'enviciate', 'conmigo', 'heheheheh', 'rats', 'thoroughly', 'committed', 'hee', 'earn', 'pedal', 'posted', 'cooks', 'manila', 'specially', 'goingto', 'greenflies', 'ants', 'toes', \"summer's\", 'nokia', 'senses', 'listens', 'wakes', 'naturaly', 'coolest', 'barack', 'obama', 'measham', 'dealing', 'greek', 'gods', 'goddesses', 'bonded', 'nick', 'packers', 'crosse', 'hotter', 'jason', 'bartha', 'riley', 'bejamin', 'gates', 'treasure', 'chase', 'seth', 'chick', 'expect', 'nefertiti', 'misunderstood', 'success', 'webinar', 'conference', 'belgrade', 'successful', 'business', 'auntie', 'telly', 'insane', 'reminder', 'greeting', 'peruvian', 'ale', 'insomnia', 'keys', 'war', 'homee', 'browsing', 'points', 'twiends', 'bronx', 'queens', 'niece', 'kymora', 'ummm', 'toronto', 'umm', 'bing', 'sorted', 'loverly', 'bathe', 'walk', 'shops', 'lollies', 'pleasure', 'fab', 'doiin', \"mofo's\", 'mann', 'thingz', 'wudd', 'enter', 'giveaways', 'ten', \"what'cha\", 'tweeties', 'frogs', 'particular', 'mistakes', 'opportunities', 'learn', 'duck', \"#that'snothowexpenseswork\", 'momma', 'chillis', '#followfriday', 'brightonians', 'recommendation', 'appreciated', 'cuttin', '1:1', 'attribute', 'winning', 'personality', 'syrian', 'krissy', 'pointless', 'men', 'finallay', 'effects', 'global', 'warming', 'fm3', 'customization', 'matters', 'dying', 'suncream', 'oil', 'grabbing', 'winks', 'lvatt', 'stephenie', 'meyer', 'trailer', 'moon', 'teryn', 'comic', 'sans', 'rebel', 'iamculture', 'csi', 'spy', 'danny', 'discount', '698', '1080', 'walmart', 'paid', 'liking', \"nintendo's\", 'mario', 'endless', 'picross', 'professor', 'layton', 'mariners', 'ridge', 'wolverine', 'evan', 'bobby', 'brugger', 'walker', 'wesche', 'marie', 'akron', 'visited', 'tokio', 'bria', 'etc', \"brewer's\", 'sea', 'italiannn', 'tips', 'tweeting', 'teens', 'lonley', 'deserved', 'cleaned', 'mii', 'scrolly', 'profile', 'actions', 'nudge', 'gene', 'canning', 'repost', 'tylenol', 'dahlin', 'tommy', 'speaks', 'spanish', 'it', 'stamina', 'sequel', 'loving', 'annabelle', 'photos', 'memorial', 'kick-off', 'center', 'behind', 'pumping', 'hummer', 'archive', 'ignore', 'directions', '#readathon', 'adored', 'reviewing', 'picnic', 'basket', 'types', '194', 'modern', 'romance', 'pish', \"mother's\", 'hungarian', 'puli', 'pup', 'heartworm', 'homepage', '#newnews24', 'heading', 'captive', 'audience', 'tessa', \"c'mon\", 'investment', 'honest', 'box', 'state', 'juice', 'uying', 'kelly', 'germany', 'anytime', '6th', 'auto', 'posts', 'stoked', 'bubbly', '2pm', 'ended', 'blocking', 'bumblebee', 'rich', 'kinds', 'dope', 'deserve', 'hestite', 'thunder', 'watchinn', 'britain', 'bestie', 'conserve', 'giveaway', 'incentive', '#clothdiapers', 'gaaay', 'htown', 'resolved', '#amazeballs', 'nazis', 'largely', 'apathetic', 'anyway', 'leyton', 'culinary', 'comfirmation', 'assembly', 'goodnighttt', 'urself', 'beauty', 'purnus', 'soul', 'reconized', 'godly', 'corrected', \"we'd\", 'cover', 'mothers', 'mexico', 'alive', 'allowing', 'linux', 'delay', 'productivity', 'prepare', 'carolina', 'twilight', 'studying', 'deal', 'telling', 'mileey', 'wainting', 'brazil', '2hours', 'yumm', 'greater', 'blessing', 'written', \"melo's\", '#noundiessunday', 'students', '1994', 'seventh', 'gymnasium', 'zagreb', 'croatia', 'museum', 'ie6update', 'code', 'dodgy', 'aaron', 'jim', '. .', 'high', 'interseting', 'dogs', 'bought', 'heirlooms', 'hahahahahah', 'laugh', 'tweetie', 'turtle', 'naww', 'layering', 'infamous', 'peggy', 'definately', 'rocket', 'launcher', 'trucks', 'nigh', 'jazz', '89.1', 'kmhd', 'kmhd.fm', 'infect', 'fatal', 'tune', 'calms', 'snugglin', 'misses', 'dynamically', 'plotting', 'locations', '#umbraco', '#jquery', '#jmaps', 'kml', 'output', 'xslt', 'masterpages', 'curious', 'conclusion', 'khols', 'prettyy', 'skools', 'spring', 'tweeps', 'ringtones', 'gimme', 'entering', 'mood', 'melted', 'lipstick', 'vaseline', 'contest', 'entries', 'slept', '2.5', 'hrs', 'usually', 'napper', 'rdy', 'hubby', 'asheville', 'footlong', 'subway', 'detox', 'fruits', 'thaaanks', 'currently', 'intensive', 'bribe', 'mummehh', 'fresh', 'asexual', 'seem', 'hardest', 'dudes', 'biz', 'mon', 'aidan', 'xxx', 'dennis', 'melina', 'hawwwtt', 'felt', 'restore', 'requested', 'personally', 'across', 'trending', 'paper', 'ink', 'comeon', 'knew', 'coloured', 'rollercoaster', 'butterflies', 'psaz', 'zoo', 'bette', 'midler', 'strength', 'lalala', 'shaun', 'kaison', 'superrr', 'tireddd', 'o_o', 'goinggg', 'sleeeppp', 'gah', 'interesting', 'statistic', 'union', 'jack', 'nail', 'variations', 'worriess', 'chris', 'weitz', 'yayayayay', 'grind', 'cinnamon', 'flaxseed', 'nutmeg', 'ginger', 'cocoa', 'powder', 'outta', 'knights', 'ere', 'santorini', 'greece', 'hint', 'follower', 'videogames', 'finishing', 'chem', 'jca', 'fewww', 'stephen', \"brandon's\", 'flag', 'stud', 'wooo', 'awebo', 'nadrei', 'rublev', 'esta', 'veinte', 'vidoes', 'por', 'verla', 'ma', 'ana', 'que', 'hacer', \"kaulitz's\", 'whut', 'luv', \"disney's\", 'princess', 'bringin', 'oldschool', 'disney', 'introducing', 'tweetpeeps', 'prizes', 'solidified', 'backyard', 'lolz', 'iono', 'ish', 'certain', '#tad', 'aint', 'shy', 'darling', 'netune', 'active', 'gentle', 'influence', 'hidden', 'mysteries', 'kissed', 'roof', 'finding', 'kiss', 'clouds', 'smile', 'skies', 'grey', 'ldrs', 'west', '360idev', 'planning', 'glasgow', 'nxt', 'hitting', 'rare', 'await', 'persistence', 'searching', '#probeard', 'counts', 'brian', 'settin', 'wheat', 'thins', 'pepper', 'champions', 'wake-up', 'grab', 'yofruit', 'cheese', 'sandwich', 'salt', 'vinegar', 'crisps', 'clay', 'noraniza', 'idris', 'spotlight', 'hapuslah', 'airmata', 'kak', 'ani', 'loveee', 'adorable', 'xoxoxo', 'yess', 'shee', 'l0ve', 't000', 'f0r', 'miami', 'gig', 'blue', 'aka', 'zigatos', '12th', '9pm', 'butterfly', 'hanging', 'philbert', 'twilighters', 'polite', 'lemonade', 'lemon', 'sugar', 'pancakes', 'ohm', 'everything-is-alright-and-viv-will-be-fine', 'everything-is-alright', 'falling', '#iloveyou', 'xbox', 'support', 'press', 'regret', 'yawn-groan-snapcracklepop', 'mornin', 'ahead', 'brazilian', 'willl', 'skys', 'beautifully', 'keeping', '#mtogo', 'thx', 'lovin', 'apt', 'lack', 'lots', 'ojdl', 'playing', 'changes', 'hornby', 'strange', 'mostly', 'alright', 'writes', 'secretly', 'pok', 'churchhh', 'hiding', 'kks', 'discuss', 'nightmare', 'christmas', 'fellas', 'stalker', 'backround', 'ncis', 'rather', 'toss', 'lie', 'des', 'moines', 'scott', 'kaki', 'sangat', 'sakit', 'bershopping', 'sehari', 'suntuk', 'sungguh', 'berbaloi', 'material', 're-launch', 'prefer', 'august', 'bryony', 'sometimes', 'barrafina', 'hands', 'tapas', 'yeeeaaahhh', 'wit', 'mia', 'alreadyyy', 'trouble', 'yup', 'mix', 'sarah', 'mclachlan', 'weds', 'flower', 'petal', 'yelping', 'rec', 'twitterberry', 'options', 'gave', 'snoring', 'fisnih', 'tommorow', 'heyy', 'ethan', 'hahah', 'drama', 'highlight', 'impression', 'fancy', 'juicy', 'debate', 'transit', 'twittersphere', 'laughed', 'discussion', 'nickname', 'peanut', \"aunt's\", 'resting', 'brew', 'bottom', 'lash', 'geordie', 'term', 'drinks', 'celebrating', 'spizzle', 'forreal', 'current', \"tonight's\", 'knock', 'hustle', 'sippin', 'remy', 'rockz', 'gooodniite', 'mufffins', 'mode-working', 'applications', 'submitted', 'ezine', 'article', 'organised', 'cheesy', 'pops', 'meat', 'lovers', 'viva', 'yeesss', 'woot', '#lvatt', 'uploading', 'picturesss', 'safe', 'travels', 'radio', '97.4', '#canterbury', '#music', 'orlando', 'downtown', 'ghirardelli', 'bittersweet', 'symphony', 'verve', 'places', 'sonya', 'lady', 'small', 'hiatus', 'dent', 'marathon', 'winking', 'ekka', 'over.whats', 'agenda', 'popping', 'yeaaa', 'manng', 'happens', 'visit', 'bone', 'cracker', 'ingredients', \"g'morning\", 'unprecedented', '3rd', 'row', 'wales', 'snorers', 'legger', 'leggers', 'bauer', 'remembering', 'goood', 'adding', 'functionality', 'visiteach', 'impressed', 'created', 'aweber', 'potential', 'publishers', 'feeel', 'loool', 'lenchen', 'thu', 'msg', 'betttchhh', 'suspense', 'dental', 'yesterdays', 'anna', 'xoxo', 'heaven', 'summertime', 'kimyew', 'offline', \"she'll\", 'newborn', 'indonesia', 'earliest', 'traveling', 'hollies', 'lcwiabd', 'spencer', 'past', 'flesh', 'tone', 'beard', 'creeps', 'fergilicious', 'sassy', 'joint', 'agian', 'cepet', 'sembuh', 'nggak', 'usah', 'terus', 'idyllic', 'pregnant', 'sleeps', 'sneek', 'bahah', 'lex', 'gooo', 'engine', 'kissing', 'distinguish', 'picking', 'vietnam', 'grandpa', 'army', 'kristoffer', 'plays', 'tricks', 'rite', 'crack', 'porcelan', 'unfixable', 'beast', 'laser', 'tagging', 'number', 'filming', 'halfway', 'miracle', 'pamona', 'nikki', 'joana', 'carls', 'portobello', 'mate', 'emily', 'sweatpants', 'comfy', 'sweatshirt', 'chanklas', 'drea', 'millionaire', 'received', 'ascot', 'necktie', 'stunning', 'etsy', 'char', \"daddy's\", 'noticing', 'kudos', 'broz', 'fyi', 'inquired', '#bhb', 'immediately', 'book---and', 'reach', 'yesss', 'wbu', 'prob', 'oracle', 'owns', 'database', 'conan', '1/2', \"mine's\", 'bio', 'interviewin', 'nicoley', 'hallelujah', 'renee', 'anf', 'kris', 'graduations', 'cards', 'hoops', 'yoyo', 'israel', 'replacement', 'yessir', 'boat', 'joys', 'parenthood', 'interpretations', ';-)', 'offering', 'blowin', 'buildin', 'oven', 'frank', 'zappa', 'stevie', 'basketball', 'laters', 'labyo', 'cha', 'drums', 'frosties', 'soft', 'centre', 'knackers', 'okaying', '@followfriday', 'bonfire', \"s'mores\", 'ohio', 'uncle', 'casi', 'jeez', 'parties', 'clean', 'semangat', 'berangkat', 'kerja', 'bus', 'anger', 'managements', 'ego', 'setting', 'schedule', 'washin', 'clothes', 'relaxin', 'makin', 'moves', 'length', 'trish', 'stratus', 'liked', 'stacy', 'keibler', 'lean', 'ile', 'anticipating', 'quality', \"grey's\", 'supper', 'twitters', 'degrees', 'pool', 'extended', 'chill', 'saved', 'ryan', 'cabrera', 'yes-he', 'decent', 'career', 'drawers', 'riding', 'ladies', 'bible', 'stumbled', 'fighting', 'captured', 'mushy', \"how's\", 'caffeine', 'drape', 'towel', 'mid-section', 'sydney', 'youy', 'singer', 'hannah', 'montana', 'innocent', 'jpeg', 'easily', 'friendster', 'ill', 'unedited', 'brushed', 'teeth', 'max', 'botox', 'entertaining', 'angels', \"everything's\", 'playlist', 'favourite', 'paranoid', 'electricity', 'bet', 'flat', 'ski', 'survive', 'boots', 'telford', 'recommended', 't-shirt', 'tan', 'son', 'contemplating', 'sim', 'john', 'ginormous', 'alabama', 'university', 'takin', 'padre', 'plants', 'heads', 'bylaurenluke', 'calling', 'butts', \"kids'll\", 'stalking', 'vin', 'famous', 'hmnnn', 'refering', 'george', 'harrison', '#musicmonday', 'awol', 'initiative', 'space', 'mabs', 'bees', 'wohooo', 'twiend', 'itll', 'hokey', 'pokey', 'flashlight', 'slippers', 'striven', 'perfection', 'lettt', 'shine', 'suuunn', 'iiinn', 'wot', 'wondered', '22nd', 'dofe', 'expedition', 'snowdonia', 'wooha', 'hiking', 'youngest', 'swim', 'diary', 'tyler', 'purdy', 'jap', 'raw', 'blah', 'defo', 'agrees', 'beth', 'ditto', 'soup', 'cupcakes', 'chels', 'hundred', 'sixty', 'hundreds', 'hailey', 'failure', 'pursuit', 'izzz', 'realist', 'wrote', 'cheer', 'gal', 'feline', 'discovered', 'reader', 'newb', 'duty', 'warfare', 'announced', 'yelling', 'nascar', 'races', 'pugman', 'riddles', 'annie', 'russ', \"arby's\", 'allow', 'intelligence', 'minimal', 'bruising', 'arms', 'barrier', 'albums', 'goiing', 'cockstain', 'denise', 'rocks', 'quotes', '70-75', 'yah', 'bud', 'windy', 'sby', 'malah', 'hujan', 'deres', 'chillin', 'bake', 'utter', 'disappointment', '2.30', '96fm.com.au', 'station', 'unless', 'robbie', 'williams', 'jessica', 'simpson', 'foxysmile', \"danny's\", 'idf', 'sis', 'becuz', 'kept', 'massive', 'brilliant', 'muffins', 'tgif', 'looses', 'meaning', 'cuddling', 'comfortable', 'walked', 'alun-alun', 'magazines', 'sale', 'sucky', 'refill', 'minute', 'mayb', 'frwy', 'baker', 'dno', 'bwt', 'vamps', 'existed', 'dracula', 'memorized', 'blessed', 'roadbike', 'twitlove', 'southern', 'german', 'tipsy', 'saiyan', 'sayanggg', 'yahh', 'dearest', 'jumping', 'jacks', '101', 'gainesville', \"ea's\", 'command', 'conquer', 'alert', 'pre', 'racing', 'model', 'dye', 'appliedd', 'relationship', 'stoke', 'relatively', 'saga', 'wen', 'address', 'adipavi', 'lounging', 'fear', 'loathing', 'las', 'vega', 'possitive', 'weekends', 'method', 'nuts', '1,000', '000', 'mid', 'september', 'spoiled', 'toys', 'willing', 'saab', 'pasta', 'tri-tip', 'dutton', 'goldfield', 'zin', 'morelli', 'lane', 'illustrating', 'existance', 'lewis', 'mama', 'ini', 'amwezome', 'hump', 'shinning', 'downloading', 'tracks', 'excatly', 'tht', 'shouldnt', 'exsist', 'okaiee', 'thoughtt', 'ahaha', 'charm', 'meatballs', 'brekky', 'spaghetti', 'studied', 'seven', 'pounds', 'street', 'parade', 'kallio', 'kukkii', 'imp', 'rio', 'papagaio', 'streets', '#fixreply', 'drove', 'sunrise', 'cafe', 'monde', 'stroll', 'quarter', 'cheaper', 'geez', 'tannin', 'release', 'lvoe', 'tweeples', 'retail', 'therapy', 'hardcore', 'developer', 'asp.net', 'whisky', 'torino', 'abit', 'swift', 'rays', 'excuse', 'mall', 'theriot', 'homered', 'geeking', 'wave', 'presentation', 'amused', 'initech', 'example', 'organisation', 'oooh', 'blacks', 'furnished', 'rent', 'perkins', 'freshly', 'hashed', 'ducklings', 'spelling', 'sob', 'cracks', 'snapshots', 'messages', \"that'd\", \"andrew's\", 'cutie', 'orchestra', 'ellen', 'social', 'networks', 'sweetie', 'explode', 'pageant', 'worry.we', 'septum', 'united', 'portrait', 'preordered', 'contributing', 'soulful-steem', 'futurismic', 'giants', 't.g.i.fridays', 'thus', 'deciding', 'print', 'haters', 'scotland', 'confident', ':o)', 'skins', 'netbooks', 'dreamt', 'mike', 'brekkie', 'honestly', 'orgasm', 'gotcha', 'amex', 'godin', 'useful', 'comparison', 'iam', 'fauxhawk', 'pony-tail', 'kindle', 'hooo', '4am', 'viet', 'hips', 'bum', 'nerds', 'droool', 'thanx', 'michaelson', 'msu', '7:00', 'decadent', 'ooh', 'excitement', 'aaa', 'mag', 'marina', 'souarna', 'donate', 'sundaes', 'burgers', 'yields', 'dairy', 'queen', 'alternatives', 'googling', 'indianapolis', 'chasters', 'babybaby', 'alyssa', 'immitate', 'delicious', 'commercial', 'perfectly', 'hollywood', 'hop', 'beddd', 'swag', 'ooonnn', 'aladin', 'heunisch', 'pussy', '5yr', 'fussy', 'sometines', 'autism', \"brian's\", 'vino', 'chose'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tommorow', 'nightmares', \"who's\", 'omg', 'volleyball', 'fewer', 'plane', 'murphy', 'taf', 'bean', 'cedric', 'investigated', 'picross', 'productivity', 'biz', 'semi', 'rumours', 'excitement', 'talkative', 'teu', 'upload', 'without', 'suggestions', 'swap', 'guys', 'name', 'strap', 'atleast', 'naked', 'hee', \"melo's\", 'stalker', 'thankiesss', 'potential', 'upcoming', 'april', 'hates', 'dat', \"drew's\", 'puppets', 'twitterville', 'muffins', 'monsters', 'weather', 'context', 'wakes', 'fatz', 'room', 'beby', 'autism', 'log', 'unraveling', 'krugman', 'audience', 'ben', 'perhaps', 'belated', 'tree', 'browsing', 'overcast', 'pencil', 'relaized', 'ngerti', 'balloons', 'launcher', 'discuss', 'vega', 'din', 'lettt', 'asheville', 'interval', 'raining', 'morelli', 'interest', 'following', 'personal', 'interacting', 'lewis', 'hugs', 'p60', 'dogs', 'abandoned', 'fyi', 'ahh', 'burning', 'cruise', 'dahlin', 'montserrat', 'achievement', 'season', 'send', 'error', 'press', 'snap', 'fit', 'checking', 'comment', 'sweatpants', 'youngest', 'subway', 'agrees', 'terrible', 'dads', 'theater', 'delicious', 'ani', 'puppy', 'driveway', 'l0ve', 'wooo', 'waiting', 'usah', 'misfortune', 'kris', 'diarrhea', 'backtell', 'hooo', 'jogging', 'cookies', 'sometimes', 'nokia', 'old', 'jon', 'tell', 'iron', 'married', 'millionaire', 'piff', 'follow', 'interviewin', 'every', 'total', 'especially', 'schoool', 'hello', 'ran', 'wag', 'bed', 'ronald', \"mother's\", 'proper', 'blessed', '2.30', 'baby', 'hang', 'rule', 'bruv', 'done', 'people', 'surgery', 'tagging', 'else', 'uno', 'view', 'cuts', 'emergency', 'last.fm', 'brightonians', 'uncle', 'crap', 'que', 'imagine', 'netbooks', 'dpd', 'call', 'comcast', 'bird', 'agree', '000', 'noo', 'taken', 'question', 'spoiled', 'bedtimeee', 'broke', 'thurs-sun', 'coloured', 'reality', 'themostawesomepromever', 'sept', 'apps', 'england', 'creeps', 'likes', 'niece', 'quick', 'lip', 'wee', 'bahah', 'famous', 'usual', 'angry', 'prettyy', 'debating', 'assuming', 'kilala', 'preordered', 'hop', 'hiking', 'prob', 'playstation', 'park', 'wondering', 'rocket', '#ilove', 'belongs', 'ride', 'romania', 'heating', 'dennis', 'watch', 'found', 'implied', 'septum', 'wage', 'ooo', 'bloated', 'gurgaon', 'eclipse', 'marina', 'tummys', 'fab', 'sites', 'heck', 'pamona', 'lame', 'pok', 'hiccups', 'nicoley', 'blazing', 'kick', 'except', 'east', 'update', 'cracking', 'server', 'locations', 'exhausted', 'powder', 'hornby', 'talks', 'images', 'bro', 'australia', 'anytime', 'traffic', 'beautiful', 'manager', 'staff', 'six', 'fed', 'anticipating', 'kukkii', 'asking', 'rollercoaster', 'bees', 'speech', 'generation', 'order', 'aghh', 'house', 'churchhh', 'turned', '500', 'terrific', 'nervous', 'weitz', 'alabama', 'webinar', 'suncream', '272', 'lautner', 'twitterberry', 'awful', \"bestfriend's\", 'hahah', 'weds', 'todayy', 'energy', 'fruits', 'playlist', 'michaelson', 'atlantic', 'rings', 'wainting', 'saddd', 'grumpsus', 'halfway', 'soo', 'ipod', 'mas', 'shining', 'wat', 'recommendation', 'charging', 'juat', 'bang', 'intend', 'standard', 'ohhh', 'noticing', 'something', 'men', 'devo', 'end', 'endless', 'trish', 'baker', 'influence', 'froofroo', 'twiiter', 'team', 'account', 'episode', 'business', 'screamed', 'mariners', 'joining', 'mile', 'table', 'douchebag', 'till', 'rides', 'sometime', 'meant', '#fail', '#newmoon', 'course', 'entering', 'miley', 'appreciated', 'threw', 'idris', '22nd', \"l's\", 'great', 'dynamically', 'users', 'guess', 'teamed', 'plan', 'example', 'yarns', 'ile', 'hal', 'cameo', 'ima', \"avi's\", 'arsed', 'woo', 'pasta', 'getting', 'kid', 'cat', 'heeey', 'del', 'craving', 'kmt', 'jeez', 'needs', 'despite', 'nowww', 'songs', 'transit', 'butts', 'honestly', 'stock', 'lolz', 'char', 'week', 'poles', 'heunisch', 'sing', 'worrying', '7th', 'becuz', 'download', 'option', 'don', 'gimme', 'car', 'ugh', 'failing', '#mtv', 'sequel', 'china', 'runny', 'cupcake', 'ended', 'lunchtime', 'katty', 'hardcore', 'state', 'american', 'birds', 'geordie', '200.00', 'buena', 'tasty', 'drea', 'buy', 'unbareable', 'unfixable', 'signal', 'carls', 'ooohhh', 'outside', 'theres', 'pit', 'wear', 'finished', 'terus', 'peanut', 'smells', 'brought', 'sungguh', 'spencer', 'hoops', 'kiss', 'kimyew', 'bein', 'needed', 'allergic', 'tracks', 'thu', 'seem', 'sleepy', 'www.tweeterfollow.com', 'investment', 'moms', 'okaying', 'introduction', 'jees', 'raket', 'drop', \"nintendo's\", 'kat', 'kahit', 'sawyer', 'studied', 'aches', 'insomnia', 'diana', 'looses', 'shuffles', 'address', 'worth', 'millions', 'cheese', 'survive', 'fay', 'ugly', 'bau', 'daniel', 'kill', 'honest', 'apathetic', 'somebody', 'shows', 'altho', 'spit', 'driving', 'xoxo', 'poodle', 'pissed', 'ide', 'weekend', 'blues', 'take', 'borrow', 'yea', 'database', 'films', 'toast', 'switched', 'leaves', 'salt', 'nestly', 'access', 'serious', 'roof', 'tossing', 'ooonnn', 'badly', 'since', 'dofe', 'shirt', 'ears', 'time-lapse', 'schedule', 'kettle', 'philly', 'entertaining', 'cold', 'whats', 'volcano', '#canterbury', 'internet', 'computer', '...  ..', 'multimedia', 'large', 'told', 'whole', 'highlight', 'wreck', 'israel', 'wknd', 'hiks', 'twitters', 'body-hugging', '1700.00', 'tnt', 'vin', 'multiple', 'funny', 'george', 'betta', 'depends', 'reading', 'ads', 'hannah', 'muir', 'gona', 'knackered', 'simpson', 'mike', 'accts', 'symptoms', 'support', 'mcfly', 'sims', 'greeaattt', 'jks', 'sanie', 'low', 'corndogs', 'brussels', 'thinned', 'sweetcorn', 'dumb', 'thinking', 'thx', 'chick', 'longest', 'flatbed', 'miles', 'couldve', 'aloud', 'pleeease', 'others', 'bummish', 'everyone', 'dont', 'breakfast', 'sneezing', 'spammer', 'wakin', 'iiinn', '#smtb', 'market', '#maxis', 'hump', 'omfg', 'yields', 'incredibally', 'flight', 'talked', 'mario', 'greater', 'steven', 'barrier', 'lol', 'deve', '1981', 'austin', 'gig', 'brb', 'howz', 'hurting', 'social', 'navy', 'ham', 'frank', 'gross', 'started', 'budget', 'in-laws', 'purnus', 'loathing', 'sched', 'channel', 'either', 'dateng', 'queen', 'icon', 'safari', 'regular', 'choc', 'lemonade', 'face', 'parents', 'planner', 'swoll', 'songz', 'clue', 'pedal', 'migraine', 'riddles', 'must', 'pretty', 'logs', 'ldrs', 'procrastinating', 'unpack', 'besides', 'appreciate', 'fear', 'uni', 'stranger', 'pair', 'message', 'davy', 'friendster', 'tom', 'enjoying', 'pirates', 'twittering', 'pumping', 'sleepin', 'gmn', 'bartha', 'buddy', 'tokio', 'hopes', \"matt's\", 'first', 'britans', 'mix', 'nerds', 'often', 'purdy', 'night', 'dresses', 'dislike', 'deli', 'life', 'laging', 'damn', 'tan', 'hour', 'los', 'method', 'skillz', 'variety', 'borin', 'sack', 'trip', 'please', 'pfff', 'spotlight', 'makes', 'knew', 'addy', 'ruin', 'burnt', 'zagreb', 'awww', 'innocent', 'boi', 'mini', 'stand', 'believe', 'catching', 'seems', 'reason', 'whoops', 'mtv', 'grizzly', 'scratched', 'pageant', 'horribly', 'archangel', 'wind', 'direct', 'creation', 'bags', 'intelligence', 'nearly', 'slat', 'beat', 'hateful', 'rockin', 'photos', 'pasti', 'sundance', 'continues', 'ignore', 'actual', 'help', 'ropes', 'friend', 'indianapolis', 'naw', 'mind', 'may', 'enviciate', 'syrian', 'pish', 'bitchin', 'stephenie', 'word', '2.5', 'serial', 'intl', 'discount', 'tireddd', 'miracle', 'add-ons', 'marie', 'lvoe', 'outsides', 'waltzers', 'metallic', 'stiff', 'cinta', 'premiere', 'contract', 'awebo', 'sell', 'grim', 'pontiac', 'lying', 'helps', 'ppl', 'atlanta', 'wishing', 'ojdl', 'model', 'hehe', 'drive', 'crush', 'bathe', 'worries', 'm-a', 'animal', 'foxtel', 'asp.net', 'nggak', 'early', '#sony', 'went', 'accumulate', 'emotional', 'fellow', 'stretch', 'possible', 'travels', 'dope', 'mentioned', 'mmm', 'youtube', 'leicester', 'showing', 'popping', 'tokin', 'always', 'nail', 'birthday', 'nuffin', 'paid', 'remember', 'mid-section', 'grrr', 'magazines', 'donut', 'prepare', 'packers', 'blagh', 'mornings', 'possibly', 'bowling', 'colour', 'babybaby', 'tickets', '800msp', 'song', 'fanatics', 'hardest', 'ribs', 'mornin', '50sqm', 'happens', 'bear', 'tucks', 'hilton', '1:1', 'hokey', 'settings', 'brothers', 'pushing', 'career', 'world', 'families', 'idf', \"emma's\", 'ive', 'sober', 'zin', 'msg', 'classes', 'making', 'harrison', 'well-being', 'gloom', 'eggs', 'fake', 'udate', 'zone', 'forgot', 'diego', 'passed', 'gotten', 'comfy', 'licence', 'mid', 'ridge', '15th', 'lung', 'revenge', 'days', 'flew', 'save', 'plagiarised', 'here', 'whut', 'changes', 'slippers', 't.g.i.fridays', 'shaun', 'dhira', 'mcdonalds', 'ethan', 'prayers', 'ask', 'dot', 'nap', 'widget', 'outdoors', 'grossed', 'informed', 'pkwy', 'plese', 'cream', 'uber', 'jeremy', 'offering', 'california', 'battle', 'committed', 'midler', 'adorable', 'mental', 'over.whats', 'flying', 'bria', 'watching', 't-shirt', 'fave', 'heart', 'white', 'soul', 'nya', 'stuck', 'role', 'mend', 'service', 'kyle', 'detox', 'suspense', 'refill', 'pee', 'blocked', 'pop', 'gateway', 'per', 'overdraft', 'excuse', 'msu', 'wont', 'howdy', 'abis', 'tri-tip', 'downloadingnow', 'center', 'aching', 'refund', 'mummehh', 'finishing', 'grow', 'trouble', 'hysterical', 'mwah', 'havent', 'zulu', 'multi', 'kick-off', 'brown', 'drama', 'mac', 'sadd', 'sundae', 'morning', 'supposed', 'contact', 'already', 'row', 'ekka', 'orchid', 'viola', 'round', \"shannon's\", 'haruhi', 'hacker', 'care', 'michelleyys', 'bak', '270/10', 'agian', 'restore', 'shitty', 'hooked', 'it', 'protocol', 'yeh', 'watchinn', 'illustrating', 'sounds', '5yr', \"we're\", 'somewhere', '2nd', 'esta', 'gooodniite', 'leader', 'insane', 'slip', 'finding', 'birth', 'issues', 'el-oh-el', 'stumbled', 'trinda', 'jesus', 'wine', 'pictures', 'luck', 'pussy', 'afan', 'melted', 'supper', 'jackson', 'officialjobros', 'separate', 'russia', 'loneeelllyyy', 'keeping', 'socks', 'tennis', 'quarantined', 'nefertiti', 'huge', 'nfight', 'self', 'hope', 'final', ';-)', 'nigh', 'deserves', 'nutmeg', 'coke', 'faith', 'clever', 'throw', 'iam', 'gangster', 'salad', 'heading', 'going', 'heff', 'part', 'performance', 'colors', 'cheats', 'idiots', 'grand', 'orgasm', 'coughy', 'gear', 'useful', 'shops', 'winks', 'padre', 'plastic', 'lips', 'wot', 'micro', 'efforts', 'canadian', 'queens', '360', 'asap', 'botox', 'journo', 'ever', 'miss', 'hmm', '830', 'pancakes', 'august', 'membership', 'stevie', 'souarna', 'push', 'emoticons', 'basic', 'dry', 'laughed', 'evan', 'emily', \"o'clock\", 'arms', 'wash', \"would've\", 'bio', \"they've\", 'duty', 'complaining', 'bark', 'wristcutters', 'kutner', 'nazis', 'warfare', 'phone', 'however', 'giveaways', 'chance', 'ending', 'carma', 'attic', 'lollies', 'suitcase', 'keurig', 'newmediaguy', 'tangan', 'urself', 'visit', \"team's\", '11.25', 'liquor', 'iran', 'bots', 'mag', 'celebrating', 'closed', 'photo', 'horrid', 'verla', 'wake-up', 'illegal', 'peggy', 'earlier', 'pleaseee', 'walking', 'besties', 'bunches', 'santorini', 'dracula', 'cycle', 'revision', 'ngerjain', 'sakit', 'checked', \"disney's\", 'design', 'cullens', \"cat's\", 'mum', 'fast', 'fuck', 'perfect', 'bone', 'excited', 'little', 'understanding', 'telly', 'realised', 'gal', 'water', 'fault', 'qualli', 'god', 'considered', 'ring', 'whos', 'related', 'goldfield', 'walkin', 'tryna', 'downtown', 'pria', 'awol', 'mom', 'puyeng', 'bday', 'dayy', 'melissa', 'guinness', 'missin', 'pili', 'wbu', 'sadly', 'celeb', 'cheesy', 'attention', 'haircut', 'piss', 'peaceful', 'sir', 'influenced', 'loose', '5647560', 'sebelah', 'anti-breakage', 'umm', 'need', 'use', 'snagged', 'engineering', 'announced', 'attractive', 'brillance', 'impact', 'broken', 'book', 'worst', 'gods', 'becoming', 'point', 'resigning', 'headache', 'fine', 'ankles', 'thats', 'homggg', 'surprise', 'giants', 'woken', 'passing', 'hayfever', 'beats', 'years', 'fuckin', 'stash', 'heyyy', 'bringin', 'title', 'imp', 'beach', 'seth', 'mieser', 'loves', 'suuunn', 'union', 'eugh', 'julia', \"s'mores\", '#pawpawty', 'moment', 'company', 'blacks', 'aaah', 'algebra', 'edge', 'boyzone', 'wasted', 'dearest', 'eff', 'daddy', 'delete', 'picnic', 'rite', 'fan', 'catch', 'skys', 'twilight', 'read', 'scones', 'lax', 'interesting', 'rusty', 'stay', '83.50', 'doin', 'crosse', \"she'll\", 'cyrus', 'bodies', 'pizza', 'suicide', 'repeat', 'aka', 'non-attendance', 'shake', \"grey's\", 'wiso', 'writes', 'wrote', 'glasgow', 'models', 'vidzone', '#edtech', 'pool', 'threes', 'disheartening', 'ihop', 'hummer', 'sippin', 'des', 'anung', 'chillis', 'saga', 'min', 'sifr', 'chose', 'hangovers', 'neckache', 'gave', 'walked', 'tailgaiting', 'tina', 'feelin', 'ignorant', 'magwito', 'hahaha', 'drugs', 'noes', 'embarrassment', 'jca', 'launch', 'polariod', '2pm', 'remy', 'mia', '#format', 'loll', 'harder', 'tim', 'rebel', 'veggies', 'blue', 'backache', 'foot', 'wanna', 'tho', 'chortle', 'moves', 'mabs', 'quarantine', 'perfumes', 'sox', 'unfortunately', 'jobros', 'isnt', 'third', 'james', 'safe', 'willl', 'sonya', 'disappointment', 'magpies', 'page', 'dairy', 'national', 'vino', 'tommy', 'feline', 'dead', 'kudos', 'gray', '5.5', 'uplifter', 'actions', 'shy', 'woodlands', 'downstairs', 'sadness', 'bottom', 'aminn', 'words', 'hundreds', 'mild', 'grumpy', 'rly', 'rdy', 'drawers', 'step', 'incidents', 'coming', 'practice', 'hapuslah', 'updates', 'thaaanks', 'fun', 'oops', 'dentist', 'footlong', 'rockz', 'neck', 'monday', 'laughin', 'windy', 'texted', 'bar', 'month', 'graduations', 'pulled', 'umbrellas', 'reconized', 'backlog', 'cha', 'knackers', 'bus', 'recommended', 'plurk', \"ev'd\", 'ventura', 'start', 'motorcycle', 'sob', 'pre', 'laundry', 'crowded', 'burny', 'p45', 'urrgh', \"lautner's\", 'hup', 'nene', 'almost', 'resort', 'bruising', 'danny', 'backed', 'skirts', 'publix', 'race', 'starin', 'wher', 'nope', 'tgif', 'unfollow', 'nothin', 'yer', 'zappa', 'presentation', 'cabrera', 'no1', \"y'all\", 'bnc', 'immediately', '. . .', 'exercising', \"kid's\", 'sending', 'auntie', '#noundiessunday', 'exsist', 'isolated', 'killing', 'boyle', 'sucking', 'treasure', 'organisation', 'possibility', 'couple', 'modem', 'section', 'cancels', 'geek', 'swag', 'resulted', 'school', 'economy', 'babies', 'source', 'hospital', 'exact', 'links', 'useless', \"best's\", 'speed', 'materials', 'tan.com/skincaner', 'official', 'washed', 'another', 'hotter', 'headaches', 'bedtime', 'bad', 'chosen', 'play', 'aidan', 'holidays', 'recommend', 'september', 'pokey', 'charlie', 'hoo', 'wings', 'lately', 'sunbath', 'striven', 'highly', \"cook's\", 'sassy', 'promotion', 'cuddling', 'windows', 'guidance', 'talent', 'romance', 'four', 'betttchhh', 'pounds', 'iya', 'yofruit', 'interested', 'accidently', '195bucks', 'debbie', 'sneek', 'friday', 'wii-tastic', \"what'cha\", 'speaks', 'homepage', \"kids'll\", 'hips', 'fair', 'born', 'basket', 'southside', 'ghirardelli', 'police', 'spanish', '#jquery', 'email', 'live', 'add', 'pain', 'spend', 'case', 'alex', 'toronto', 'grad', 'advise', 'webber', 'spell', 'basis', 'rexy', 'immitate', 'bloggers', 'dent', \"kate's\", 'fav', 'snoring', 'cleaning', 'gossip', 'different', 'obviously', 'realize', 'wales', 'son', 'dee', 'kaison', 'crampsss', 'important', 'interseting', 'googled', 'taylah', 'acting', 'bike', 'greeting', 'refering', 'grandpa', 'wonderful', 'bored', 'ages', 'feel', 'cramping', 'beard', 'cheer', 'safely', 'amazing', 'communication', \":'(\", 'can.have', 'seven', 'conclusion', 'everytime', 'looked', 'terrestrial', 'competitive', \"father's\", 'child', 'nothing', 'der', 'euro', 'working', 'cry', '3-1', '698', 'customised', 'ovr', 'twilighters', 'meal', 'seeing', 'bonded', 'nearby', 'transformation', 'loads', 'demi', 'busan', 'awesome', 'lagged', 'meat', '#text', 'cherry', 'solidified', 'immer', 'tyler', 'scorpions', 'mains', 'promise', 'thunderstorm', 'heaptweets', 'anymore', 'oooh', 'animation', 'slim', 'stephen', 'expensive', 'gas', 'stamina', 'cleaned', 'bills', 'buildin', 'zoo', 'west', 'freaky', 'sale', 'serve', 'hurray', 'sweatshirt', \"pj's\", 'soon', 'croatia', 'twitterers', 'studio', 'yesterday', '.  ...', 'mothers', 'skool', 'stoked', 'k-cups', 'pleasure', 'cockstain', 'gainesville', 'teacher', 'able', 'amazon', 'facing', 'eng', 'worn', 'attribute', 'setting', 'reply', 'wedding', 'best', 'hawwwtt', 'orders', 'owns', 'pleasant', 'limit', 'geez', 'captured', 'frm', 'happened', 'lush', 'freedom', 'hear', 'spammed', \"let's\", \"that'd\", 'comes', 'woooa', 'man', 'thumb', 'jen', 'missing', 'loss', 'psaz', 'peter', 'pus', 'tried', 'actually', 'saiyan', 'love', 'kindly', 'shampoos', 'teryn', 'giveaway', 'indoors', 'human', 'pawty', 'nadrei', 'building', 'ducklings', 'command', 'sucks', \"ea's\", 'massive', 'mann', 'beast', 'screenshots', 'wifi', 'leyton', 'win', 'southern', 'german', 'trawl', 'careless', 'level', 'info', 'made', 'pimp', 'score', 'ere', 'things', 'sun', 'shall', 'saturday', 'bloody', 'yeaaa', 'adipavi', 'retarded', 'wtf-is-your-problem-feed-me', 'raw', 'dark', 'incredible', 'cepet', 'nebraska', 'lalala', 'casi', 'connection', 'friends', 'jumping', 'link', 'block', 'boat', 'charge-up', 'glade', 'tmrw', 'davids', 'flail', 'gf11', 'suffer', 'coisa', 'zomg', 'stewards', 'grandma', \"he's\", 'ideas', 'butterflies', 'text-based', 'film', 'horrible', 'ways', 'commute', 'thoughon', 'cord', 'goes', 'hut', 'izzz', 'tilt-shift', 'vietnam', 'quoting', 'khols', 'comeon', 'say', 'kaki', 'hallelujah', 'username', 'free', 'taking', 'glares', 'www.netpierre.nl', 'coreplayer', 'fans', 'twiends', 'clear', 'banging', 'yayayayay', 'waste', 'habit', 'goose', 'ryan', 'short', 'lamb', 'explode', '250', 'montana', 'joshua', 'characters', 'training', 'heh', 'mostly', 'daisies', 'theriot', 'rofl', 'wimbledonul', 'moving', 'worry', 'doubt', 'clients', \"we've\", 'unorganised', 'sleeps', 'reviewing', 'fmlfmlfml', 'wonderfulness', 'fattening', 'misunderstood', 'currently', 'albums', 'anger', 'difficulty', 'cuevas', 'tooted', 'canning', 'abit', 'twitlove', 'thread', 'spy', 'ansted', 'saved', 'ski', 'screen', 'fall', 'conversations', 'rage', 'eurovision', 'mama', 'ready', 'earn', 'gah', 'bill', 'weekends', 'tomorrowww', 'playstation', \"dvd's\", 'makan', 'australian', 'bay', 'keep', 'fathers', 'resting', 'nuts', 'away', 'cos', 'age', 'sweetheart', 'reformat', 'frustrated', 'dock', 'exceptionally', 'rio', 'sind', 'peruse', 'note', 'tragic', 'mayer', 'russ', 'extended', 'aim', 'chilling', 'congrat', \"steve's\", 'stealing', 'fully', 'cup', 'pleease', 'hidden', 'infamous', \"nothing's\", 'graceful', 'rules', 'flat', 'policy', 'instead', 'grab', 'lovin', 'mollyd', 'coaching', 'difference', 'doctor', 'videogames', 'dmb', 'php', 'britain', 'pepper', 'dreams', \"t'was\", 'largely', 'ma', 'cared', 'cheap', 'sleeeppp', 'dude', '#musicmonday', 'snack', 'hehehe', 'andrew', 're-launch', 'beginning', 'splashed', 'bugger', 'homework', 'peruvian', 'region', \"could've\", 'orange', 'last', 'shower', 'fuzzball', 'online', 'yah', 'hard', 'day', 'plotting', 'appliedd', 'messages', 'minggu', 'possitive', 'propozitii', 'getty', 'local', 'thinks', 'jus', 'feels', 'chata', 'personality', 'lot', 'svu', 'cracks', 'fletcher', 'scottish', 'iabm', 'counting', 'centre', 'rock', 'sigh', 'average', 'misses', 'could', 'site', 'lmfaoo', 'costume', 'hardheaded', '20th', 'release', 'tuesday', 'notes', 'year', 'goodnighttt', 'breathe', 'snugglin', 'grind', 'shot', 'comedy', 'goinggg', 'tastes', 'arent', 'trending', 'shouldnt', 'hangover', 'tweets', 'plays', 'jacks', 'loh', 'unsatisfied', 'sugar', 'on-air', 'netune', 'rubber', 'beyond', 'costumes', 'moneyyy', 'thingz', 'click', 'officially', 'stickers', 'sleep', 'weird', 'glittery', 'boogie', 'aaron', 'wen', 'wythville', 'lightheaded', 'onion', 'snow', 'managed', \"that's\", 'puli', 'decadent', 'hospitalized', \"tv's\", '3000', 'blog', 'fancy', 'discontinue', 'tasted', 'hands', 'chillin', 'cutted', 'yelping', 'ace', 'points', '6th', \"i'd\", 'totally', 'fallout', 'gothic', 'lay', 'managements', 'mysteries', 'charm', 'way', 'easy', 'yet', 'side', 'turn', 'susan', '21st', 'preakness', 'wii', 'comments', 'hiss', 'rare', 'huddersfield', 'hollies', 'given', 'huuurts', 'coward', 'bath', '3rd', 'orchestra', 'fmlaptop', 'parade', 'hopefully', 'ill', 'slept', 'types', 'outfit', 'whisky', 'upset', 'exams', 'asia', 'hold', 'lie', 'sangat', 'joys', 'hook', 'dye', '#plain', 'samsung', 'hunt', 'fullest', 'organizing', 'nxt', 'crack', 'sixty', 'scratch', 'dyeing', 'accidents', 'delayed', 'alas', 'pony-tail', 'futurismic', 'yumm', 'braces', 'easliy', 'drunkenness', 'comfirmation', 'wanted', 'program', 'homework-time', \"we'd\", 'family', 'vol', 'club', 'hate', 'allowing', 'band-aids', 'mother', 'hiddedn', 'wuss', 'ass', 'www.uniqlo.com/calendar/', 'statistic', 'rejecting', 'raining.and', 'sydney', 'coffee', 'mksdnya', 'snaps', 'hug', 'john', 'chicken', 'food', 'clicked', 'heartbroken', 'biog', 'girl', 'sdk', 'attached', 'geeking', 'unfair', 'impressed', 'mistake', 'chicago', 'godly', 'beauty', 'bing', 'sometines', 'overwhelmed', 'tennessee', 'kak', 'hid', 'mary', 'hashed', 'universe', 'along', 'google', 'bet', 'europe', 'bailed', 'sch', 'assessment', 'xslt', 'introducing', 'bwt', 'paying', 'greek', 'term', 'hitting', 'freshly', 'learn', 'colognes', \"friend's\", '#bhb', 'chem', 'cake', 'idiotic', 'skies', 'replay', 'okay', 'movement', 'rays', 'central', 'major', 'rats', 'profile', 'obama', 'tumblr', 'towel', 'searching', 'wacked', 'long', 'muzza', 'lives', 'colleages', 'france', 'mommie', 'portrait', 'hair', 'sam', 'woot', 'trey', 'oct', 'favourite', 'settin', 'triangle', 'signing', 'oven', 'thought', 'japan', 'wooot', 'photography', 'fm3', 'yelling', 'hilll', 'shinning', 'said', 'ago', 'suppose', 'butterfly', 'rain', 'joop', 'pms', 'ooh', 'bosses', 'connected', 'blah', 'tweeples', 'flavor', 'idiot', 'breaks', 'chelsea', 'health', 'malm', 'banff', 'beg', 'exclusive', 'lady', 'lex', 'straight', 'memorized', 'yep', 'losing', 'riley', 'somehow', 'smoother', 'lenchen', 'sound', 'beer', 'infect', 'cuttin', 'waited', \"can't\", 'reallly', 'tradus', 'sumtimes', 'hammersmith', 'careful', 'philippines', 'finger', 'las', 'peace', 'essay', 'reeks', 'south', 'brunch', \"they'd\", 'suntuk', 'homered', 'confusing', 'mufffins', 'letters', '#followfriday', 'mechanic', \"car's\", 'covered', 'rate', 'depressed', 'yawn-groan-snapcracklepop', 'ball', 'somerville', 'ketek', 'hrs', 'aber', 'siick', 'pink', 'fix', 'tea', 'less', 'fairly', 'hangin', 'suggest', '#jeffstreet', 'come', 'afternoon', 'htown', 'utilities', 'laugh', 'heirlooms', 'discussion', 'recording', 'cloud', '11am', 'caffeine', 'hestite', 'cute', 'kept', 'pana', 'sniffs', 'eat', 'burn', 'flesh', 'weekly', 'invites', 'later', 'holy', 'video', 'cursed', 'cancellation', 'racing', 'want', 'normal', 'putt-putt', 'sharing', 'realist', 'guee', 'walker', '4days', 'forcing', '10.5', 'thru', 'dutton', 'ingredients', 'soup', 'facebook', 'supervision', 'beth', 'everybody', 'pts', 'kareoke', 'reno', 'amwezome', 'involved', 'hungarian', 'bersama', 'strip', 'resize', 'starting', '#iloveyou', 'sold', 'swine', 'interveiws', 'conflicts', 'saying', 'bangin', 'fuckers', 'emails', 'melody', 'congrats', 'overtired', 'brilliant', 'smell', 'young', 'gran', '#twittertakeover', 'migrate', 'screwed', 'visited', 'ladies', 'fries', 'future', 'depressing', 'persistence', 'prom', 'willing', 'happening', 'dans', 'speak', 'deciding', 'alun-alun', 'baka', 'struggling', 'knock', 'stress', 'bout', 'drink', 'advance', 'ruining', 'battery', 'jealous', 'pugman', 'place', 'turning', 'oil', 'bummed', '#gmail', 'im-el-im', 'saw', 'meeting', 'gtuu', \"maiya's\", 'jetlagg', '89.1', 'measham', 'rent', 'pursuit', '#bntm', 'expecting', 'ouch', 'organs', 'milder', \"nikki's\", 'opportunities', 'bands', 'joana', 't-shirts', 'product', \"we'll\", 'masterpieces', 'simple', 'monde', 'mode-working', 'shoot', 'wants', 'roll', 'yup', 'cds', 'berangkat', 'problem', 'cus', 'jim', 'library', 'pops', 'zander', 'kerry', 'pilot', 'kitty', '#mtogo', 'tylenol', 'couldnt', 'entire', 'romana', 'bitch', 'aaw', 'church', 'canny', 'cocoa', 'lcwiabd', 'conquer', 'gotta', 'attack', 'tomorrows', 'heartbreaking', 'glad', 'change', 'nikki', 'might', 'keys', 'confident', 'ginormous', 'mood', 'nibble', 'played', 'lana', 'deal', 'everything', 'annoying', 'lasagna', 'canberra', 'loved', 'vicinity', 'promising', 'washin', 'pots', 'hotel', 'battlefield', \"what's\", 'rainy', 'yummy', 'utterly', 'walk', 'dreading', 'fauxhawk', 'viewing', 'money', 'office', 'ridiculous', 'airport', 'variations', 'affect', 'chair', 'cloudy', 'bertepuk', 'ftl', 'sayanggg', 'waterfront', '#tad', 'air', 'fresh', 'dno', 'angelus', 'meatballs', 'hey', 'bum', 'thorn', 'brekky', 'washing', 'malah', 'midnight', \"name's\", 'activity', 'hills', 'waking', 'ini', 'hahahaha', 'shift', 'meets', 'shook', 'speaking', 'starbucks', 'pune', 'anything', 'definately', 'excatly', \"mine's\", 'graduated', 'nine', 'trapped', 'clean', 'drinks', 'til', 'downloading', 'card', 'mosquitoes', 'understand', 'make', 'tokyo', 'bust', 'rublev', 'alreadyyy', 'university', 'enjoy', 'argentina', 'ellen', 'flag', 'donate', 'flu', 'programs', 'strength', 'hanging', 'stuff', 'star', 'modern', 'barack', 'legger', 'guitar', 'second', 'blocking', 'vet', 'neglected', \"daddy's\", \"here's\", 'okaiee', 'submitted', 'jason', 'applied', 'googling', 'lloyd', 'sadface', 'nightmare', 'kristoffer', 'comparison', 'yellow', 'arabic', 'credit', 'lonley', 'probably', 'tweeting', 'system', 'onto', 'adrenaline', 'gates', 'lil', 'medical', 'berbaloi', 'eventually', 'waterbug', 'trying', 'decide', 'avoiding', 'scrolly', 'climb', 'flower', 'telford', 'akon', 'refuse', 'mush', 'written', 'sunshine', 'sickies', 'invited', '2night', 'potatoes', 'culinary', 'teeth', 'dissed', '9:22', \"today's\", 'lovey', 'punk', 'sns', 'fam', 'father-in-law', 'months', 'bumbed', 'delay', 'secondary', 'paper', 'vacation', 'rice', 'marathon', 'wld', 'illinois', 'downer', 'snorers', 'rafael', 'chill', 'dog', 'cant', '2morow', 'mentioning', 'annabelle', 'haha', 'followers', 'yeeeaaahhh', 'apologise', 'babe', 'clothes', 'box', 'seniors', 'canada', 'hiding', 'workin', 'brain', 'killer', 'enjoyed', 'means', 'david', 'customization', 'gon', '2:30', 'falling', 'guy', 'backyard', 'busy', 'durin', 'minute', 'dang', 'alert', 'died', 'times', 'talk', 'paperwork', 'rec', 'yum', 'opening', 'nick', 'airlines', 'output', 'takin', 'frogs', 'definitely', 'board', 'airmata', 'wait', 'laser', \"d'aw\", 'boards', 'jonas', 'discrete', 'distinguish', 'tweet', 'productive', 'english', 'hiatus', '2day', 'soulful-steem', 'crazy', 'thakyou', 'knowing', 'leggers', 'scotland', 'behind', 'thisss', \"brandon's\", 'foolery', 'gym', 'mega', 'studying', 'paranoid', 'hungry', 'drunk', 'random', 'indeed', 'indo', 'finish', '447', 'ginger', 'lozenges', 'bud', 'eloise', 'finallay', 'shine', '228', 'kind', 'arm', 'graphic', 'pup', 'desist', 'tires', 'quiet', 'heheheheh', 'ale', 'gentle', 'max', 'would', 'microsoft', 'tonight', '#fixreply', '#rpattz', 'traveling', '1,000', 'nobody', 'worried', 'grills', 'wheel', 'vote', 'widad', 'blackmailed', 'website', 'legs', 'elana', 'ser', 'sby', 'doesnt', 'emo', 'wasnt', 'taste', 'boots', 'forever', \"arby's\", 'physical', 'real', 'cure', 'uploading', 'dropping', 'hell', 'uhhh', 'space', 'feet', 'now.lost', '#clothdiapers', 'spizzle', 'janes', 'unprecedented', 'lane', 'idk', \"where's\", 'plugin', 'hmmm', 'living', 'corrected', 'emptied', 'one', 'frog', 'adored', 'disappointed', 'fuckkk', 'mileey', 'restricted', 'shee', 'lmfao', 'masterpages', 'time', 'functioning', 'boring', 'deine', 'stumped', 'korea', 'hundred', 'eyes', 'mad', 'eaten', 'touched', 'nickkkjonasss', 'disconnected', 'classy', 'thank', 'didnt', 'brightening', 'pick', 'brian', 'current', 'cool', 'enter', 'thursday', 'twittersphere', 'print', 'pounding', 'ability', \"honey's\", 'desire', 'modeling', 'household', 'wolverine', \"summer's\", 'gorgeous', '1pm', 'itching', 'veinte', 'tone', 'minimal', 'open', 'slow', 'language', 'vanilla', 'ridiculously', 'plans', 'sis', 'app-by-app', 'robin', 'chels', 'ikea', 'penguins', 'impossible', 'matters', 'game', 'fat', \"tom's\", 'bound', 'reagan', '#rich', 'smoking', 'dyin', 'climbing', 'eyes.cuz', 'maria', 'mexico', 'caliwas', 'wwaaahhh', 'green', 'wrong', 'crackers', 'lazy', 'sky', 'phil', 'bejamin', 'news', \"baby's\", 'bull', 'uhhmm', 'decent', 'fudge', 'remain', '4dogz', '2hear', 'high', 'por', 'crying', 'comfortable', 'subject', 'minus', 'manng', 'champions', 'transformers', 'relatively', 'woods', 'also', 'u21', 'though', 'drape', 'aint', '#amazeballs', 'juicy', 'glorious', 'senses', 'shame', 'castle', 'joint', 'lobsters', 'taylor', '#lvatt', 'howard', 'agenda', 'grabbing', 'bleh', 'quite', 'anticlimatic', 'nicht', 'layton', 'hand', 'follower', 'wonder', 'giving', 'nose', 'egg', 'await', 'thins', 'loveee', 'dwnld', 'quakelive', 'gymnasium', 'requested', 'unless', \"updating-can't\", 'came', 'brazilian', 'three', 'kallio', 'form', 'biatches', 'dammit', 'sayaw', 'jerrys', 'arrrgh', 'quake', 'someone', 'darling', 'yall', 'skools', 'outloud', 'idea', 'professor', 'helen', 'depended', 'graduation', 'engine', 'curious', 'london', 'iphone', 'swimteam', 'stratus', 'gutted', 'piece', 'towers', 'noise', 'dealing', 'fridayyy', 'momma', 'playing', '#literalvideos', 'tweetpeeps', 'give', '100', 'covers', 'prevent', 'gene', 'replacement', 'quarter', 'roger', 'tears', 'whitby', 'modules', 'bootcamp', 'move', 'true', 'wellington', \"brian's\", 'left', 'leave', 'possum', 'mailbox', 'capture', 'break', 'united', 'scene', 'bloodwork', 'fire', 'leaving', 'neil', 'hahahahhahaha', 'cooks', 'unlikely', 'jolt', 'options', 'past', 'gettin', 'cutest', 'goood', \"dr's\", 'itunes', 'wohooo', 'spin', 'big', 'machine', 'visiteach', 'community', 'saaad', 'caring', 'owning', 'via', 'took', 'memories', 'amex', 'verizon', 'lipstick', 'street', 'unmotivated', 'ascot', '#oldnavyweekly', 'plugging', 'ie6update', 'swear', 'places', 'sat', 'goin', 'anyway', 'everything-is-alright', 'twitpic', 'bucks', 'actors', 'asleep', 'regret', 'viet', 'dancing', 'streets', 'pile', \"nyt's\", \"ya'll\", 'stopped', 'interior', 'abby', 'porcelan', 'publishers', 'bgirl', 'brekkie', 'functionality', 'war', 'watchin', 'sub', 'knw', 'realise', 'pooped', 'debate', '. .', 'twins', 'incher', 'alyssa', 'payday', 'smile', 'reminder', 'f0r', 'ammo', 'one-on-one', 'foxysmile', 'tanta', 'solo', 'grey', 'continental', 'genre', 'fish', 'build', 'awsome', 'needle', 'dane', \"g'morning\", 'stop', 'stupid', 'couples', 'srs', 'trucks', 'alive', 'work', 'far', 'vistoso', 'tongue', 'selling', '2hours', 'informing', 'beautifully', 'mall', 'starvin', 'knows', 'teens', 'hustle', 'crickets', '96fm.com.au', 'sway', 'umbrella', 'number', 'al-queda', 'scott', 'japanese', 'positive', 'rather', 'nickname', 'kerrang', 'contemplating', 'quizzes', 'shudder', 'lovers', 'failure', 'cand', 'ate', 'reach', 'picture', 'camera', 'moon', 'boston', 'running', 'sweet', 'chasters', 'pics', 'knights', 'hearing', 'turns', 'blows', 'coughing', 'duno', 'sunrise', '730', 'yesterdays', 'particular', 'teasing', 'pens', 'ringtones', 'choir', 'brew', 'terry', 'nurse', 'personally', 'butt', 'ummm', 'mbxes', 'code', 'nyc', 'camp', 'right', 'technical', 'taco', 'offline', 'crappy', \"twitter's\", 'shooting', 'sans', 'itll', 'ohno', 'maths', 'deer', 'resolved', 'using', 'lived', 'respect', 'thinkin', 'jazz', 'metra', 'ants', 'eminem', 'picked', 'sandwich', 'rapido', 'cafe', 'conan', 'oracle', 'thus', 'bye', 'drew', 'italian', 'erg', 'flipsides', 'web', 'kml', 'anf', 'evening', 'least', 'accent', 'dirty', 'takes', 'conference', 'kinda', 'mii', 'feeel', 'anywhere', \"danny's\", 'soulmate', 'mon', 'initiate', \"how's\", 'daily', 'yess', 'pint', 'wake', 'scout', 'dreaming', 'hurts', 'buttons', 'stunning', 'pie', 'indonesia', 'bae', 'dreamt', 'nite', 'xoxoxo', 'temple', 'twits', 'happy', 'version', 'woke', 'toys', 'dnt', 'aiyo', 'absolutely', 'tapas', \"i'msoo\", 'including', 'apartment', 'yay', 'happen', 'bottle', 'hurt', 'radio', 'sooo', 'danicng', 'viitoare', 'sawry', 'wow', 'coolest', 'talking', 'hubby', 'initech', 'gota', '1/2', 'worse', 'xxx', 'asexual', 'plus', 'keen', 'scenery', 'csi', 'awake', 'newborn', 'lossless', 'die', 'benedict', 'preparing', 'congratulations', 'exciting', 'ting', \"u're\", 'havnt', 'kan', 'felt', 'videos', 'dedication', 'concerned', 'called', 'cut', 'dancer', \"everything's\", 'infection', 'redmond', 'meyer', 'flaxseed', \"main-that's\", 'renee', 'goddesses', 'hoping', 'ocean', 'trips', 'laptops', 'outta', 'present', 'sunday', 'intercept', 'listening', 'funnystyle', 'stockton', 'bought', 'barn', 'beasides', 'nottingham', 'tutor', 'alone', 'tip', 'demand', 'machines', 'lobster', 'corner', 'fucked', '311', 'greenflies', 'cheers', 'kicked', 'twiend', 'got', 'teach', 'across', 'coolio', 'tub', 'gurl', 'grounded', \"rem's\", 'stood', 'content', 'ink', 'flabbergasted', 'lash', 'dropped', 'bomb', 'ramp', 'tomoro', 'thoughtt', 'ohio', 'full', 'vip', 'wishes', 'pricing', 'hmnnn', 'godin', 'iono', 'pff', 'close', 'gosh', 'schweizer', 'america', 'letting', 'memory', 'global', 'madd', 'rush', '70-75', 'maoam', 'sunburn', 'back', 'frwy', 'inside', 'cutie', 'boy', 'names', 'helping', 'appear', 'isa', 'telling', 'assume', 'mistakes', 'cancelled', 'wheels', 'grumbling', 'caught', 'show.songs', 'benihana', 'neighbor', 'data', 'showings', 'anna', 'sim', 'everyday', 'hacks', 'lack', 'puppies', 'burgers', 'yessir', 'spot', 'books', 'minutes', 'passengers', 'hats', 'problems', 'decided', 'stronger', 'flavia', 'lovvve', 'prices', 'pinball', 'oldschool', 'forget', 'sore', 'home', \"aunt's\", \"i'm\", 'farewell', 'kymora', 'nba', 'nights', 'poohey', 'specially', 'fail', 'derby', 'writing', 'feverish', 'funeral', 'scare', 'fallen', 'success', 'chellez', 'posts', 'sorry', 'trailer', 'deserve', 'heyy', 'africans', 'wounded', 'nah', 'defo', 'vidoes', 'tweeps', 'interpretations', 'mojo', 'eye', 'wit', 'ngga', 'necktie', 'centrelink', 'answer', 'trees', 'killed', 'luv', '@bakytn', 'spare', 'webical', 'swim', 'holiday', 'laying', 'chicken-pox', 'red', 'carradine', '#jmaps', 'ewww', 'road', 'furnished', 'july', 'manila', 'connect', 'ahead', 'kobe', 'stolen', 'station', 'incident', 'padahal', 'portable', 'small', 'apparently', 'football', 'graduating', 'youy', 'yoyo', 'philbert', 'palm', 'nadal', 'welcome', 'boo', \"in't\", 'ash', 't000', 'shop', 'degrees', 'party', 'disney', 'boxing', 'appt', 'intensive', 'swimming', 'intimidating', 'hullooo', 'wud', 'fisnih', 'dental', 'mane', 'networks', 'yes-he', 'lucozade', 'someones', 'run', 'sarah', 'expression', \"it'll\", 'fridays', 'plz', 'tillie', 'extend', 'dooo', 'painkillers', 'shattered', 'beethoven', 'gone', 'comic', 'contest', 'aplication', 'walmart', 'minimize', 'alton', 'miserable', 'ohh', 'wish', 'smelling', 'piano', 'loser', 'north', 'scenes', 'perfectly', \"brewer's\", 'ezine', 'newark', 'twitterland', 'perkins', 'planning', 'lump', 'bumblebee', 'rift', 'freaking', 'laptop', 'remembering', 'fired', 'earring', 'research', 'thursdays', 'jpeg', \"rob's\", 'dovey', 'mclachlan', 'kmhd', 'host', 'bauer', 'rough', 'screams', 'next', 'papagaio', 'sweetie', 'starving', 'denise', 'whether', 'stroll', 'bylaurenluke', '24hrs', 'lagi', 'fot', 'riding', 'knit', 'wood', 'land', \"mofo's\", 'comedyqueen', 'chase', 'movie', 'pan', 'freddie', 'music', 'shut', 'parties', 'booked', 'bermuda', 'cover', 'dryh', 'chat', 'wong', 'memorial', 'tessa', 'like', 'death', 'arm-paint', 'steps', 'visual', 'eating', 'calling', 'singer', 'ddude', 'tips', 'body', 'bun', 'favorite', 'slamming', 'experience', 'loaded', 'turtle', 'sweater', 'attempt', 'thre', 'finland', 'combination', 'finally', 'carrasco', 'luckkky', 'viva', 'sushi', 'winning', 'skyped', 'nelson', 'orlando', 'looking', 'pay', 'secret', 'dunnut', 'drinkin', 'map', 'watched', 'purse', 'manga', 'andas', 'goona', 'everything-is-alright-and-viv-will-be-fine', 'michigan', 'strong', 'throat', 'science', 'bruno', 'quality', 'improve', 'api', 'fergilicious', 'share', 'anybody', 'bake', 'goingto', 'toll', 'mins', 'requires', 'organiser', 'ono', '10.4', 'blast', 'exactly', 'kindle', 'basically', 'says', 'crisps', 'ice', 'anthem', \"tmail'in\", 'black', '400', 'length', 'vortex', 'never', 'compare', 'relaxin', 'hit', 'sobombtictic', 'sad', 'perfection', 'melina', 'train', '08:22', 'mail', 'fixed', 'husband', 'ish', 'smiley', 'drawing', 'nice', 'baseball', 'rip', 'brugger', 'ones', 'get', 'christmas', 'musica', 'weak', 'stalking', 'pic', 'sign', 'ego', 'util', 'drinking', 'bathroom', 'cause', 'today', 'commercials', 'hay', 'duck', 'kinds', 'expected', 'finals', 'many', 'cease', 'snapshots', 'cannot', 'truly', 'scary', 'oclock', 'etc', 'etsy', 'cards', 'hollywood', 'anyone', 'ssup', '@followfriday', 'stream', 'look', 'smoke', 'lahh', 'haa', 'hste', 'icecream', 'apa', 'archie', 'cramps', 'unusual', 'krissy', 'bittersweet', 'wave', 'wembley', 'counts', \"c'mon\", 'sux', 'passenger', 'dinner', 'luvin', \"they're\", 'heads', 'summertime', 'listens', 'symphony', 'album', 'aladin', 'due', 'complain', 'youre', 'polite', 'sense', 'incepe', 'messin', 'agreed', 'secretly', 'winmo', 'cousin', 'tootoo__much', 'ship', 'jump', 'wife', 'light', 'adore', 'angeles', 'background', 'trek', 'potluck', 'meaning', 'paintballing', 'growing', 'matter', 'rest', 'spring', 'wednesday', 'yeaaauh', 'mushy', 'goodnight', 'lake', 'fewww', 'put', 'summer', 'series', 'vinegar', 'reminds', 'goodies', '360idev', 'gay', 'livin', 'show', 'discovered', \"mmva's\", 'microbiology', 'awe', 'crash', 'commercial', 'maybe', 'renew', 'kissing', 'dash', 'ding', '6am', 'craziest', 'goal', 'oldest', 'lycan', 'dad', 'attempted', 'gaaay', 'pro', 'conmigo', 'voice', 'mtk', 'belgrade', 'sucky', 'yayy', 'shoes', '11.15', 'saab', 'treat', 'captive', 'tannin', 'brett', 'tweetie', 'alright', '140', 't_t', 'non-plastic', 'ana', 'soundtrack', 'sorted', 'yuck', 'organised', 'offers', 'heavy', 'acho', 'truth', '2ma', 'snowdonia', 'packing', 'psycho', \"wife's\", 'civil', 'new', 'better', 'rugged', 'stitch', 'twice', 'girlie', 'picturesss', 'assembly', '2moz', 'stomach', 'ahah', 'juice', 'peste', 'owner', 'bette', 'greece', 'quotes', 'popped', 'bribe', 'older', 'iughhh', 'yesss', 'exam', 'btw', 'oomph', 'doobie', '3100', 'cried', 'piiissed', 'mosquito', 'concert', 'lond', \"there's\", 'whilst', 'boss', 'poor', 'bronx', 'roommate', 'endere', 'warm', 'bag', 'reminding', 'rude', 'aweber', 'corn', 'kissed', 'loool', 'pristine', 'teenagers', 'fell', 'applications', 'oooppps', 'thanx', 'fandom', 'joe', '6-1', 'yeah', 'available', 'sehari', 'infecting', 'set', 'ditto', 'ticket', 'archive', 'keibler', 'backround', 'bubbly', 'project', 'existed', 'wounds', 'successful', 'lunching', 'client', 'flipping', 'nicely', 'conserve', 'convincingly', 'states', '9pm', 'expedition', 'joy', 'skits', 'apple', 'wore', 'forward', 'become', 'marrying', 'children', 'fucking', 'thanks', 'outlook', 'june', 'expect', 'skins', 'accoint', 'loving', 'naww', 'shojo', 'torino', 'public', 'bible', 'learned', 'nazi', 'profs', 'nascar', 'tomorrow.but', 'seen', 'write', 'try', 'bershopping', 'forreal', 'anyways', 'although', 'tis', 'fussy', 'addicted', 'wesche', 'awards', 'thankfully', 'rejects', 'wet', 'login', 'feeling', 'gmtv', 'sry', 'arghhh', 'prizes', 'works', 'rescheduled', 'sundaes', 'material', 'ohm', 'scared', 'jut', 'hahahahahah', 'www.journeykenya.com', 'created', 'verse', 'customer', 'coding', 'class', '1st', 'boot', 'biggest', 'frustrating', 'former', 'bryony', 'parenthood', 'races', 'kids', 'kitchen', 'liner', 'parked', 'pollen', 'realy', 'bright', 'serato', 'prolly', 'fashion', 'dear', 'makeup', 'otherwise', 'bestie', 'calls', 'cmt', 'arrived', 'blowin', 'confused', 'epic', 'article', 'ashley', 'frosties', 'invigorating', 'doped', 'goooddd', 'install', 'really', 'alternatives', 'taxi', 'utter', 'prefer', 'kerja', 'stud', 'plants', 'let', 'paul', 'book---and', 'positivity', 'tru', 'superrr', 'clay', 'cheaper', 'entries', 'allow', 'bentley', 'andrews', 'sick', 'brushed', '97.4', 'makin', 't-mobile', 'moines', 'filming', 'poly', 'lucky', 'exist', 'nerd', 'germany', 'b-day', 'chris', 'homee', 'babysit', 'hacer', 'power', 'wudd', 'certain', 'around', 'used', 'evryone', 'whopping', 'hola', 'clouds', 'tonite', 'envy', 'oneon', 'thoroughly', 'diary', 'vamps', 'artist', 'toes', 'diet', 'tact', 'mean', 'inquired', 'yippie', 'olds', 'devoured', 'duhh', 'patience', 'eachother', 'wears', 'lal', 'cell', 'dood', \"ain't\", 'bbq', 'carolina', 'pregnancy', 'rich', 'received', 'asked', 'noticed', 'lunch', 'hummm', 'usually', 'near', 'reinstall', 'directions', 'lang', 'tricks', 'college', 'record', 'worry.we', 'sharyn', 'barrafina', 'kitten', 'hurry', 'cotton', 'toget', 'myspace', 'head', 'shud', 'hairdresser', \"#that'snothowexpenseswork\", 'naturaly', 'fatal', '194', '#newnews24', 'brazil', '#umbraco', 'penguin', 'tweet-up', 'basta', 'issue', 'noe', 'jap', '1080', 'warmed', 'bummer', 'travel', 'story', 'wakey', 'christ', 'jacket', 'sends', 'gooo', 'good', 'mate', 'sister', 'meet', 'retail', 'thoughts', 'two', 'media', 'rise', 'wes', 'uying', 'drums', 'fiends', 'cook', 'wishin', 'thing', 'spending', 'person', 'seriously', '<sob>', 'wooha', 'storms', 'afraid', 'single', 'fever', 'brasiliansnya', 'keeps', 'kks', 'dream', 'iloveyou', 'streaming', 'lost', 'laaame', 'spent', 'wheat', 'belinda', 'announcements', 'argh', 'gotcha', 'tired', 'roadbike', 'snarky', 'sree', 'labyo', 'session', 'hideous', 'dond', 'loverly', \"andrew's\", 'posted', 'winds', 'o_o', 'mayb', 'lonely', 'linux', 'lean', 'hun', 'ten', \"sammy's\", 'together', 'failed', 'visiting', 'cuz', 'suspend', 'earliest', 'youd', 'nom', 'loveme', 'okey', 'easily', 'dudes', 'miami', 'petal', 'women', 'net', 'opportunity', 'mine', '#apple', 'seat', 'customers', 'foo', 'strange', 'prepearing', 'post', 'fml', 'dozen', 'missed', 'phne', 'sure', 'forgotten', '#readathon', '101', 'hike', 'fantastic', 'bunch', 'annie', 'rendering', 'twitter', 'winged', 'heeelp', 'doiin', 'jessica', 'auto', 'forest', '12th', 'pass', 'find', 'extremely', 'metro', 'iamculture', 'grandmother', 'theme', 'drank', 'think', 'atm', 'tht', 'melbs', 'patio', 'noraniza', 'bell', 'yeesss', 'lounging', 'angels', 'half', 'sih', 'forgive', 'mark', 'liked', 'heartworm', 'beddd', 'awning', 'flashlight', 'font', 'date', 'adding', 'bustin', 'lovely', 'lyrics', 'kangen', 'lemon', '#music', 'named', '#acen', 'mais', 'tym', ':o)', 'see', 'chocolate', 'cine', 'sex', 'museum', 'fingerrs', 'sisters', 'existance', 'napper', 'ngl', 'shit', 'job', '640x480', 'zigatos', 'hujan', 'phones', 'dance', 'carriers', 'atl', 'kentut', 'hiz', 'hablaaame', 'serve-volleying', 'window', \"kaulitz's\", 'huh', 'broz', 'ncis', '1gb', 'swift', 'store', 'semangat', 'hours', \"tonight's\", 'excellent', 'warming', 'doc', 'study', 'outa', 'wondered', 'lookout', 'luckyyy', 'williams', 'relationship', 'lmao', 'waitress', 'sit', 'robbie', 'spaghetti', 'murderer', 'grandads', 'original', 'empty', '7:00', 'cooking', 'heard', 'popcorn', 'much', 'xbox', 'princess', 'fireworks', 'whoah', 'previous', 'payment', '1057', 'dbz', 'scaredi', 'still', 'changed', 'emv', 'bit', 'heaps', 'wtf', 'lots', 'sembuh', 'deres', 'singin', 'incentive', 'sudden', 'portobello', 'flooding', 'aww', 'aaa', 'layering', 'figure', 'electric', 'search', 'humidity', \"they'll\", 'headed', 'girls', 'stacy', 'tweeted', 'www.auntychristine.etsy.com', 'seas', 'duminica', 'sea', 'calendar', 'dougs', 'hint', 'initiative', 'list', 'chanklas', 'looks', 'sitting', 'concerts', 'snapping', 'mukas', 'jeans', 'listen', 'skip', 'effects', 'toss', 'bali', 'silly', 'nih', 'super', 'jet', 'nicest', 'winking', 'suck', \"i'll\", 'risk', 'tweeties', 'brother', 'town', 'slightly', 'keeper', 'partying', 'mighty', 'secrets', '#probeard', 'lvatt', 'text', 'amused', 'worriess', 'uhm', 'legal', 'comp', 'singing', 'hailey', 'special', 'coz', 'akron', 'replies', 'dodgy', 'choking', 'heaven', 'cooked', 'wearing', 'ystrdy', '1130z', 'tune', 'reliving', '1994', 'tipsy', 'cracker', 'brownie', 'late', 'italiannn', 'seventh', 'newb', 'nails', 'liking', 'san', 'saturdays', 'jack', 'unedited', 'spelling', 'smiled', 'kmhd.fm', 'soe', 'ordered', 'tattooed', 'test', 'tomorrow', 'sin', 'cuddle', 'legend', 'pointless', 'yahh', 'know', 'mommy', 'unlucky', 'yes', 'calms', 'lan', 'nudge', 'hot', 'wokr', 'esp', 'well', 'movies', 'orientation', 'dying', 'sunny', 'enough', 'stick', \"i've\", 'female', 'deserved', 'fighting', 'vai', 'check', 'laters', 'blackberry', 'developer', 'ton', 'restarting', 'controls', 'cupcakes', 'lens', 'shopaholic', '#iphone', \"dad's\", 'shipping', 'students', 'basketball', 'redicously', 'stoopid', 'valley', 'bring', 'dress', 'scurried', 'baner', 'cinnamon', 'thunder', 'join', 'ahhh', 'oversized', 'gonna', 'contributing', 'owen', 'ajax', 'staying', 'frozen', 'fellas', 'celebrate', 'rated', 'blood', 'app', 'bobby', 'therapy', 'mbp', 'army', \"cousin's\", 'pregnant', 'nooo', 'blessing', 'vaseline', 'freshener', 'reader', 'door', 'even', 'apt', 'lets', 'met', 'thxs', 'breasts', 'soft', 'tattoos', 'idyllic', 'spreading', 'bothered', 'pet', 'gets', 'sexy', 'goiing', 'tweeters', 'finale', 'thunderstorms', 'haters', 'droool', 'verve', 'boys', 'garage', '4am', 'reminded', 'picking', 'kelly', 'repost', 'aussie', 'top', 'preparation', 'ahha', 'drove', 'ahaha', 'area', 'screw', 'bonfire', '10pm', 'electricity', 'coast', 'inappropriate', 'rocks', 'stoke', 'impression', 'sleeping', 'active', 'doctors', 'shopping', 'mess', 'inch'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Information Gain to test only Best Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Movie Review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet downloads the most popular datasets for experimenting with NLTK functionalities.\n",
    "import nltk\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_classifier(feats):\n",
    "    # Get the negative reviews for movies    \n",
    "    negids = movie_reviews.fileids('neg')\n",
    "\n",
    "    # Get the positive reviews for movies\n",
    "    posids = movie_reviews.fileids('pos')\n",
    "\n",
    "    # Find the features that most correspond to negative reviews    \n",
    "    negfeats = [(feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "\n",
    "    # Find the features that most correspond to positive reviews\n",
    "    posfeats = [(feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "    # We would only use 1500 instances to train on. The quarter of the reviews left is for testing purposes.\n",
    "    negcutoff = int(len(negfeats)*3/4)\n",
    "    poscutoff = int(len(posfeats)*3/4)\n",
    "\n",
    "    # Construct the training dataset containing 50% positive reviews and 50% negative reviews\n",
    "    trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "\n",
    "    # Construct the negative dataset containing 50% positive reviews and 50% negative reviews\n",
    "    testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "\n",
    "    print ('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    "\n",
    "    # Train a NaiveBayesClassifier\n",
    "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "\n",
    "    for i, (feats, label) in enumerate(testfeats):\n",
    "            refsets[label].add(i)\n",
    "            observed = classifier.classify(feats)\n",
    "            testsets[observed].add(i)\n",
    "\n",
    "    print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "    print ('pos precision:', precision(refsets['pos'], testsets['pos']))\n",
    "    print ('pos recall:', recall(refsets['pos'], testsets['pos']))\n",
    "    print ('neg precision:', precision(refsets['neg'], testsets['neg']))\n",
    "    print ('neg recall:', recall(refsets['neg'], testsets['neg']))\n",
    "    classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Word Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that extracts which words exist in a text based on a list of words to which we compare.\n",
    "def word_feats(words):\n",
    "        return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('evaluating single word features')\n",
    "eval_classifier(word_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Word Features using Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_fd = FreqDist()\n",
    "label_word_fd = ConditionalFreqDist()\n",
    " \n",
    "for word in movie_reviews.words(categories=['pos']):\n",
    "    word_fd[word.lower()] += 1\n",
    "    label_word_fd['pos'][word.lower()] += 1\n",
    " \n",
    "for word in movie_reviews.words(categories=['neg']):\n",
    "    word_fd[word.lower()] += 1\n",
    "    label_word_fd['neg'][word.lower()] += 1\n",
    " \n",
    "pos_word_count = label_word_fd['pos'].N()\n",
    "neg_word_count = label_word_fd['neg'].N()\n",
    "total_word_count = pos_word_count + neg_word_count\n",
    " \n",
    "word_scores = {}\n",
    " \n",
    "for word, freq in word_fd.items():\n",
    "    pos_score = BigramAssocMeasures.chi_sq(label_word_fd['pos'][word],\n",
    "        (freq, pos_word_count), total_word_count)\n",
    "    neg_score = BigramAssocMeasures.chi_sq(label_word_fd['neg'][word],\n",
    "        (freq, neg_word_count), total_word_count)\n",
    "    word_scores[word] = pos_score + neg_score\n",
    " \n",
    "best = sorted(word_scores.items(), key=lambda s: s[1], reverse=True)[:10000]\n",
    "bestwords = set([w for w, s in best])\n",
    " \n",
    "def best_word_feats(words):\n",
    "    return dict([(word, True) for word in words if word in bestwords])\n",
    " \n",
    "print ('evaluating best word features')\n",
    "eval_classifier(best_word_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MovieDataModel on Twitter Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('train on %d instances, test on %d instances' % (len(trainfeats), len(twitter_test_set)))\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, twitter_test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
