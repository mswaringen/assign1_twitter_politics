{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "* Import and preprocess Assignment Data\n",
    "* Import and preprocess Labeled Twitter Data\n",
    "* Split/train/test Labeled Twitter data model\n",
    "* Split/train/test Movie Review data model\n",
    "* Compare results of both models on Labeled Twitter data Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import html.parser as HTMLParser# In Python 3.4+ import html \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>full_location</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 10:04:02 +0000 2016</td>\n",
       "      <td>@BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...</td>\n",
       "      <td>en</td>\n",
       "      <td>Baton Rouge, LA</td>\n",
       "      <td>United States</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Aug 12 10:04:30 +0000 2016</td>\n",
       "      <td>#CNN #newday clear #Trump deliberately throwin...</td>\n",
       "      <td>en</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>United States</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Aug 12 10:04:46 +0000 2016</td>\n",
       "      <td>@realDonaldTrump, you wouldn't recognize a lie...</td>\n",
       "      <td>en</td>\n",
       "      <td>Palm Springs, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Aug 12 10:04:48 +0000 2016</td>\n",
       "      <td>\"Kid, you know, suing someone? Thats the most ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Secaucus, NJ</td>\n",
       "      <td>United States</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Aug 12 10:04:48 +0000 2016</td>\n",
       "      <td>@HillaryClinton you ARE the co-founder of ISIS...</td>\n",
       "      <td>en</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>United States</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Fri Aug 12 10:04:02 +0000 2016   \n",
       "1  Fri Aug 12 10:04:30 +0000 2016   \n",
       "2  Fri Aug 12 10:04:46 +0000 2016   \n",
       "3  Fri Aug 12 10:04:48 +0000 2016   \n",
       "4  Fri Aug 12 10:04:48 +0000 2016   \n",
       "\n",
       "                                                text lang     full_location  \\\n",
       "0  @BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...   en   Baton Rouge, LA   \n",
       "1  #CNN #newday clear #Trump deliberately throwin...   en     Baltimore, MD   \n",
       "2  @realDonaldTrump, you wouldn't recognize a lie...   en  Palm Springs, CA   \n",
       "3  \"Kid, you know, suing someone? Thats the most ...   en      Secaucus, NJ   \n",
       "4  @HillaryClinton you ARE the co-founder of ISIS...   en        Irving, TX   \n",
       "\n",
       "         country state  \n",
       "0  United States    LA  \n",
       "1  United States    MD  \n",
       "2  United States    CA  \n",
       "3  United States    NJ  \n",
       "4  United States    TX  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_feather('data/tweets_by_state.feather')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[[0]]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract then Remove Hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# A function that extracts the hyperlinks from the tweet's content.\n",
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''\n",
    "\n",
    "# A function that removes the hyperlink and tokenizes the text\n",
    "def clean_text(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match: \n",
    "        result = re.sub(r\"http\\S+\", \"\", text)\n",
    "        return tokenizer.tokenize(result.lower())\n",
    "    return tokenizer.tokenize(text.lower())\n",
    "\n",
    "# A function that checks whether a word is included in the tweet's content\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_tokens'] = tweets['text'].apply(lambda tweet: clean_text(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>full_location</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>link</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 10:04:02 +0000 2016</td>\n",
       "      <td>@BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...</td>\n",
       "      <td>en</td>\n",
       "      <td>Baton Rouge, LA</td>\n",
       "      <td>United States</td>\n",
       "      <td>LA</td>\n",
       "      <td>https://t.co/5GMNZq40V3</td>\n",
       "      <td>[barackobama, fbi, lorettalynch, all, in, coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Aug 12 10:04:30 +0000 2016</td>\n",
       "      <td>#CNN #newday clear #Trump deliberately throwin...</td>\n",
       "      <td>en</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>United States</td>\n",
       "      <td>MD</td>\n",
       "      <td></td>\n",
       "      <td>[cnn, newday, clear, trump, deliberately, thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Aug 12 10:04:46 +0000 2016</td>\n",
       "      <td>@realDonaldTrump, you wouldn't recognize a lie...</td>\n",
       "      <td>en</td>\n",
       "      <td>Palm Springs, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>CA</td>\n",
       "      <td>https://t.co/pKSQM8yikm</td>\n",
       "      <td>[realdonaldtrump, you, wouldn, t, recognize, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Aug 12 10:04:48 +0000 2016</td>\n",
       "      <td>\"Kid, you know, suing someone? Thats the most ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Secaucus, NJ</td>\n",
       "      <td>United States</td>\n",
       "      <td>NJ</td>\n",
       "      <td></td>\n",
       "      <td>[kid, you, know, suing, someone, thats, the, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Aug 12 10:04:48 +0000 2016</td>\n",
       "      <td>@HillaryClinton you ARE the co-founder of ISIS...</td>\n",
       "      <td>en</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>United States</td>\n",
       "      <td>TX</td>\n",
       "      <td></td>\n",
       "      <td>[hillaryclinton, you, are, the, co, founder, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Fri Aug 12 10:04:02 +0000 2016   \n",
       "1  Fri Aug 12 10:04:30 +0000 2016   \n",
       "2  Fri Aug 12 10:04:46 +0000 2016   \n",
       "3  Fri Aug 12 10:04:48 +0000 2016   \n",
       "4  Fri Aug 12 10:04:48 +0000 2016   \n",
       "\n",
       "                                                text lang     full_location  \\\n",
       "0  @BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...   en   Baton Rouge, LA   \n",
       "1  #CNN #newday clear #Trump deliberately throwin...   en     Baltimore, MD   \n",
       "2  @realDonaldTrump, you wouldn't recognize a lie...   en  Palm Springs, CA   \n",
       "3  \"Kid, you know, suing someone? Thats the most ...   en      Secaucus, NJ   \n",
       "4  @HillaryClinton you ARE the co-founder of ISIS...   en        Irving, TX   \n",
       "\n",
       "         country state                     link  \\\n",
       "0  United States    LA  https://t.co/5GMNZq40V3   \n",
       "1  United States    MD                            \n",
       "2  United States    CA  https://t.co/pKSQM8yikm   \n",
       "3  United States    NJ                            \n",
       "4  United States    TX                            \n",
       "\n",
       "                                        clean_tokens  \n",
       "0  [barackobama, fbi, lorettalynch, all, in, coll...  \n",
       "1  [cnn, newday, clear, trump, deliberately, thro...  \n",
       "2  [realdonaldtrump, you, wouldn, t, recognize, a...  \n",
       "3  [kid, you, know, suing, someone, thats, the, m...  \n",
       "4  [hillaryclinton, you, are, the, co, founder, o...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Labeled Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets = pd.read_csv('data/raw_data/training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-1\", usecols=[0,5], names=['sentiment', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets.loc[labeled_tweets['sentiment'] == 4, 'sentiment'] = 'pos'\n",
    "labeled_tweets.loc[labeled_tweets['sentiment'] == 0, 'sentiment'] = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       neg  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       neg  is upset that he can't update his Facebook by ...\n",
       "2       neg  @Kenichan I dived many times for the ball. Man...\n",
       "3       neg    my whole body feels itchy and like its on fire \n",
       "4       neg  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>pos</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>pos</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>pos</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>pos</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>pos</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                               text\n",
       "1599995       pos  Just woke up. Having no school is the best fee...\n",
       "1599996       pos  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997       pos  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998       pos  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999       pos  happy #charitytuesday @theNSPCC @SparksCharity..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    800000\n",
       "pos    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_tweets.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "def tokenize_tweets(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match: \n",
    "        result = re.sub(r\"http\\S+\", \"\", text)\n",
    "        return tokenizer.tokenize(result.lower())\n",
    "    return tokenizer.tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets['clean_tokens'] = labeled_tweets['text'].apply(lambda tweet: tokenize_tweets(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets['clean_tokens'] = labeled_tweets['clean_tokens'].apply(lambda x: [item for item in x if item not in stops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>[-, awww, ,, that's, bummer, ., shoulda, got, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[upset, can't, update, facebook, texting, ...,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>[dived, many, times, ball, ., managed, save, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[,, behaving, ., i'm, mad, ., ?, can't, see, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text  \\\n",
       "0       neg  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1       neg  is upset that he can't update his Facebook by ...   \n",
       "2       neg  @Kenichan I dived many times for the ball. Man...   \n",
       "3       neg    my whole body feels itchy and like its on fire    \n",
       "4       neg  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                        clean_tokens  \n",
       "0  [-, awww, ,, that's, bummer, ., shoulda, got, ...  \n",
       "1  [upset, can't, update, facebook, texting, ...,...  \n",
       "2  [dived, many, times, ball, ., managed, save, 5...  \n",
       "3            [whole, body, feels, itchy, like, fire]  \n",
       "4    [,, behaving, ., i'm, mad, ., ?, can't, see, .]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (End preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['love', 'u', 'guys', 'r', 'best', '!', '!'], 'pos'),\n",
      " (['im',\n",
      "   'meeting',\n",
      "   'one',\n",
      "   'besties',\n",
      "   'tonight',\n",
      "   '!',\n",
      "   'cant',\n",
      "   'wait',\n",
      "   '!',\n",
      "   '!',\n",
      "   '-',\n",
      "   'girl',\n",
      "   'talk',\n",
      "   '!',\n",
      "   '!'],\n",
      "  'pos')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pos_tweets_df = labeled_tweets[labeled_tweets['sentiment']=='pos']\n",
    "pos_tweets = []\n",
    "\n",
    "def feat_format(token):\n",
    "    pos_tweets.append((token,'pos'))\n",
    "\n",
    "pos_tweets_df['clean_tokens'].apply(lambda token: feat_format(token))\n",
    "pprint(pos_tweets[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['-',\n",
      "   'awww',\n",
      "   ',',\n",
      "   \"that's\",\n",
      "   'bummer',\n",
      "   '.',\n",
      "   'shoulda',\n",
      "   'got',\n",
      "   'david',\n",
      "   'carr',\n",
      "   'third',\n",
      "   'day',\n",
      "   '.',\n",
      "   ';d'],\n",
      "  'neg'),\n",
      " (['upset',\n",
      "   \"can't\",\n",
      "   'update',\n",
      "   'facebook',\n",
      "   'texting',\n",
      "   '...',\n",
      "   'might',\n",
      "   'cry',\n",
      "   'result',\n",
      "   'school',\n",
      "   'today',\n",
      "   'also',\n",
      "   '.',\n",
      "   'blah',\n",
      "   '!'],\n",
      "  'neg')]\n"
     ]
    }
   ],
   "source": [
    "neg_tweets_df = labeled_tweets[labeled_tweets['sentiment']=='neg']\n",
    "neg_tweets = []\n",
    "\n",
    "def feat_format(token):\n",
    "    neg_tweets.append((token,'neg'))\n",
    "\n",
    "neg_tweets_df['clean_tokens'].apply(lambda token: feat_format(token))\n",
    "pprint(neg_tweets[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Reduce data set\n",
    "\n",
    "Accuracy improves with larger dataset, but takes exponentially more time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = pos_tweets[:int((len(pos_tweets)*0.001))]\n",
    "neg_tweets = neg_tweets[:int((len(neg_tweets)*0.001))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_tweets+neg_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract List of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the separate words in tweets\n",
    "# Input:  A list of tweets\n",
    "# Output: A list of all words in the tweets\n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "# Create a dictionary measuring word frequencies\n",
    "# Input: the list of words\n",
    "# Output: the frequency of those words apearing in tweets\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    print (\"Word frequency list created\\n\")\n",
    "    # pprint(type(wordlist))\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_features = get_word_features(get_words_in_tweets(pos_tweets + neg_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "negcutoff = int(len(neg_tweets)*3/4)\n",
    "poscutoff = int(len(pos_tweets)*3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = neg_tweets[:negcutoff] + pos_tweets[:poscutoff]\n",
    "test_tweets = neg_tweets[negcutoff:] + pos_tweets[poscutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequency list created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(train_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our features based on which tweets contain which word\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we apply the features we constructed to our tweets data.\n",
    "training_set = nltk.classify.apply_features(extract_features, train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the resulting training set shows the features we are going to pass to the classifier.\n",
    "# pprint(training_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7127"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the line of code that we use to train our classifier. Training is performed in a streamlined way so no output is visible.\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6716666666666666\n"
     ]
    }
   ],
   "source": [
    "test_set = nltk.classify.apply_features(extract_features,test_tweets)\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "           contains(sad) = True              neg : pos    =     12.4 : 1.0\n",
      "          contains(sick) = True              neg : pos    =     11.6 : 1.0\n",
      "          contains(blog) = True              pos : neg    =     10.3 : 1.0\n",
      "          contains(poor) = True              neg : pos    =      9.8 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =      9.0 : 1.0\n",
      "        contains(missed) = True              neg : pos    =      8.4 : 1.0\n",
      "          contains(woke) = True              neg : pos    =      8.3 : 1.0\n",
      "           contains(cry) = True              neg : pos    =      7.7 : 1.0\n",
      "      contains(headache) = True              neg : pos    =      7.7 : 1.0\n",
      "         contains(heard) = True              neg : pos    =      7.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Movie Review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/mark/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This snippet downloads the most popular datasets for experimenting with NLTK functionalities.\n",
    "import nltk\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "\n",
    "# A function that extracts which words exist in a text based on a list of words to which we compare.\n",
    "def word_feats(words):\n",
    "        return dict([(word, True) for word in words])\n",
    "\n",
    "# Get the negative reviews for movies    \n",
    "negids = movie_reviews.fileids('neg')\n",
    "\n",
    "# Get the positive reviews for movies\n",
    "posids = movie_reviews.fileids('pos')\n",
    " \n",
    "# Find the features that most correspond to negative reviews    \n",
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "\n",
    "# Find the features that most correspond to positive reviews\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "# We would only use 1500 instances to train on. The quarter of the reviews left is for testing purposes.\n",
    "negcutoff = int(len(negfeats)*3/4)\n",
    "poscutoff = int(len(posfeats)*3/4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1500 instances, test on 500 instances\n",
      "accuracy: 0.728\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Construct the training dataset containing 50% positive reviews and 50% negative reviews\n",
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "\n",
    "# Construct the negative dataset containing 50% positive reviews and 50% negative reviews\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "\n",
    "print ('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    "\n",
    "# Train a NaiveBayesClassifier\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "\n",
    "# Test the trained classifier and display the most informative features.\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MovieDataModel on Twitter_test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(-)': False,\n",
       "  'contains(awww)': False,\n",
       "  'contains(,)': False,\n",
       "  \"contains(that's)\": False,\n",
       "  'contains(bummer)': False,\n",
       "  'contains(.)': True,\n",
       "  'contains(shoulda)': False,\n",
       "  'contains(got)': False,\n",
       "  'contains(david)': False,\n",
       "  'contains(carr)': False,\n",
       "  'contains(third)': False,\n",
       "  'contains(day)': False,\n",
       "  'contains(;d)': False,\n",
       "  'contains(upset)': False,\n",
       "  \"contains(can't)\": False,\n",
       "  'contains(update)': False,\n",
       "  'contains(facebook)': False,\n",
       "  'contains(texting)': False,\n",
       "  'contains(...)': False,\n",
       "  'contains(might)': False,\n",
       "  'contains(cry)': False,\n",
       "  'contains(result)': False,\n",
       "  'contains(school)': False,\n",
       "  'contains(today)': False,\n",
       "  'contains(also)': False,\n",
       "  'contains(blah)': False,\n",
       "  'contains(!)': False,\n",
       "  'contains(dived)': False,\n",
       "  'contains(many)': False,\n",
       "  'contains(times)': False,\n",
       "  'contains(ball)': False,\n",
       "  'contains(managed)': False,\n",
       "  'contains(save)': False,\n",
       "  'contains(50)': False,\n",
       "  'contains(%)': False,\n",
       "  'contains(rest)': False,\n",
       "  'contains(go)': False,\n",
       "  'contains(bounds)': False,\n",
       "  'contains(whole)': False,\n",
       "  'contains(body)': False,\n",
       "  'contains(feels)': False,\n",
       "  'contains(itchy)': False,\n",
       "  'contains(like)': False,\n",
       "  'contains(fire)': False,\n",
       "  'contains(behaving)': False,\n",
       "  \"contains(i'm)\": False,\n",
       "  'contains(mad)': False,\n",
       "  'contains(?)': False,\n",
       "  'contains(see)': False,\n",
       "  'contains(crew)': False,\n",
       "  'contains(need)': False,\n",
       "  'contains(hug)': False,\n",
       "  'contains(hey)': False,\n",
       "  'contains(long)': False,\n",
       "  'contains(time)': False,\n",
       "  'contains(yes)': False,\n",
       "  'contains(..)': False,\n",
       "  'contains(rains)': False,\n",
       "  'contains(bit)': False,\n",
       "  'contains(lol)': False,\n",
       "  'contains(fine)': False,\n",
       "  'contains(thanks)': False,\n",
       "  \"contains(how's)\": False,\n",
       "  'contains(nope)': False,\n",
       "  'contains(que)': False,\n",
       "  'contains(muera)': False,\n",
       "  'contains(spring)': False,\n",
       "  'contains(break)': False,\n",
       "  'contains(plain)': False,\n",
       "  'contains(city)': False,\n",
       "  'contains(snowing)': False,\n",
       "  'contains(re-pierced)': False,\n",
       "  'contains(ears)': False,\n",
       "  'contains(bear)': False,\n",
       "  'contains(watch)': False,\n",
       "  'contains(thought)': False,\n",
       "  'contains(ua)': False,\n",
       "  'contains(loss)': False,\n",
       "  'contains(embarrassing)': False,\n",
       "  'contains(. . . . .)': False,\n",
       "  'contains(counts)': False,\n",
       "  'contains(idk)': False,\n",
       "  'contains(either)': False,\n",
       "  'contains(never)': False,\n",
       "  'contains(talk)': False,\n",
       "  'contains(anymore)': False,\n",
       "  \"contains(would've)\": False,\n",
       "  'contains(first)': False,\n",
       "  'contains(gun)': False,\n",
       "  'contains(really)': False,\n",
       "  'contains(though)': False,\n",
       "  'contains(zac)': False,\n",
       "  \"contains(snyder's)\": False,\n",
       "  'contains(doucheclown)': False,\n",
       "  'contains(wish)': False,\n",
       "  'contains(miss)': False,\n",
       "  'contains(premiere)': False,\n",
       "  'contains(hollis)': False,\n",
       "  \"contains(')\": False,\n",
       "  'contains(death)': False,\n",
       "  'contains(scene)': False,\n",
       "  'contains(hurt)': False,\n",
       "  'contains(severely)': False,\n",
       "  'contains(film)': False,\n",
       "  'contains(wry)': False,\n",
       "  'contains(directors)': False,\n",
       "  'contains(cut)': False,\n",
       "  'contains(file)': False,\n",
       "  'contains(taxes)': False,\n",
       "  'contains(ahh)': False,\n",
       "  'contains(ive)': False,\n",
       "  'contains(always)': False,\n",
       "  'contains(wanted)': False,\n",
       "  'contains(rent)': False,\n",
       "  'contains(love)': False,\n",
       "  'contains(soundtrack)': False,\n",
       "  'contains(oh)': False,\n",
       "  'contains(dear)': False,\n",
       "  'contains(drinking)': False,\n",
       "  'contains(forgotten)': False,\n",
       "  'contains(table)': False,\n",
       "  'contains(drinks)': False,\n",
       "  'contains(get)': False,\n",
       "  'contains(much)': False,\n",
       "  'contains(done)': False,\n",
       "  'contains(one)': False,\n",
       "  'contains(friend)': False,\n",
       "  'contains(called)': False,\n",
       "  'contains(asked)': False,\n",
       "  'contains(meet)': False,\n",
       "  'contains(mid)': False,\n",
       "  'contains(valley)': False,\n",
       "  \"contains(i've)\": False,\n",
       "  'contains(*)': False,\n",
       "  'contains(sigh)': False,\n",
       "  'contains(baked)': False,\n",
       "  'contains(cake)': False,\n",
       "  'contains(ated)': False,\n",
       "  'contains(week)': False,\n",
       "  'contains(going)': False,\n",
       "  'contains(hoped)': False,\n",
       "  'contains(blagh)': False,\n",
       "  'contains(class)': False,\n",
       "  'contains(8)': False,\n",
       "  'contains(tomorrow)': False,\n",
       "  'contains(hate)': False,\n",
       "  'contains(call)': False,\n",
       "  'contains(wake)': False,\n",
       "  'contains(people)': False,\n",
       "  'contains(sleep)': False,\n",
       "  'contains(watching)': False,\n",
       "  'contains(marley)': False,\n",
       "  'contains(im)': False,\n",
       "  'contains(sad)': False,\n",
       "  'contains(miss.lilly)': False,\n",
       "  'contains(oooh)': False,\n",
       "  'contains(leslie)': False,\n",
       "  'contains(ok)': False,\n",
       "  'contains(meh)': False,\n",
       "  'contains(almost)': False,\n",
       "  'contains(lover)': False,\n",
       "  'contains(exception)': False,\n",
       "  'contains(track)': False,\n",
       "  'contains(gets)': False,\n",
       "  'contains(depressed)': False,\n",
       "  'contains(every)': False,\n",
       "  'contains(1)': False,\n",
       "  'contains(hacked)': False,\n",
       "  'contains(account)': False,\n",
       "  'contains(aim)': False,\n",
       "  'contains(make)': False,\n",
       "  'contains(new)': False,\n",
       "  'contains(want)': False,\n",
       "  'contains(promote)': False,\n",
       "  'contains(gear)': False,\n",
       "  'contains(groove)': False,\n",
       "  'contains(unfornately)': False,\n",
       "  'contains(ride)': False,\n",
       "  'contains(may)': False,\n",
       "  'contains(b)': False,\n",
       "  'contains(anaheim)': False,\n",
       "  'contains(sleeping)': False,\n",
       "  'contains(option)': False,\n",
       "  'contains(realizing)': False,\n",
       "  'contains(evaluations)': False,\n",
       "  'contains(morning)': False,\n",
       "  'contains(work)': False,\n",
       "  'contains(afternoon)': False,\n",
       "  'contains(awe)': False,\n",
       "  'contains(asian)': False,\n",
       "  'contains(eyes)': False,\n",
       "  'contains(night)': False,\n",
       "  'contains(sick)': False,\n",
       "  'contains(spent)': False,\n",
       "  'contains(hour)': True,\n",
       "  'contains(sitting)': False,\n",
       "  'contains(shower)': False,\n",
       "  'contains(cause)': False,\n",
       "  'contains(stand)': False,\n",
       "  'contains(held)': False,\n",
       "  'contains(back)': False,\n",
       "  'contains(puke)': False,\n",
       "  'contains(champ)': False,\n",
       "  'contains(bed)': True,\n",
       "  'contains(ill)': False,\n",
       "  'contains(tell)': False,\n",
       "  'contains(ya)': False,\n",
       "  'contains(story)': False,\n",
       "  'contains(later)': False,\n",
       "  'contains(good)': False,\n",
       "  'contains(workin)': False,\n",
       "  'contains(three)': False,\n",
       "  'contains(hours)': False,\n",
       "  'contains(sorry)': False,\n",
       "  'contains(came)': False,\n",
       "  'contains(()': False,\n",
       "  'contains(gmt)': False,\n",
       "  'contains(+)': False,\n",
       "  'contains())': False,\n",
       "  'contains(depressing)': False,\n",
       "  'contains(think)': False,\n",
       "  'contains(even)': False,\n",
       "  'contains(know)': False,\n",
       "  'contains(kids)': False,\n",
       "  'contains(suitcases)': False,\n",
       "  'contains(8-12)': False,\n",
       "  'contains(12-3)': False,\n",
       "  'contains(gym)': False,\n",
       "  'contains(3-5)': False,\n",
       "  'contains(6)': False,\n",
       "  'contains(6-10)': False,\n",
       "  'contains(another)': False,\n",
       "  'contains(gonna)': False,\n",
       "  'contains(fly)': False,\n",
       "  'contains(girlfriend)': False,\n",
       "  'contains(feel)': False,\n",
       "  'contains(getting)': False,\n",
       "  'contains(study)': False,\n",
       "  'contains(tomorrows)': False,\n",
       "  'contains(practical)': False,\n",
       "  'contains(exam)': False,\n",
       "  \"contains(he's)\": False,\n",
       "  'contains(reason)': False,\n",
       "  'contains(teardrops)': False,\n",
       "  'contains(guitar)': False,\n",
       "  'contains(enough)': False,\n",
       "  'contains(heart)': False,\n",
       "  'contains(feeling)': False,\n",
       "  'contains(wanna)': False,\n",
       "  'contains(still)': False,\n",
       "  'contains(soo)': False,\n",
       "  'contains(finally)': False,\n",
       "  'contains(comfortable)': False,\n",
       "  'contains(missed)': False,\n",
       "  'contains(falling)': False,\n",
       "  'contains(asleep)': False,\n",
       "  'contains(heard)': False,\n",
       "  'contains(tracy)': False,\n",
       "  \"contains(girl's)\": False,\n",
       "  'contains(found)': False,\n",
       "  'contains(breaks)': False,\n",
       "  'contains(family)': False,\n",
       "  'contains(yay)': False,\n",
       "  'contains(happy)': False,\n",
       "  'contains(job)': False,\n",
       "  'contains(means)': False,\n",
       "  'contains(less)': False,\n",
       "  'contains(checked)': False,\n",
       "  'contains(user)': False,\n",
       "  'contains(timeline)': False,\n",
       "  'contains(blackberry)': False,\n",
       "  'contains(looks)': False,\n",
       "  'contains(twanking)': False,\n",
       "  'contains(happening)': False,\n",
       "  'contains(ppl)': False,\n",
       "  'contains(probs)': False,\n",
       "  'contains(w)': False,\n",
       "  'contains(/)': False,\n",
       "  'contains(bgs)': False,\n",
       "  'contains(uids)': False,\n",
       "  'contains(man)': False,\n",
       "  'contains(ironing)': False,\n",
       "  'contains(fave)': False,\n",
       "  'contains(top)': False,\n",
       "  'contains(wear)': False,\n",
       "  'contains(meeting)': False,\n",
       "  'contains(burnt)': False,\n",
       "  'contains(strangely)': False,\n",
       "  'contains(lilo)': False,\n",
       "  'contains(samro)': False,\n",
       "  'contains(breaking)': False,\n",
       "  'contains(retweeting)': False,\n",
       "  'contains(broadband)': False,\n",
       "  'contains(plan)': False,\n",
       "  'contains(massive)': False,\n",
       "  'contains(broken)': False,\n",
       "  'contains(promise)': False,\n",
       "  'contains(via)': False,\n",
       "  'contains(www.diigo.com/~tautao)': False,\n",
       "  'contains(waiting)': False,\n",
       "  'contains(wow)': False,\n",
       "  'contains(tons)': False,\n",
       "  'contains(replies)': False,\n",
       "  'contains(unfollow)': False,\n",
       "  'contains(friends)': False,\n",
       "  'contains(tweets)': False,\n",
       "  'contains(scrolling)': False,\n",
       "  'contains(feed)': False,\n",
       "  'contains(lot)': False,\n",
       "  'contains(duck)': False,\n",
       "  'contains(chicken)': False,\n",
       "  'contains(taking)': False,\n",
       "  'contains(wayyy)': False,\n",
       "  'contains(hatch)': False,\n",
       "  'contains(put)': False,\n",
       "  'contains(vacation)': False,\n",
       "  'contains(photos)': False,\n",
       "  'contains(online)': False,\n",
       "  'contains(yrs)': False,\n",
       "  'contains(ago)': False,\n",
       "  'contains(pc)': False,\n",
       "  'contains(crashed)': False,\n",
       "  'contains(forget)': False,\n",
       "  'contains(name)': False,\n",
       "  'contains(site)': False,\n",
       "  'contains(sure)': False,\n",
       "  'contains(pos)': False,\n",
       "  'contains(dont)': False,\n",
       "  'contains(trade)': False,\n",
       "  'contains(away)': False,\n",
       "  'contains(company)': False,\n",
       "  'contains(assets)': False,\n",
       "  'contains(andy)': False,\n",
       "  'contains(happens)': False,\n",
       "  'contains(dallas)': False,\n",
       "  'contains(show)': False,\n",
       "  'contains(gotta)': False,\n",
       "  'contains(say)': False,\n",
       "  'contains(shows)': False,\n",
       "  'contains(would)': False,\n",
       "  'contains(use)': False,\n",
       "  'contains(music)': False,\n",
       "  'contains(game)': False,\n",
       "  'contains(mmm)': False,\n",
       "  'contains(ugh)': True,\n",
       "  'contains(92)': False,\n",
       "  'contains(degrees)': False,\n",
       "  'contains(u)': False,\n",
       "  'contains(move)': False,\n",
       "  'contains(already)': False,\n",
       "  'contains(sd)': False,\n",
       "  'contains(hmmm)': False,\n",
       "  'contains(random)': False,\n",
       "  'contains(glad)': False,\n",
       "  'contains(hear)': False,\n",
       "  'contains(yer)': False,\n",
       "  'contains(well)': False,\n",
       "  'contains(ps3)': False,\n",
       "  'contains(commission)': False,\n",
       "  'contains(wutcha)': False,\n",
       "  'contains(playing)': False,\n",
       "  'contains(copped)': False,\n",
       "  'contains(blood)': False,\n",
       "  'contains(sand)': False,\n",
       "  'contains(leaving)': False,\n",
       "  'contains(parking)': False,\n",
       "  'contains(life)': False,\n",
       "  'contains(cool)': False,\n",
       "  'contains(sadly)': False,\n",
       "  'contains(gotten)': False,\n",
       "  'contains(experience)': False,\n",
       "  'contains(post)': False,\n",
       "  'contains(coitus)': False,\n",
       "  'contains(cigarette)': False,\n",
       "  'contains(nice)': False,\n",
       "  'contains(bad)': False,\n",
       "  'contains(rain)': False,\n",
       "  'contains(comes)': False,\n",
       "  'contains(5am)': False,\n",
       "  'contains(around)': False,\n",
       "  'contains(lost)': False,\n",
       "  'contains(pay)': False,\n",
       "  'contains(phone)': False,\n",
       "  'contains(bill)': False,\n",
       "  'contains(lmao)': False,\n",
       "  'contains(aw)': False,\n",
       "  'contains(shucks)': False,\n",
       "  'contains(damm)': False,\n",
       "  'contains(mo)': False,\n",
       "  'contains(jobs)': False,\n",
       "  'contains(money)': False,\n",
       "  'contains(hell)': False,\n",
       "  'contains(min)': False,\n",
       "  'contains(wage)': False,\n",
       "  'contains(4)': False,\n",
       "  \"contains(f'n)\": False,\n",
       "  'contains(clams)': False,\n",
       "  'contains(forever)': False,\n",
       "  'contains(soon)': False,\n",
       "  'contains(agreed)': False,\n",
       "  'contains(saw)': False,\n",
       "  'contains(failwhale)': False,\n",
       "  'contains(alll)': False,\n",
       "  'contains(haha)': False,\n",
       "  'contains(dude)': False,\n",
       "  'contains(look)': False,\n",
       "  'contains(em)': False,\n",
       "  'contains(unless)': False,\n",
       "  'contains(someone)': False,\n",
       "  'contains(says)': False,\n",
       "  'contains(added)': False,\n",
       "  'contains(terrible)': False,\n",
       "  'contains(pop)': False,\n",
       "  'contains(right)': False,\n",
       "  'contains(start)': False,\n",
       "  'contains(working)': False,\n",
       "  'contains(nikster)': False,\n",
       "  'contains(jared)': False,\n",
       "  'contains(least)': False,\n",
       "  'contains(diss)': False,\n",
       "  'contains(bands)': False,\n",
       "  'contains(trace)': False,\n",
       "  'contains(clearly)': False,\n",
       "  'contains(ugly)': False,\n",
       "  'contains(attire)': False,\n",
       "  'contains(:)': False,\n",
       "  'contains(puma)': False,\n",
       "  'contains(singlet)': False,\n",
       "  'contains(adidas)': False,\n",
       "  'contains(shorts)': False,\n",
       "  'contains(black)': False,\n",
       "  'contains(business)': False,\n",
       "  'contains(socks)': False,\n",
       "  'contains(leather)': False,\n",
       "  'contains(shoes)': False,\n",
       "  'contains(lucky)': False,\n",
       "  'contains(run)': False,\n",
       "  'contains(cute)': False,\n",
       "  'contains(girls)': False,\n",
       "  'contains(location)': False,\n",
       "  'contains(picnic)': False,\n",
       "  'contains(smells)': False,\n",
       "  'contains(citrus)': False,\n",
       "  'contains(donkey)': False,\n",
       "  'contains(sensitive)': False,\n",
       "  'contains(comments)': False,\n",
       "  'contains(nevertheless)': False,\n",
       "  \"contains(he'd)\": False,\n",
       "  \"contains(me'd)\": False,\n",
       "  'contains(mug)': False,\n",
       "  'contains(asap)': False,\n",
       "  'contains(charger)': False,\n",
       "  'contains(awol)': False,\n",
       "  'contains(csi)': False,\n",
       "  'contains(tonight)': False,\n",
       "  'contains(fml)': False,\n",
       "  'contains(arms)': False,\n",
       "  'contains(sore)': False,\n",
       "  'contains(tennis)': False,\n",
       "  'contains(wonders)': False,\n",
       "  'contains(unhappy)': False,\n",
       "  'contains(split)': False,\n",
       "  'contains(seccond)': False,\n",
       "  'contains(saying)': False,\n",
       "  'contains(bye)': False,\n",
       "  'contains(ur)': False,\n",
       "  'contains(newsletter)': False,\n",
       "  'contains(fares)': False,\n",
       "  'contains(unbelievable)': False,\n",
       "  'contains(shame)': False,\n",
       "  'contains(booked)': False,\n",
       "  'contains(paid)': False,\n",
       "  'contains(mine)': False,\n",
       "  'contains(missin)': False,\n",
       "  'contains(boo)': False,\n",
       "  'contains(#itm)': False,\n",
       "  'contains(damn)': False,\n",
       "  'contains(chalk)': False,\n",
       "  'contains(chalkboard)': False,\n",
       "  'contains(useless)': False,\n",
       "  'contains(blast)': False,\n",
       "  'contains(getty)': False,\n",
       "  'contains(villa)': False,\n",
       "  'contains(hates)': False,\n",
       "  'contains(throat)': False,\n",
       "  'contains(worse)': False,\n",
       "  'contains(sup)': False,\n",
       "  'contains(mama)': False,\n",
       "  'contains(tummy)': False,\n",
       "  'contains(hurts)': False,\n",
       "  'contains(wonder)': False,\n",
       "  'contains(hypnosis)': False,\n",
       "  'contains(anything)': False,\n",
       "  'contains(stop)': False,\n",
       "  'contains(smoking)': False,\n",
       "  'contains(fat)': False,\n",
       "  'contains(ones)': False,\n",
       "  'contains(babe)': False,\n",
       "  'contains(fam)': False,\n",
       "  'contains(annoys)': False,\n",
       "  'contains(thankfully)': False,\n",
       "  \"contains(they're)\": False,\n",
       "  'contains(muahaha)': False,\n",
       "  'contains(evil)': False,\n",
       "  'contains(laugh)': False,\n",
       "  'contains(attention)': False,\n",
       "  'contains(covered)': False,\n",
       "  'contains(photoshop)': False,\n",
       "  'contains(webpage)': False,\n",
       "  'contains(design)': False,\n",
       "  'contains(undergrad)': False,\n",
       "  'contains(wednesday)': False,\n",
       "  'contains(b-day)': False,\n",
       "  'contains(2)': False,\n",
       "  'contains(poor)': False,\n",
       "  'contains(cameron)': False,\n",
       "  'contains(hills)': False,\n",
       "  'contains(pray)': False,\n",
       "  'contains(please)': False,\n",
       "  'contains(ex)': False,\n",
       "  'contains(threatening)': False,\n",
       "  'contains(sh)': False,\n",
       "  'contains(babies)': False,\n",
       "  'contains(1st)': False,\n",
       "  'contains(birthday)': False,\n",
       "  'contains(party)': False,\n",
       "  'contains(jerk)': False,\n",
       "  'contains(headache)': False,\n",
       "  'contains(hmm)': False,\n",
       "  'contains(enjoy)': False,\n",
       "  'contains(problems)': False,\n",
       "  'contains(constants)': False,\n",
       "  'contains(things)': False,\n",
       "  'contains(find)': False,\n",
       "  'contains(ulike)': False,\n",
       "  'contains(strider)': False,\n",
       "  'contains(little)': False,\n",
       "  'contains(puppy)': False,\n",
       "  'contains(rylee)': False,\n",
       "  'contains(grace)': False,\n",
       "  'contains(wana)': False,\n",
       "  \"contains(steve's)\": False,\n",
       "  'contains(since)': False,\n",
       "  'contains(easter)': False,\n",
       "  'contains(wnt)': False,\n",
       "  'contains(able)': False,\n",
       "  'contains(ohh)': False,\n",
       "  'contains(actually)': False,\n",
       "  'contains(bracket)': False,\n",
       "  'contains(pools)': False,\n",
       "  'contains(follow)': False,\n",
       "  'contains(nite)': False,\n",
       "  'contains(favorite)': False,\n",
       "  'contains(teams)': False,\n",
       "  'contains(astros)': False,\n",
       "  'contains(spartans)': False,\n",
       "  'contains(lose)': False,\n",
       "  'contains(missing)': False,\n",
       "  'contains(northern)': False,\n",
       "  'contains(calif)': False,\n",
       "  'contains(girl)': False,\n",
       "  'contains(police)': False,\n",
       "  'contains(remains)': False,\n",
       "  'contains(california)': False,\n",
       "  'contains(hope)': False,\n",
       "  'contains(increase)': False,\n",
       "  'contains(capacity)': False,\n",
       "  'contains(fast)': False,\n",
       "  'contains(yesterday)': False,\n",
       "  'contains(pain)': False,\n",
       "  'contains(fail)': False,\n",
       "  'contains(whale)': False,\n",
       "  'contains(15)': False,\n",
       "  'contains(behind)': False,\n",
       "  'contains(classes)': False,\n",
       "  'contains(\")': False,\n",
       "  'contains(house)': False,\n",
       "  'contains(remember)': False,\n",
       "  'contains(bum)': False,\n",
       "  'contains(leg)': False,\n",
       "  'contains(strikes)': False,\n",
       "  'contains(serious)': False,\n",
       "  'contains(kinds)': False,\n",
       "  'contains(complaints)': False,\n",
       "  'contains(laptop)': False,\n",
       "  'contains(overheating)': False,\n",
       "  'contains(recalls)': False,\n",
       "  'contains(emily)': False,\n",
       "  'contains(mommy)': False,\n",
       "  'contains(training)': False,\n",
       "  'contains(misses)': False,\n",
       "  'contains(rather)': False,\n",
       "  'contains(send)': False,\n",
       "  'contains(messages)': False,\n",
       "  'contains(3rd)': False,\n",
       "  'contains(mixed)': False,\n",
       "  'contains(sophmore)': False,\n",
       "  'contains(year)': False,\n",
       "  'contains(overrated)': False,\n",
       "  'contains(wondered)': False,\n",
       "  'contains(thing)': False,\n",
       "  'contains(moscow)': False,\n",
       "  'contains(laying)': False,\n",
       "  'contains(voice)': False,\n",
       "  'contains(sooo)': False,\n",
       "  'contains(killed)': False,\n",
       "  'contains(kutner)': False,\n",
       "  'contains(whyyy)': False,\n",
       "  'contains(mea)': False,\n",
       "  'contains(culpa)': False,\n",
       "  'contains(sense)': False,\n",
       "  'contains(suicide)': False,\n",
       "  'contains(refuse)': False,\n",
       "  'contains(believe)': False,\n",
       "  'contains(happened)': False,\n",
       "  'contains(grind)': False,\n",
       "  'contains(inspirational)': False,\n",
       "  'contains(saddening)': False,\n",
       "  'contains(cuz)': False,\n",
       "  'contains(yeah)': False,\n",
       "  'contains(wudnt)': False,\n",
       "  'contains(chance)': False,\n",
       "  'contains(cant)': False,\n",
       "  'contains(1:30)': False,\n",
       "  'contains(hanging)': False,\n",
       "  'contains(crooners)': False,\n",
       "  'contains(sing)': False,\n",
       "  'contains(sucks)': False,\n",
       "  'contains(aaw)': False,\n",
       "  'contains(bh)': False,\n",
       "  'contains(aww)': False,\n",
       "  'contains(beach)': False,\n",
       "  'contains(pissed)': False,\n",
       "  \"contains(there's)\": False,\n",
       "  \"contains(asba's)\": False,\n",
       "  'contains(radio)': False,\n",
       "  'contains(station)': False,\n",
       "  'contains(n)': False,\n",
       "  'contains(flipped)': False,\n",
       "  'contains(upside)': False,\n",
       "  'contains(head)': False,\n",
       "  'contains(ramen)': False,\n",
       "  'contains(sounds)': False,\n",
       "  'contains(sides)': False,\n",
       "  'contains(mention)': False,\n",
       "  'contains(crying)': False,\n",
       "  'contains(made)': False,\n",
       "  'contains(late)': False,\n",
       "  'contains(snack)': False,\n",
       "  'contains(glass)': False,\n",
       "  'contains(oj)': False,\n",
       "  'contains(c)': False,\n",
       "  'contains(sickness)': False,\n",
       "  'contains(big)': False,\n",
       "  'contains(fan)': False,\n",
       "  'contains(camilla)': False,\n",
       "  'contains(belle)': False,\n",
       "  'contains(wah)': False,\n",
       "  'contains(clip)': False,\n",
       "  'contains(must)': False,\n",
       "  'contains(el-stupido)': False,\n",
       "  'contains(filters)': False,\n",
       "  'contains(wait)': False,\n",
       "  'contains(till)': False,\n",
       "  'contains(puter)': False,\n",
       "  'contains(something)': False,\n",
       "  'contains(else)': False,\n",
       "  'contains(blame)': False,\n",
       "  'contains(broke)': False,\n",
       "  'contains(seems)': False,\n",
       "  'contains(longer)': False,\n",
       "  'contains(terms)': False,\n",
       "  'contains(cold)': False,\n",
       "  'contains(ehhh)': False,\n",
       "  \"contains(weather's)\": False,\n",
       "  'contains(take)': False,\n",
       "  'contains(turn)': False,\n",
       "  'contains(cooold)': False,\n",
       "  'contains(incredible)': False,\n",
       "  'contains(stuff)': False,\n",
       "  'contains(hoping)': False,\n",
       "  'contains(rumbles)': False,\n",
       "  'contains(notice)': False,\n",
       "  'contains(told)': False,\n",
       "  \"contains(i'd)\": False,\n",
       "  'contains(agency)': False,\n",
       "  'contains(said)': False,\n",
       "  'contains(bedtime)': False,\n",
       "  'contains(alive)': False,\n",
       "  'contains(yawwwnn)': False,\n",
       "  'contains(tired)': False,\n",
       "  'contains(imma)': False,\n",
       "  'contains(try)': False,\n",
       "  'contains(hopefully)': False,\n",
       "  'contains(headstart)': False,\n",
       "  'contains(agh)': False,\n",
       "  'contains(snow)': False,\n",
       "  'contains(kenny)': False,\n",
       "  'contains(powers)': False,\n",
       "  'contains(thank)': False,\n",
       "  'contains(letting)': False,\n",
       "  'contains(direct)': False,\n",
       "  'contains(message)': False,\n",
       "  'contains(bridget)': False,\n",
       "  'contains(india)': False,\n",
       "  'contains(100th)': False,\n",
       "  'contains(test)': False,\n",
       "  'contains(victory)': False,\n",
       "  'contains(10th)': False,\n",
       "  'contains(consecutive)': False,\n",
       "  'contains(win)': False,\n",
       "  'contains(without)': False,\n",
       "  'contains(guess)': False,\n",
       "  'contains(stephan)': False,\n",
       "  'contains(leavin)': False,\n",
       "  'contains(intending)': False,\n",
       "  'contains(finish)': False,\n",
       "  'contains(editing)': False,\n",
       "  'contains(536)': False,\n",
       "  'contains(page)': False,\n",
       "  'contains(novel)': False,\n",
       "  'contains(manuscript)': False,\n",
       "  'contains(probably)': False,\n",
       "  'contains(happen)': False,\n",
       "  'contains(12)': False,\n",
       "  'contains(pages)': False,\n",
       "  'contains(left)': False,\n",
       "  'contains(laid)': False,\n",
       "  'contains(read)': False,\n",
       "  'contains(9th)': False,\n",
       "  'contains(&)': False,\n",
       "  'contains(princess)': False,\n",
       "  'contains(diaries)': False,\n",
       "  'contains(saving)': False,\n",
       "  'contains(francesca)': False,\n",
       "  'contains(end)': False,\n",
       "  'contains(easy)': False,\n",
       "  'contains(books)': False,\n",
       "  'contains(nokia)': False,\n",
       "  'contains(1110)': False,\n",
       "  'contains(died)': False,\n",
       "  'contains(mom)': False,\n",
       "  'contains(breast)': False,\n",
       "  'contains(cancer)': False,\n",
       "  'contains(worried)': False,\n",
       "  'contains(better)': False,\n",
       "  'contains(understood)': False,\n",
       "  'contains(daylight)': False,\n",
       "  'contains(savings)': False,\n",
       "  'contains(ended)': False,\n",
       "  'contains(breakfast)': False,\n",
       "  'contains(keep)': False,\n",
       "  'contains(waking)': False,\n",
       "  'contains(lame)': False,\n",
       "  'contains(understand)': False,\n",
       "  'contains(heroes)': False,\n",
       "  'contains(season)': False,\n",
       "  'contains(living)': False,\n",
       "  'contains(downtown)': False,\n",
       "  'contains(fun)': False,\n",
       "  'contains(calorie)': False,\n",
       "  'contains(wise)': False,\n",
       "  'contains(junk)': False,\n",
       "  'contains(food)': False,\n",
       "  'contains(free)': False,\n",
       "  'contains(ate)': False,\n",
       "  'contains(sour)': False,\n",
       "  'contains(skittles)': False,\n",
       "  'contains(ass)': False,\n",
       "  'contains(cherry)': False,\n",
       "  'contains(coke)': False,\n",
       "  'contains(hard)': False,\n",
       "  'contains(hot)': False,\n",
       "  'contains(tea)': False,\n",
       "  'contains(studying)': False,\n",
       "  'contains(sleeep)': False,\n",
       "  'contains(eyebrows)': False,\n",
       "  'contains(waxed)': False,\n",
       "  'contains(phantasy)': False,\n",
       "  'contains(star)': False,\n",
       "  'contains(macheist)': False,\n",
       "  'contains(3.0)': False,\n",
       "  'contains(apps)': False,\n",
       "  'contains(sweet)': False,\n",
       "  'contains(espresso)': False,\n",
       "  'contains(serial)': False,\n",
       "  'contains(although)': False,\n",
       "  'contains(sent)': False,\n",
       "  'contains(picked)': False,\n",
       "  'contains(mich)': False,\n",
       "  'contains(st)': False,\n",
       "  'contains(pretty)': False,\n",
       "  'contains(pick)': False,\n",
       "  'contains(way)': False,\n",
       "  \"contains(a's)\": False,\n",
       "  'contains(alone)': False,\n",
       "  'contains(downstairs)': False,\n",
       "  'contains(anoop)': False,\n",
       "  'contains(mean)': False,\n",
       "  'contains(seriously)': False,\n",
       "  'contains(kinda)': False,\n",
       "  'contains(sprint)': False,\n",
       "  'contains(4g)': False,\n",
       "  'contains(baltimore)': False,\n",
       "  'contains(chicago)': False,\n",
       "  'contains(far)': False,\n",
       "  'contains(stuck)': False,\n",
       "  'contains(awake)': False,\n",
       "  'contains(middle)': False,\n",
       "  'contains(second)': False,\n",
       "  'contains(row)': False,\n",
       "  'contains(felt)': False,\n",
       "  'contains(bursting)': False,\n",
       "  'contains(bubble)': False,\n",
       "  'contains(gosh)': False,\n",
       "  'contains(deleted)': False,\n",
       "  'contains(history)': False,\n",
       "  'contains(crazy)': False,\n",
       "  'contains(wind)': False,\n",
       "  'contains(=)': False,\n",
       "  'contains(birding)': False,\n",
       "  'contains(currently)': False,\n",
       "  'contains(grrr)': False,\n",
       "  'contains(ipods)': False,\n",
       "  'contains(acting)': False,\n",
       "  'contains(weird)': False,\n",
       "  'contains(jai)': False,\n",
       "  'contains(ho)': False,\n",
       "  'contains(thinking)': False,\n",
       "  'contains(full)': False,\n",
       "  'contains(songs)': False,\n",
       "  'contains(ughh)': False,\n",
       "  'contains(dvd)': False,\n",
       "  'contains(cos)': False,\n",
       "  'contains(heaps)': False,\n",
       "  'contains(deal)': False,\n",
       "  'contains(website)': False,\n",
       "  'contains(#therapyfail)': False,\n",
       "  'contains(rail)': False,\n",
       "  'contains(tips)': False,\n",
       "  'contains(swear)': False,\n",
       "  'contains(losing)': False,\n",
       "  'contains(gaining)': False,\n",
       "  'contains(tweeps)': False,\n",
       "  'contains(wrenching)': False,\n",
       "  'contains(realized)': False,\n",
       "  'contains(hiding)': False,\n",
       "  'contains(staying)': False,\n",
       "  'contains(neighbors)': False,\n",
       "  'contains(loud-having)': False,\n",
       "  'contains(danny)': False,\n",
       "  'contains(wasnt)': False,\n",
       "  'contains(live)': False,\n",
       "  'contains(chat)': False,\n",
       "  'contains(car)': False,\n",
       "  'contains(3)': False,\n",
       "  'contains(trip)': False,\n",
       "  'contains(check)': False,\n",
       "  'contains(borders)': False,\n",
       "  'contains(closed)': False,\n",
       "  'contains(10)': False,\n",
       "  'contains(downloading)': False,\n",
       "  \"contains(nin's)\": False,\n",
       "  'contains(album)': False,\n",
       "  'contains(slip)': False,\n",
       "  'contains(come)': False,\n",
       "  'contains(days)': False,\n",
       "  'contains(woke)': False,\n",
       "  'contains(written)': False,\n",
       "  'contains(e-mail)': False,\n",
       "  'contains(early)': False,\n",
       "  'contains(university)': False,\n",
       "  'contains(teach)': False,\n",
       "  'contains(8:)': False,\n",
       "  'contains(30)': False,\n",
       "  'contains(hill)': False,\n",
       "  'contains(. . .)': False,\n",
       "  'contains(making)': False,\n",
       "  'contains(channels)': False,\n",
       "  'contains(yet)': False,\n",
       "  'contains(boring)': False,\n",
       "  'contains(lazy)': False,\n",
       "  'contains(hobby)': False,\n",
       "  'contains(buddy)': False,\n",
       "  'contains(ny)': False,\n",
       "  'contains(25th)': False,\n",
       "  'contains(french)': False,\n",
       "  'contains(south)': False,\n",
       "  'contains(qtr)': False,\n",
       "  'contains(snarl)': False,\n",
       "  'contains(beautiful)': False,\n",
       "  'contains(opps)': False,\n",
       "  'contains(remain)': False,\n",
       "  'contains(problem)': False,\n",
       "  'contains(activated)': False,\n",
       "  'contains(selfcontrol)': False,\n",
       "  'contains(block)': False,\n",
       "  'contains(meaning)': False,\n",
       "  'contains(qc)': False,\n",
       "  'contains(regularizing)': False,\n",
       "  'contains(internal)': False,\n",
       "  'contains(clock)': False,\n",
       "  'contains(difficult)': False,\n",
       "  'contains(#fb)': False,\n",
       "  'contains(spencer)': False,\n",
       "  'contains(guy)': False,\n",
       "  'contains(reese)': False,\n",
       "  'contains(dying)': False,\n",
       "  'contains(#ttsc)': False,\n",
       "  'contains(finale)': False,\n",
       "  'contains(next)': False,\n",
       "  'contains(#24)': False,\n",
       "  'contains(madame)': False,\n",
       "  'contains(president)': False,\n",
       "  'contains(woman)': False,\n",
       "  'contains(limited)': False,\n",
       "  'contains(letters)': False,\n",
       "  'contains(too.hope)': False,\n",
       "  'contains(guys)': False,\n",
       "  'contains(dog)': False,\n",
       "  'contains(sheï)': False,\n",
       "  'contains(¿)': False,\n",
       "  'contains(½)': False,\n",
       "  'contains(shit)': False,\n",
       "  'contains(~)': False,\n",
       "  'contains(screwed)': False,\n",
       "  'contains(wanttss)': False,\n",
       "  'contains(tonite)': False,\n",
       "  'contains(interview)': False,\n",
       "  'contains(cardiff)': False,\n",
       "  'contains(luck)': False,\n",
       "  'contains(whack)': False,\n",
       "  'contains(wiggety-whack)': False,\n",
       "  'contains(:*()': False,\n",
       "  'contains(choose)': False,\n",
       "  'contains(chose)': False,\n",
       "  'contains(accept)': False,\n",
       "  \"contains(family's)\": False,\n",
       "  'contains(help)': False,\n",
       "  'contains(dead)': False,\n",
       "  'contains(kill)': False,\n",
       "  'contains(seen)': False,\n",
       "  'contains(ds9)': False,\n",
       "  'contains(solid)': False,\n",
       "  'contains(hahaha)': False,\n",
       "  'contains(4.5)': False,\n",
       "  'contains(hrs)': False,\n",
       "  'contains(mind)': False,\n",
       "  'contains(protesting)': False,\n",
       "  'contains(nightmares)': False,\n",
       "  'contains(boot)': False,\n",
       "  'contains(goin)': False,\n",
       "  'contains(angels)': False,\n",
       "  'contains(library)': False,\n",
       "  'contains(nap)': False,\n",
       "  'contains(interrupted)': False,\n",
       "  'contains(japanese)': False,\n",
       "  'contains(rents)': False,\n",
       "  'contains(kind)': False,\n",
       "  'contains(longs)': False,\n",
       "  'contains(bus)': False,\n",
       "  'contains(ghost)': False,\n",
       "  'contains(world)': False,\n",
       "  'contains(canada)': False,\n",
       "  \"contains(we're)\": False,\n",
       "  'contains(supposed)': False,\n",
       "  'contains(awwh)': False,\n",
       "  'contains(babs)': False,\n",
       "  'contains(underneith)': False,\n",
       "  'contains(shop)': False,\n",
       "  'contains(entrance)': False,\n",
       "  \"contains(yesterday's)\": False,\n",
       "  'contains(musik)': False,\n",
       "  'contains(transformer)': False,\n",
       "  'contains(movie)': False,\n",
       "  'contains(feet)': False,\n",
       "  'contains(macbook)': False,\n",
       "  'contains(fell)': False,\n",
       "  'contains(132am)': False,\n",
       "  'contains(tipsy)': False,\n",
       "  'contains(lonesome)': False,\n",
       "  'contains(sweating)': False,\n",
       "  'contains(forthcoming)': False,\n",
       "  'contains(e3)': False,\n",
       "  'contains(crash)': False,\n",
       "  'contains(somebody)': False,\n",
       "  'contains(omgawd)': False,\n",
       "  'contains(couldnt)': False,\n",
       "  'contains(handle)': False,\n",
       "  'contains(cat)': False,\n",
       "  'contains(heat)': False,\n",
       "  'contains(d:)': False,\n",
       "  'contains(auburn)': False,\n",
       "  'contains(looking)': False,\n",
       "  'contains(thats)': False,\n",
       "  'contains(mag)': False,\n",
       "  'contains(fit)': False,\n",
       "  'contains(pictures)': False,\n",
       "  'contains(ever)': False,\n",
       "  'contains(magazine)': False,\n",
       "  ...},\n",
       " 'neg')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'plot': True,\n",
       "  ':': True,\n",
       "  'two': True,\n",
       "  'teen': True,\n",
       "  'couples': True,\n",
       "  'go': True,\n",
       "  'to': True,\n",
       "  'a': True,\n",
       "  'church': True,\n",
       "  'party': True,\n",
       "  ',': True,\n",
       "  'drink': True,\n",
       "  'and': True,\n",
       "  'then': True,\n",
       "  'drive': True,\n",
       "  '.': True,\n",
       "  'they': True,\n",
       "  'get': True,\n",
       "  'into': True,\n",
       "  'an': True,\n",
       "  'accident': True,\n",
       "  'one': True,\n",
       "  'of': True,\n",
       "  'the': True,\n",
       "  'guys': True,\n",
       "  'dies': True,\n",
       "  'but': True,\n",
       "  'his': True,\n",
       "  'girlfriend': True,\n",
       "  'continues': True,\n",
       "  'see': True,\n",
       "  'him': True,\n",
       "  'in': True,\n",
       "  'her': True,\n",
       "  'life': True,\n",
       "  'has': True,\n",
       "  'nightmares': True,\n",
       "  'what': True,\n",
       "  \"'\": True,\n",
       "  's': True,\n",
       "  'deal': True,\n",
       "  '?': True,\n",
       "  'watch': True,\n",
       "  'movie': True,\n",
       "  '\"': True,\n",
       "  'sorta': True,\n",
       "  'find': True,\n",
       "  'out': True,\n",
       "  'critique': True,\n",
       "  'mind': True,\n",
       "  '-': True,\n",
       "  'fuck': True,\n",
       "  'for': True,\n",
       "  'generation': True,\n",
       "  'that': True,\n",
       "  'touches': True,\n",
       "  'on': True,\n",
       "  'very': True,\n",
       "  'cool': True,\n",
       "  'idea': True,\n",
       "  'presents': True,\n",
       "  'it': True,\n",
       "  'bad': True,\n",
       "  'package': True,\n",
       "  'which': True,\n",
       "  'is': True,\n",
       "  'makes': True,\n",
       "  'this': True,\n",
       "  'review': True,\n",
       "  'even': True,\n",
       "  'harder': True,\n",
       "  'write': True,\n",
       "  'since': True,\n",
       "  'i': True,\n",
       "  'generally': True,\n",
       "  'applaud': True,\n",
       "  'films': True,\n",
       "  'attempt': True,\n",
       "  'break': True,\n",
       "  'mold': True,\n",
       "  'mess': True,\n",
       "  'with': True,\n",
       "  'your': True,\n",
       "  'head': True,\n",
       "  'such': True,\n",
       "  '(': True,\n",
       "  'lost': True,\n",
       "  'highway': True,\n",
       "  '&': True,\n",
       "  'memento': True,\n",
       "  ')': True,\n",
       "  'there': True,\n",
       "  'are': True,\n",
       "  'good': True,\n",
       "  'ways': True,\n",
       "  'making': True,\n",
       "  'all': True,\n",
       "  'types': True,\n",
       "  'these': True,\n",
       "  'folks': True,\n",
       "  'just': True,\n",
       "  'didn': True,\n",
       "  't': True,\n",
       "  'snag': True,\n",
       "  'correctly': True,\n",
       "  'seem': True,\n",
       "  'have': True,\n",
       "  'taken': True,\n",
       "  'pretty': True,\n",
       "  'neat': True,\n",
       "  'concept': True,\n",
       "  'executed': True,\n",
       "  'terribly': True,\n",
       "  'so': True,\n",
       "  'problems': True,\n",
       "  'well': True,\n",
       "  'its': True,\n",
       "  'main': True,\n",
       "  'problem': True,\n",
       "  'simply': True,\n",
       "  'too': True,\n",
       "  'jumbled': True,\n",
       "  'starts': True,\n",
       "  'off': True,\n",
       "  'normal': True,\n",
       "  'downshifts': True,\n",
       "  'fantasy': True,\n",
       "  'world': True,\n",
       "  'you': True,\n",
       "  'as': True,\n",
       "  'audience': True,\n",
       "  'member': True,\n",
       "  'no': True,\n",
       "  'going': True,\n",
       "  'dreams': True,\n",
       "  'characters': True,\n",
       "  'coming': True,\n",
       "  'back': True,\n",
       "  'from': True,\n",
       "  'dead': True,\n",
       "  'others': True,\n",
       "  'who': True,\n",
       "  'look': True,\n",
       "  'like': True,\n",
       "  'strange': True,\n",
       "  'apparitions': True,\n",
       "  'disappearances': True,\n",
       "  'looooot': True,\n",
       "  'chase': True,\n",
       "  'scenes': True,\n",
       "  'tons': True,\n",
       "  'weird': True,\n",
       "  'things': True,\n",
       "  'happen': True,\n",
       "  'most': True,\n",
       "  'not': True,\n",
       "  'explained': True,\n",
       "  'now': True,\n",
       "  'personally': True,\n",
       "  'don': True,\n",
       "  'trying': True,\n",
       "  'unravel': True,\n",
       "  'film': True,\n",
       "  'every': True,\n",
       "  'when': True,\n",
       "  'does': True,\n",
       "  'give': True,\n",
       "  'me': True,\n",
       "  'same': True,\n",
       "  'clue': True,\n",
       "  'over': True,\n",
       "  'again': True,\n",
       "  'kind': True,\n",
       "  'fed': True,\n",
       "  'up': True,\n",
       "  'after': True,\n",
       "  'while': True,\n",
       "  'biggest': True,\n",
       "  'obviously': True,\n",
       "  'got': True,\n",
       "  'big': True,\n",
       "  'secret': True,\n",
       "  'hide': True,\n",
       "  'seems': True,\n",
       "  'want': True,\n",
       "  'completely': True,\n",
       "  'until': True,\n",
       "  'final': True,\n",
       "  'five': True,\n",
       "  'minutes': True,\n",
       "  'do': True,\n",
       "  'make': True,\n",
       "  'entertaining': True,\n",
       "  'thrilling': True,\n",
       "  'or': True,\n",
       "  'engaging': True,\n",
       "  'meantime': True,\n",
       "  'really': True,\n",
       "  'sad': True,\n",
       "  'part': True,\n",
       "  'arrow': True,\n",
       "  'both': True,\n",
       "  'dig': True,\n",
       "  'flicks': True,\n",
       "  'we': True,\n",
       "  'actually': True,\n",
       "  'figured': True,\n",
       "  'by': True,\n",
       "  'half': True,\n",
       "  'way': True,\n",
       "  'point': True,\n",
       "  'strangeness': True,\n",
       "  'did': True,\n",
       "  'start': True,\n",
       "  'little': True,\n",
       "  'bit': True,\n",
       "  'sense': True,\n",
       "  'still': True,\n",
       "  'more': True,\n",
       "  'guess': True,\n",
       "  'bottom': True,\n",
       "  'line': True,\n",
       "  'movies': True,\n",
       "  'should': True,\n",
       "  'always': True,\n",
       "  'sure': True,\n",
       "  'before': True,\n",
       "  'given': True,\n",
       "  'password': True,\n",
       "  'enter': True,\n",
       "  'understanding': True,\n",
       "  'mean': True,\n",
       "  'showing': True,\n",
       "  'melissa': True,\n",
       "  'sagemiller': True,\n",
       "  'running': True,\n",
       "  'away': True,\n",
       "  'visions': True,\n",
       "  'about': True,\n",
       "  '20': True,\n",
       "  'throughout': True,\n",
       "  'plain': True,\n",
       "  'lazy': True,\n",
       "  '!': True,\n",
       "  'okay': True,\n",
       "  'people': True,\n",
       "  'chasing': True,\n",
       "  'know': True,\n",
       "  'need': True,\n",
       "  'how': True,\n",
       "  'giving': True,\n",
       "  'us': True,\n",
       "  'different': True,\n",
       "  'offering': True,\n",
       "  'further': True,\n",
       "  'insight': True,\n",
       "  'down': True,\n",
       "  'apparently': True,\n",
       "  'studio': True,\n",
       "  'took': True,\n",
       "  'director': True,\n",
       "  'chopped': True,\n",
       "  'themselves': True,\n",
       "  'shows': True,\n",
       "  'might': True,\n",
       "  've': True,\n",
       "  'been': True,\n",
       "  'decent': True,\n",
       "  'here': True,\n",
       "  'somewhere': True,\n",
       "  'suits': True,\n",
       "  'decided': True,\n",
       "  'turning': True,\n",
       "  'music': True,\n",
       "  'video': True,\n",
       "  'edge': True,\n",
       "  'would': True,\n",
       "  'actors': True,\n",
       "  'although': True,\n",
       "  'wes': True,\n",
       "  'bentley': True,\n",
       "  'seemed': True,\n",
       "  'be': True,\n",
       "  'playing': True,\n",
       "  'exact': True,\n",
       "  'character': True,\n",
       "  'he': True,\n",
       "  'american': True,\n",
       "  'beauty': True,\n",
       "  'only': True,\n",
       "  'new': True,\n",
       "  'neighborhood': True,\n",
       "  'my': True,\n",
       "  'kudos': True,\n",
       "  'holds': True,\n",
       "  'own': True,\n",
       "  'entire': True,\n",
       "  'feeling': True,\n",
       "  'unraveling': True,\n",
       "  'overall': True,\n",
       "  'doesn': True,\n",
       "  'stick': True,\n",
       "  'because': True,\n",
       "  'entertain': True,\n",
       "  'confusing': True,\n",
       "  'rarely': True,\n",
       "  'excites': True,\n",
       "  'feels': True,\n",
       "  'redundant': True,\n",
       "  'runtime': True,\n",
       "  'despite': True,\n",
       "  'ending': True,\n",
       "  'explanation': True,\n",
       "  'craziness': True,\n",
       "  'came': True,\n",
       "  'oh': True,\n",
       "  'horror': True,\n",
       "  'slasher': True,\n",
       "  'flick': True,\n",
       "  'packaged': True,\n",
       "  'someone': True,\n",
       "  'assuming': True,\n",
       "  'genre': True,\n",
       "  'hot': True,\n",
       "  'kids': True,\n",
       "  'also': True,\n",
       "  'wrapped': True,\n",
       "  'production': True,\n",
       "  'years': True,\n",
       "  'ago': True,\n",
       "  'sitting': True,\n",
       "  'shelves': True,\n",
       "  'ever': True,\n",
       "  'whatever': True,\n",
       "  'skip': True,\n",
       "  'where': True,\n",
       "  'joblo': True,\n",
       "  'nightmare': True,\n",
       "  'elm': True,\n",
       "  'street': True,\n",
       "  '3': True,\n",
       "  '7': True,\n",
       "  '/': True,\n",
       "  '10': True,\n",
       "  'blair': True,\n",
       "  'witch': True,\n",
       "  '2': True,\n",
       "  'crow': True,\n",
       "  '9': True,\n",
       "  'salvation': True,\n",
       "  '4': True,\n",
       "  'stir': True,\n",
       "  'echoes': True,\n",
       "  '8': True},\n",
       " 'neg')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfeats[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
